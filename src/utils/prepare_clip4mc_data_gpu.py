#!/usr/bin/env python3
"""
CLIP4MC æ•°æ®å‡†å¤‡è„šæœ¬ - GPU åŠ é€Ÿç‰ˆæœ¬

ä½¿ç”¨ NVIDIA GPU ç¡¬ä»¶è§£ç  (NVDEC) åŠ é€Ÿè§†é¢‘å¤„ç†

ä¾èµ–:
    pip install nvidia-ml-py3 torch torchvision

ä½¿ç”¨æ–¹æ³•:
    python src/utils/prepare_clip4mc_data_gpu.py \
        --pairs-json data/train_pairs.json \
        --clips-dir data/clips \
        --output-dir /path/to/processed \
        --gpu-ids 0,1,2,3 \
        --batch-size 8
"""

import argparse
import json
import pickle
import logging
import sys
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple
import random
import time
import subprocess
from multiprocessing import Process, Queue, Manager
from queue import Empty

import numpy as np

try:
    import torch
    import torchvision
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("âš ï¸ PyTorch æœªå®‰è£…")

try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [GPU-%(process)d] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_gpu_availability():
    """æ£€æŸ¥ GPU å¯ç”¨æ€§"""
    if not torch.cuda.is_available():
        return False, "CUDA ä¸å¯ç”¨"
    
    try:
        import pynvml
        pynvml.nvmlInit()
        device_count = pynvml.nvmlDeviceGetCount()
        
        gpu_info = []
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            name = pynvml.nvmlDeviceGetName(handle)
            gpu_info.append(f"GPU {i}: {name}")
        
        return True, "\n".join(gpu_info)
    except Exception as e:
        return True, f"æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ª GPU"


def extract_frames_gpu_ffmpeg(
    video_path: Path, 
    num_frames: int = 16,
    frame_height: int = 160, 
    frame_width: int = 256,
    gpu_id: int = 0
) -> Optional[np.ndarray]:
    """
    ä½¿ç”¨ ffmpeg + NVDEC ç¡¬ä»¶è§£ç æå–å¸§
    
    æ³¨æ„: éœ€è¦ ffmpeg ç¼–è¯‘æ—¶å¯ç”¨ NVDEC æ”¯æŒ
    """
    try:
        # 1. è·å–è§†é¢‘æ€»å¸§æ•°
        probe_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-count_packets',
            '-show_entries', 'stream=nb_read_packets',
            '-of', 'csv=p=0',
            str(video_path)
        ]
        
        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=5)
        total_frames = int(result.stdout.strip())
        
        if total_frames == 0:
            return None
        
        # 2. è®¡ç®—é‡‡æ ·é—´éš”
        if total_frames >= num_frames:
            step = total_frames / num_frames
        else:
            step = 1
        
        # 3. ä½¿ç”¨ ffmpeg NVDEC è§£ç 
        # -hwaccel cuda: ä½¿ç”¨ CUDA ç¡¬ä»¶åŠ é€Ÿ
        # -hwaccel_device: æŒ‡å®š GPU
        # -c:v h264_cuvid: ä½¿ç”¨ NVDEC è§£ç å™¨
        ffmpeg_cmd = [
            'ffmpeg',
            '-hwaccel', 'cuda',
            '-hwaccel_device', str(gpu_id),
            '-i', str(video_path),
            '-vf', f'select=not(mod(n\\,{int(step)})),scale={frame_width}:{frame_height}',
            '-vsync', '0',
            '-f', 'rawvideo',
            '-pix_fmt', 'rgb24',
            '-frames:v', str(num_frames),
            'pipe:1'
        ]
        
        result = subprocess.run(
            ffmpeg_cmd, 
            capture_output=True, 
            timeout=30,
            check=False
        )
        
        if result.returncode != 0:
            # Fallback to CPU decoding
            return extract_frames_cpu_fallback(video_path, num_frames, frame_height, frame_width)
        
        # 4. è§£æè¾“å‡º
        frame_size = frame_height * frame_width * 3
        frames_data = result.stdout
        
        if len(frames_data) < frame_size * num_frames:
            # æ•°æ®ä¸å®Œæ•´ï¼Œè¡¥é½
            frames = []
            for i in range(num_frames):
                start = i * frame_size
                end = start + frame_size
                if end <= len(frames_data):
                    frame = np.frombuffer(frames_data[start:end], dtype=np.uint8)
                    frame = frame.reshape((frame_height, frame_width, 3))
                    frames.append(frame)
                else:
                    # ä½¿ç”¨æœ€åä¸€å¸§æˆ–é»‘å¸§
                    if frames:
                        frames.append(frames[-1])
                    else:
                        frames.append(np.zeros((frame_height, frame_width, 3), dtype=np.uint8))
            return np.array(frames)
        
        frames = np.frombuffer(frames_data, dtype=np.uint8)
        frames = frames.reshape((-1, frame_height, frame_width, 3))
        
        return frames[:num_frames]
    
    except Exception as e:
        logger.debug(f"GPU è§£ç å¤±è´¥: {e}, å›é€€åˆ° CPU")
        return extract_frames_cpu_fallback(video_path, num_frames, frame_height, frame_width)


def extract_frames_cpu_fallback(
    video_path: Path, 
    num_frames: int = 16,
    frame_height: int = 160, 
    frame_width: int = 256
) -> Optional[np.ndarray]:
    """CPU è§£ç  fallback"""
    if not HAS_CV2:
        return None
    
    cap = cv2.VideoCapture(str(video_path))
    
    if not cap.isOpened():
        return None
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        cap.release()
        return None
    
    # å‡åŒ€é‡‡æ ·
    if total_frames >= num_frames:
        indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    else:
        indices = list(range(total_frames)) + [total_frames - 1] * (num_frames - total_frames)
    
    frames = np.zeros((num_frames, frame_height, frame_width, 3), dtype=np.uint8)
    
    for i, idx in enumerate(indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        
        if ret:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, (frame_width, frame_height))
            frames[i] = frame
    
    cap.release()
    
    return frames


def tokenize_text_clip(text: str) -> np.ndarray:
    """CLIP tokenization"""
    try:
        import open_clip
        tokenizer = open_clip.get_tokenizer('ViT-B-16')
        tokens = tokenizer([text])
        return tokens[0].numpy()
    except:
        # Fallback
        tokens = np.zeros(77, dtype=np.int64)
        tokens[0] = 49406  # SOS
        tokens[-1] = 49407  # EOS
        return tokens


def gpu_worker(
    gpu_id: int,
    task_queue: Queue,
    result_queue: Queue,
    clips_dir: Path,
    output_dir: Path,
    num_frames: int,
    frame_height: int,
    frame_width: int,
    stop_event
):
    """
    GPU å·¥ä½œè¿›ç¨‹
    
    æ¯ä¸ª GPU ä¸€ä¸ªè¿›ç¨‹ï¼Œæ‰¹é‡å¤„ç†è§†é¢‘
    """
    logger.info(f"GPU {gpu_id} worker å¯åŠ¨")
    
    # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„ GPU
    if HAS_TORCH:
        torch.cuda.set_device(gpu_id)
    
    processed_count = 0
    
    while not stop_event.is_set():
        try:
            # è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶ 1 ç§’ï¼‰
            task = task_queue.get(timeout=1)
            
            if task is None:  # æ¯’ä¸¸ä¿¡å·
                break
            
            idx, pair = task
            
            try:
                vid = pair['vid']
                transcript = pair.get('transcript', pair.get('transcript clip', ''))
                clip_path_str = pair['clip_path']
                
                clip_filename = Path(clip_path_str).name
                clip_path = clips_dir / clip_filename
                
                if not clip_path.exists():
                    result_queue.put((False, None, f"æ–‡ä»¶ä¸å­˜åœ¨: {clip_path}"))
                    continue
                
                # GPU è§£ç 
                frames = extract_frames_gpu_ffmpeg(
                    clip_path, num_frames, frame_height, frame_width, gpu_id
                )
                
                if frames is None:
                    result_queue.put((False, None, f"è§£ç å¤±è´¥: {clip_path}"))
                    continue
                
                # Tokenize
                tokens = tokenize_text_clip(transcript)
                
                # ä¿å­˜
                sample_dir = output_dir / f"sample_{idx:06d}_{vid}"
                sample_dir.mkdir(parents=True, exist_ok=True)
                
                with open(sample_dir / "video_input.pkl", "wb") as f:
                    pickle.dump(frames, f, protocol=pickle.HIGHEST_PROTOCOL)
                
                with open(sample_dir / "text_input.pkl", "wb") as f:
                    pickle.dump({'tokens': tokens}, f, protocol=pickle.HIGHEST_PROTOCOL)
                
                # Size
                if 'size' in pair and isinstance(pair['size'], list) and len(pair['size']) > 0:
                    size_values = pair['size']
                    if len(size_values) != num_frames:
                        if len(size_values) >= num_frames:
                            indices = np.linspace(0, len(size_values) - 1, num_frames, dtype=int)
                            size_values = [size_values[i] for i in indices]
                        else:
                            size_values = size_values + [size_values[-1]] * (num_frames - len(size_values))
                else:
                    size_values = [0.5] * num_frames
                
                with open(sample_dir / "size.json", "w") as f:
                    json.dump(size_values, f)
                
                result_queue.put((True, str(sample_dir), None))
                processed_count += 1
                
            except Exception as e:
                result_queue.put((False, None, f"å¤„ç†å¼‚å¸¸: {str(e)}"))
        
        except Empty:
            continue
        except Exception as e:
            logger.error(f"Worker å¼‚å¸¸: {e}")
            break
    
    logger.info(f"GPU {gpu_id} worker å®Œæˆï¼Œå¤„ç†äº† {processed_count} ä¸ªè§†é¢‘")


def process_with_gpu(
    pairs: List[Dict[str, Any]],
    clips_dir: Path,
    output_dir: Path,
    gpu_ids: List[int],
    num_frames: int = 16,
    frame_height: int = 160,
    frame_width: int = 256,
    resume_from: Optional[Path] = None
) -> List[str]:
    """
    ä½¿ç”¨å¤š GPU å¹¶è¡Œå¤„ç†
    """
    # åŠ è½½æ£€æŸ¥ç‚¹
    processed_samples = set()
    if resume_from and resume_from.exists():
        with open(resume_from) as f:
            checkpoint = json.load(f)
            processed_samples = set(checkpoint.get('processed_indices', []))
        logger.info(f"ä»æ–­ç‚¹æ¢å¤: å·²å¤„ç† {len(processed_samples)} ä¸ªæ ·æœ¬")
    
    # è¿‡æ»¤æœªå¤„ç†çš„æ ·æœ¬
    tasks = [(i, pair) for i, pair in enumerate(pairs) if i not in processed_samples]
    
    if not tasks:
        logger.info("æ‰€æœ‰æ ·æœ¬å·²å¤„ç†å®Œæˆ")
        return []
    
    logger.info(f"å¾…å¤„ç†: {len(tasks)} ä¸ªæ ·æœ¬")
    logger.info(f"ä½¿ç”¨ GPU: {gpu_ids}")
    
    # åˆ›å»ºé˜Ÿåˆ—
    manager = Manager()
    task_queue = manager.Queue()
    result_queue = manager.Queue()
    stop_event = manager.Event()
    
    # å¡«å……ä»»åŠ¡é˜Ÿåˆ—
    for task in tasks:
        task_queue.put(task)
    
    # ä¸ºæ¯ä¸ª GPU æ·»åŠ æ¯’ä¸¸ä¿¡å·
    for _ in gpu_ids:
        task_queue.put(None)
    
    # å¯åŠ¨ GPU workers
    workers = []
    for gpu_id in gpu_ids:
        p = Process(
            target=gpu_worker,
            args=(gpu_id, task_queue, result_queue, clips_dir, output_dir,
                  num_frames, frame_height, frame_width, stop_event)
        )
        p.start()
        workers.append(p)
    
    # æ”¶é›†ç»“æœ
    successful_dirs = []
    failed_count = 0
    
    if HAS_TQDM:
        pbar = tqdm(total=len(tasks), desc="ğŸ¬ GPU å¤„ç†", unit="video")
    
    checkpoint_interval = 1000
    processed_count = len(processed_samples)
    
    for _ in range(len(tasks)):
        try:
            success, sample_dir, error_msg = result_queue.get(timeout=60)
            
            if success:
                successful_dirs.append(sample_dir)
                processed_count += 1
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if resume_from and processed_count % checkpoint_interval == 0:
                    with open(resume_from, 'w') as f:
                        json.dump({
                            'processed_indices': list(processed_samples) + 
                                               list(range(len(successful_dirs))),
                            'timestamp': time.time()
                        }, f)
            else:
                failed_count += 1
                if error_msg and failed_count <= 10:
                    logger.warning(error_msg)
            
            if HAS_TQDM:
                pbar.update(1)
        
        except Empty:
            logger.warning("ç»“æœé˜Ÿåˆ—è¶…æ—¶")
            break
    
    if HAS_TQDM:
        pbar.close()
    
    # ç­‰å¾…æ‰€æœ‰ workers å®Œæˆ
    for p in workers:
        p.join(timeout=10)
    
    logger.info(f"å¤„ç†å®Œæˆ: æˆåŠŸ {len(successful_dirs)}, å¤±è´¥ {failed_count}")
    
    return successful_dirs


def main():
    parser = argparse.ArgumentParser(description="CLIP4MC æ•°æ®å‡†å¤‡ï¼ˆGPU åŠ é€Ÿç‰ˆæœ¬ï¼‰")
    
    parser.add_argument("--pairs-json", type=Path, required=True)
    parser.add_argument("--clips-dir", type=Path, required=True)
    parser.add_argument("--output-dir", type=Path, required=True)
    
    parser.add_argument("--gpu-ids", type=str, default="0", 
                       help="GPU IDsï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ 0,1,2,3")
    parser.add_argument("--num-frames", type=int, default=16)
    parser.add_argument("--frame-height", type=int, default=160)
    parser.add_argument("--frame-width", type=int, default=256)
    
    parser.add_argument("--split-mode", type=str, 
                       choices=['random', 'all_train', 'all_test'],
                       default='random')
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--max-samples", type=int, default=None)
    
    parser.add_argument("--resume", action='store_true')
    parser.add_argument("--checkpoint-file", type=Path, 
                       default=Path("checkpoint_gpu.json"))
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ GPU
    available, gpu_info = check_gpu_availability()
    if not available:
        logger.error(f"GPU ä¸å¯ç”¨: {gpu_info}")
        logger.error("å›é€€åˆ° CPU æ¨¡å¼: python src/utils/prepare_clip4mc_data_parallel.py")
        sys.exit(1)
    
    logger.info(f"æ£€æµ‹åˆ° GPU:\n{gpu_info}")
    
    # è§£æ GPU IDs
    gpu_ids = [int(x.strip()) for x in args.gpu_ids.split(',')]
    logger.info(f"å°†ä½¿ç”¨ GPU: {gpu_ids}")
    
    # åŠ è½½æ•°æ®
    with open(args.pairs_json, encoding="utf-8") as f:
        pairs = json.load(f)
    
    logger.info(f"åŠ è½½äº† {len(pairs)} ä¸ªæ ·æœ¬")
    
    if args.max_samples:
        pairs = pairs[:args.max_samples]
        logger.info(f"é™åˆ¶ä¸º {args.max_samples} ä¸ªæ ·æœ¬")
    
    args.output_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"\n{'='*60}")
    logger.info(f"GPU åŠ é€Ÿå¤„ç†é…ç½®:")
    logger.info(f"  GPU æ•°é‡: {len(gpu_ids)}")
    logger.info(f"  å¸§å°ºå¯¸: {args.frame_height}x{args.frame_width}")
    logger.info(f"  æ–­ç‚¹ç»­ä¼ : {'å¼€å¯' if args.resume else 'å…³é—­'}")
    logger.info(f"{'='*60}\n")
    
    start_time = time.time()
    
    successful_dirs = process_with_gpu(
        pairs=pairs,
        clips_dir=args.clips_dir,
        output_dir=args.output_dir,
        gpu_ids=gpu_ids,
        num_frames=args.num_frames,
        frame_height=args.frame_height,
        frame_width=args.frame_width,
        resume_from=args.checkpoint_file if args.resume else None
    )
    
    elapsed = time.time() - start_time
    
    if not successful_dirs:
        logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ ·æœ¬")
        sys.exit(1)
    
    logger.info(f"\næ€»è€—æ—¶: {elapsed/3600:.2f} å°æ—¶")
    logger.info(f"å¹³å‡é€Ÿåº¦: {len(successful_dirs)/elapsed:.2f} è§†é¢‘/ç§’")
    
    # åˆ’åˆ†æ•°æ®é›†
    n = len(successful_dirs)
    
    if args.split_mode == 'all_train':
        train_dirs, val_dirs, test_dirs = successful_dirs, [], []
    elif args.split_mode == 'all_test':
        train_dirs, val_dirs, test_dirs = [], [], successful_dirs
    else:
        random.seed(args.seed)
        random.shuffle(successful_dirs)
        n_test = max(1, int(n * 0.1))
        n_val = max(1, int(n * 0.1))
        n_train = n - n_test - n_val
        train_dirs = successful_dirs[:n_train]
        val_dirs = successful_dirs[n_train:n_train + n_val]
        test_dirs = successful_dirs[n_train + n_val:]
    
    logger.info(f"è®­ç»ƒé›†: {len(train_dirs)}")
    logger.info(f"éªŒè¯é›†: {len(val_dirs)}")
    logger.info(f"æµ‹è¯•é›†: {len(test_dirs)}")
    
    # ä¿å­˜ dataset_info.json
    dataset_info = {
        "train": train_dirs,
        "val": val_dirs,
        "test": test_dirs
    }
    
    with open(args.output_dir / "dataset_info.json", "w") as f:
        json.dump(dataset_info, f, indent=2)
    
    logger.info(f"\nâœ“ å®Œæˆ")


if __name__ == "__main__":
    main()

