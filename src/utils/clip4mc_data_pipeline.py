#!/usr/bin/env python3
"""
CLIP4MC æ•°æ®å¤„ç†æµæ°´çº¿ - ç»Ÿä¸€å·¥å…·

åŠŸèƒ½:
1. è§†é¢‘åˆ‡ç‰‡: raw videos + metadata -> clips
2. æ•°æ®å‡†å¤‡: clips -> training data (pkl files)
3. æ”¯æŒå¤šè¿›ç¨‹/GPUåŠ é€Ÿã€æ–­ç‚¹ç»­ä¼ 

ä½¿ç”¨æ–¹æ³•:
    # å®Œæ•´æµç¨‹: ä»åŸå§‹è§†é¢‘åˆ°è®­ç»ƒæ•°æ®
    python src/utils/clip4mc_data_pipeline.py \
        --mode full \
        --videos-dir /path/to/raw_videos \
        --info-csv info.csv \
        --metadata dataset.json \
        --output-dir /path/to/processed \
        --num-workers 32

    # ä»…åˆ‡ç‰‡
    python src/utils/clip4mc_data_pipeline.py \
        --mode clip \
        --videos-dir /path/to/raw_videos \
        --info-csv info.csv \
        --metadata dataset.json \
        --output-dir /path/to/output

    # ä»…æ•°æ®å‡†å¤‡ (å·²æœ‰clips)
    python src/utils/clip4mc_data_pipeline.py \
        --mode process \
        --clips-dir /path/to/clips \
        --pairs-json text_video_pairs.json \
        --output-dir /path/to/processed \
        --num-workers 32

    # GPU åŠ é€Ÿ
    python src/utils/clip4mc_data_pipeline.py \
        --mode process \
        --clips-dir /path/to/clips \
        --pairs-json text_video_pairs.json \
        --output-dir /path/to/processed \
        --use-gpu \
        --gpu-ids 0,1,2,3
"""

import argparse
import csv
import json
import pickle
import logging
import sys
import re
import subprocess
import time
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple
import random
from multiprocessing import Pool, Manager, Process, Queue, cpu_count
from queue import Empty
from functools import partial

import numpy as np

try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False

try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(processName)s] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================
# ç¬¬ä¸€é˜¶æ®µ: è§†é¢‘åˆ‡ç‰‡
# ============================================================

def extract_video_id(url: str) -> Optional[str]:
    """ä» YouTube URL æå–è§†é¢‘ ID"""
    patterns = [
        r'(?:https?://)?(?:www\.)?youtube\.com/watch\?v=([a-zA-Z0-9_-]{11})',
        r'(?:https?://)?youtu\.be/([a-zA-Z0-9_-]{11})',
        r'v=([a-zA-Z0-9_-]{11})',
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None


def parse_info_csv(csv_path: Path) -> Dict[str, str]:
    """è§£æ info.csv -> {video_id: filename}"""
    vid_to_filename = {}
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        sample = f.read(2048)
        f.seek(0)
        has_header = 'url' in sample.lower() or 'http' not in sample[:100].lower()
        
        try:
            reader = csv.reader(f)
            if has_header:
                next(reader)
            
            for row in reader:
                if len(row) >= 2:
                    url = row[0].strip().strip('"')
                    filename = row[1].strip().strip('"')
                    vid = extract_video_id(url)
                    if vid:
                        vid_to_filename[vid] = filename
        except Exception as e:
            logger.warning(f"CSV è§£æå¤±è´¥: {e}")
            f.seek(0)
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                parts = line.split(',', 1)
                if len(parts) >= 2:
                    url = parts[0].strip().strip('"')
                    filename = parts[1].strip().strip('"')
                    vid = extract_video_id(url)
                    if vid:
                        vid_to_filename[vid] = filename
    
    logger.info(f"ä» info.csv è§£æäº† {len(vid_to_filename)} æ¡è®°å½•")
    return vid_to_filename


def normalize_filename(name: str) -> str:
    """æ ‡å‡†åŒ–æ–‡ä»¶å"""
    name = re.sub(r'\.(mp4|webm|mkv|avi|mov)$', '', name, flags=re.IGNORECASE)
    name = name.lower()
    name = re.sub(r'[^a-z0-9]', '', name)
    return name


def build_file_index(videos_dir: Path) -> dict:
    """å»ºç«‹è§†é¢‘æ–‡ä»¶ç´¢å¼•"""
    name_index = {}
    for f in videos_dir.iterdir():
        if f.is_file() and f.suffix.lower() in ['.mp4', '.webm', '.mkv', '.avi', '.mov']:
            normalized = normalize_filename(f.name)
            name_index[normalized] = f
    return name_index


def find_video_file(videos_dir: Path, filename: str, all_files: dict = None) -> Optional[Path]:
    """æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶"""
    direct_path = videos_dir / filename
    if direct_path.exists():
        return direct_path
    
    if not filename.endswith('.mp4'):
        mp4_path = videos_dir / f"{filename}.mp4"
        if mp4_path.exists():
            return mp4_path
    
    if all_files is not None:
        normalized = normalize_filename(filename)
        if normalized in all_files:
            return all_files[normalized]
    
    return None


def extract_clip_ffmpeg(
    input_path: Path,
    output_path: Path,
    start_time: float,
    end_time: float,
    use_gpu: bool = False,
    gpu_id: int = 0,
    preset: str = "ultrafast",
    crf: int = 28,
    use_copy: bool = False,
    target_height: int = 0,
    target_fps: float = 0
) -> bool:
    """
    ä½¿ç”¨ ffmpeg æå–è§†é¢‘ç‰‡æ®µï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        use_gpu: æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿç¼–ç 
        gpu_id: GPU ID
        preset: ç¼–ç é€Ÿåº¦é¢„è®¾ (ultrafast/superfast/veryfast/fast/medium)
        crf: è´¨é‡æ§åˆ¶ (18-30, è¶Šå¤§è¶Šå¿«ä½†è´¨é‡è¶Šä½)
        use_copy: æ˜¯å¦ç›´æ¥å¤åˆ¶ï¼ˆä¸é‡æ–°ç¼–ç ï¼Œæå¿«ä½†ç²¾åº¦é™ä½ï¼‰
        target_height: ç›®æ ‡åˆ†è¾¨ç‡é«˜åº¦ï¼ˆ0=ä¿æŒåŸæ ·ï¼‰
        target_fps: ç›®æ ‡å¸§ç‡ï¼ˆ0=ä¿æŒåŸæ ·ï¼‰
    
    æ€§èƒ½ä¼˜åŒ–è¯´æ˜:
        - å¿«é€Ÿè·³å¸§ (Input Seek): å·²å®ç°ï¼Œ100-300x åŠ é€Ÿ
        - preset=ultrafast: 2-3x åŠ é€Ÿ
        - crf=28: 1.3x åŠ é€Ÿ
        - æ³¨æ„: CLIP4MC åŸå§‹è§†é¢‘å·²ç»æ˜¯ 360p 30fpsï¼Œé€šå¸¸ä¸éœ€è¦é™ä½åˆ†è¾¨ç‡/å¸§ç‡
    """
    if output_path.exists():
        return True
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    duration = end_time - start_time
    
    # è®¡ç®—å®é™…éœ€è¦çš„å¸§ç‡ï¼ˆç¡®ä¿è‡³å°‘ 20 å¸§ï¼‰
    if target_fps > 0:
        min_fps = 20.0 / max(duration, 1.0)  # è‡³å°‘ 20 å¸§
        actual_fps = max(target_fps, min_fps)
    else:
        actual_fps = 0
    
    if use_copy:
        # æ–¹æ¡ˆ A: ç›´æ¥å¤åˆ¶ï¼ˆæå¿«ï¼Œ10-50xï¼Œä½†ç²¾åº¦ Â±1ç§’ï¼‰
        cmd = [
            "ffmpeg", "-y",
            "-ss", str(start_time),
            "-i", str(input_path),
            "-t", str(duration),
            "-c:v", "copy",
            "-c:a", "copy",
            "-avoid_negative_ts", "1",
            "-loglevel", "error",
            str(output_path)
        ]
    elif use_gpu:
        # æ–¹æ¡ˆ B: GPU ç¼–ç ï¼ˆä¸æ¨èï¼Œæœ‰å¹¶å‘é™åˆ¶ï¼‰
        cmd = [
            "ffmpeg", "-y",
            "-ss", str(start_time),
            "-i", str(input_path),
            "-t", str(duration),
            "-c:v", "h264_nvenc",
            "-preset", "fast",
            "-c:a", "aac",
            "-loglevel", "error",
            str(output_path)
        ]
    else:
        # æ–¹æ¡ˆ C: CPU ç¼–ç ï¼ˆæ¨èï¼Œä¼˜åŒ–å‚æ•° + åˆ†è¾¨ç‡/å¸§ç‡ä¼˜åŒ–ï¼‰
        # æ„å»ºè§†é¢‘æ»¤é•œ
        vf_filters = []
        if target_height > 0:
            vf_filters.append(f"scale=-2:{target_height}")  # ä¿æŒå®½é«˜æ¯”
        if actual_fps > 0:
            vf_filters.append(f"fps={actual_fps:.2f}")
        
        cmd = [
            "ffmpeg", "-y",
            "-ss", str(start_time),
            "-i", str(input_path),
            "-t", str(duration),
        ]
        
        # æ·»åŠ è§†é¢‘æ»¤é•œ
        if vf_filters:
            cmd.extend(["-vf", ",".join(vf_filters)])
        
        cmd.extend([
            "-c:v", "libx264",
            "-preset", preset,      # ä¼˜åŒ–: å¯é…ç½®é€Ÿåº¦
            "-crf", str(crf),       # ä¼˜åŒ–: å¯é…ç½®è´¨é‡
            "-c:a", "aac",
            "-b:a", "64k",          # ä¼˜åŒ–: é™ä½éŸ³é¢‘ç ç‡ï¼ˆCLIP4MC ä¸ç”¨éŸ³é¢‘ï¼‰
            "-ac", "1",             # ä¼˜åŒ–: å•å£°é“
            "-movflags", "+faststart",
            "-loglevel", "error",
            str(output_path)
        ])
    
    try:
        result = subprocess.run(cmd, capture_output=True, timeout=120)
        
        # å¦‚æœ GPU ç¼–ç å¤±è´¥ï¼Œå›é€€åˆ° CPU
        if use_gpu and result.returncode != 0:
            cmd[cmd.index("h264_nvenc")] = "libx264"
            cmd.insert(cmd.index("libx264") + 1, "-preset")
            cmd.insert(cmd.index("libx264") + 2, preset)
            cmd.insert(cmd.index("libx264") + 3, "-crf")
            cmd.insert(cmd.index("libx264") + 4, str(crf))
            result = subprocess.run(cmd, capture_output=True, timeout=120)
        
        # å¦‚æœ copy å¤±è´¥ï¼Œå›é€€åˆ°é‡æ–°ç¼–ç 
        if use_copy and result.returncode != 0:
            return extract_clip_ffmpeg(
                input_path, output_path, start_time, end_time,
                use_gpu=False, preset=preset, crf=crf, use_copy=False
            )
        
        return result.returncode == 0 and output_path.exists()
    except Exception:
        return False


def clip_single_video(task: Tuple[int, Dict]) -> Tuple[bool, Optional[Dict], Optional[str]]:
    """å¤„ç†å•ä¸ªè§†é¢‘åˆ‡ç‰‡ (worker å‡½æ•°)"""
    i, item = task
    
    try:
        vid = item['vid']
        begin = item['begin']
        end = item['end']
        clips_dir = item['clips_dir']
        use_gpu = item.get('use_gpu', False)
        gpu_id = item.get('gpu_id', 0)
        preset = item.get('preset', 'ultrafast')
        crf = item.get('crf', 28)
        use_copy = item.get('use_copy', False)
        target_height = item.get('target_height', 360)
        target_fps = item.get('target_fps', 2.0)
        
        clip_name = f"{vid}_{int(begin)}_{int(end)}.mp4"
        clip_path = clips_dir / clip_name
        
        if extract_clip_ffmpeg(
            item['video_path'], clip_path, begin, end,
            use_gpu=use_gpu, gpu_id=gpu_id,
            preset=preset, crf=crf, use_copy=use_copy,
            target_height=target_height, target_fps=target_fps
        ):
            result = {
                'vid': vid,
                'clip_path': str(clip_path),
                'transcript': item['transcript'],
                'begin_time': begin,
                'end_time': end,
                'duration': end - begin,
                'size': item.get('size', [])
            }
            return True, result, None
        else:
            return False, None, f"åˆ‡ç‰‡å¤±è´¥: {vid}"
    except Exception as e:
        return False, None, f"å¼‚å¸¸: {str(e)}"


def clip_videos(
    videos_dir: Path,
    info_csv: Path,
    metadata_json: Path,
    output_dir: Path,
    num_workers: int = 8,
    use_gpu: bool = False,
    gpu_ids: List[int] = [0],
    preset: str = "ultrafast",
    crf: int = 28,
    use_copy: bool = False,
    target_height: int = 0,
    target_fps: float = 0
) -> Tuple[List[Dict], Path]:
    """
    è§†é¢‘åˆ‡ç‰‡é˜¶æ®µ (æ”¯æŒå¹¶è¡Œ + ç¼–ç ä¼˜åŒ–)
    
    Args:
        use_gpu: æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿç¼–ç ï¼ˆä¸æ¨èï¼Œæœ‰å¹¶å‘é™åˆ¶ï¼‰
        gpu_ids: GPU IDs åˆ—è¡¨
        preset: ç¼–ç é€Ÿåº¦é¢„è®¾ (ultrafast/superfast/fast)
        crf: è´¨é‡æ§åˆ¶ (18-30)
        use_copy: ç›´æ¥å¤åˆ¶æ¨¡å¼ï¼ˆæå¿«ä½†ç²¾åº¦é™ä½ï¼‰
        target_height: ç›®æ ‡åˆ†è¾¨ç‡é«˜åº¦ï¼ˆ0=ä¿æŒåŸæ ·ï¼‰
        target_fps: ç›®æ ‡å¸§ç‡ï¼ˆ0=ä¿æŒåŸæ ·ï¼‰
    
    Returns:
        (pairs, clips_dir): æ–‡æœ¬-è§†é¢‘å¯¹åˆ—è¡¨, åˆ‡ç‰‡ç›®å½•
    """
    logger.info("=" * 60)
    if use_copy:
        mode_desc = "copyæ¨¡å¼ï¼ˆä¸è½¬ç ï¼‰"
    elif use_gpu:
        mode_desc = "GPUç¼–ç ï¼ˆä¸æ¨èï¼‰"
    else:
        res_desc = f"{target_height}p" if target_height > 0 else "åŸå§‹åˆ†è¾¨ç‡"
        fps_desc = f"{target_fps}fps" if target_fps > 0 else "åŸå§‹å¸§ç‡"
        mode_desc = f"CPUç¼–ç  (preset={preset}, crf={crf}, {res_desc}, {fps_desc})"
    logger.info(f"é˜¶æ®µ 1: è§†é¢‘åˆ‡ç‰‡ ({mode_desc})")
    logger.info("=" * 60)
    
    # è§£ææ˜ å°„
    vid_to_filename = parse_info_csv(info_csv)
    
    # åŠ è½½å…ƒæ•°æ®
    with open(metadata_json, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    logger.info(f"åŠ è½½äº† {len(metadata)} æ¡å…ƒæ•°æ®")
    
    # å»ºç«‹æ–‡ä»¶ç´¢å¼•
    logger.info(f"æ‰«æè§†é¢‘ç›®å½•: {videos_dir}")
    name_index = build_file_index(videos_dir)
    logger.info(f"æ‰¾åˆ° {len(name_index)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    # ç»Ÿè®¡å¯ç”¨è§†é¢‘
    available_videos = {}
    for vid, filename in vid_to_filename.items():
        video_path = find_video_file(videos_dir, filename, name_index)
        if video_path:
            available_videos[vid] = video_path
    
    logger.info(f"å¯ç”¨è§†é¢‘: {len(available_videos)} / {len(vid_to_filename)}")
    
    # åˆ›å»ºåˆ‡ç‰‡ç›®å½•
    clips_dir = output_dir / "clips"
    clips_dir.mkdir(parents=True, exist_ok=True)
    
    # ç­›é€‰å¯å¤„ç†çš„å…ƒæ•°æ®
    processable = []
    for i, item in enumerate(metadata):
        vid = item.get('vid', '')
        if vid in available_videos:
            # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ†é… GPUï¼ˆè½®æµï¼‰
            gpu_id = gpu_ids[i % len(gpu_ids)] if use_gpu else 0
            processable.append({
                'vid': vid,
                'video_path': available_videos[vid],
                'transcript': item.get('transcript', item.get('transcript clip', '')),
                'begin': item.get('begin position', item.get('begin', 0)),
                'end': item.get('end position', item.get('end', 0)),
                'size': item.get('size', []),
                'clips_dir': clips_dir,
                'use_gpu': use_gpu,
                'gpu_id': gpu_id,
                'preset': preset,
                'crf': crf,
                'use_copy': use_copy,
                'target_height': target_height,
                'target_fps': target_fps
            })
    
    logger.info(f"å¯å¤„ç†ç‰‡æ®µ: {len(processable)} æ¡")
    logger.info(f"å¹¶è¡Œè¿›ç¨‹: {num_workers}")
    if use_gpu:
        logger.info(f"GPU ç¼–ç : {len(gpu_ids)} å— GPU")
    
    if not processable:
        logger.error("æ²¡æœ‰å¯å¤„ç†çš„ç‰‡æ®µ")
        sys.exit(1)
    
    # å¹¶è¡Œåˆ‡ç‰‡å¤„ç†
    tasks = list(enumerate(processable))
    results = []
    failed_count = 0
    
    with Pool(num_workers) as pool:
        if HAS_TQDM:
            clip_results = tqdm(
                pool.imap_unordered(clip_single_video, tasks, chunksize=5),
                total=len(tasks),
                desc="ğŸ¬ è§†é¢‘åˆ‡ç‰‡",
                unit="clip"
            )
        else:
            clip_results = pool.imap_unordered(clip_single_video, tasks, chunksize=5)
        
        for success, result, error_msg in clip_results:
            if success:
                results.append(result)
            else:
                failed_count += 1
                if error_msg and failed_count <= 5:
                    logger.warning(error_msg)
    
    logger.info(f"åˆ‡ç‰‡å®Œæˆ: {len(results)} ä¸ªç‰‡æ®µ (å¤±è´¥ {failed_count})")
    
    # ä¿å­˜ pairs JSON
    pairs_json = output_dir / "text_video_pairs.json"
    with open(pairs_json, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ä¿å­˜åˆ°: {pairs_json}")
    
    return results, clips_dir


# ============================================================
# ç¬¬äºŒé˜¶æ®µ: æ•°æ®å‡†å¤‡ (å¸§æå– + Tokenization)
# ============================================================

def extract_all_frames_cv2(
    video_path: Path,
    frame_height: int = 160,
    frame_width: int = 256,
    max_frames: int = None
) -> Optional[np.ndarray]:
    """
    æå–è§†é¢‘çš„æ‰€æœ‰å¸§ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼‰
    
    âš ï¸ é‡è¦: å®˜æ–¹ CLIP4MC è¦æ±‚ä¿å­˜è§†é¢‘çš„æ‰€æœ‰å¸§ï¼Œä¸æ˜¯é‡‡æ ·çš„16å¸§ï¼
    DataLoader ä¼šåœ¨åŠ è½½æ—¶åŠ¨æ€é‡‡æ ·16å¸§ã€‚
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
        frame_height: ç›®æ ‡é«˜åº¦ (é»˜è®¤: 160)
        frame_width: ç›®æ ‡å®½åº¦ (é»˜è®¤: 256)
        max_frames: æœ€å¤§å¸§æ•°é™åˆ¶ï¼ˆå¯é€‰ï¼Œé˜²æ­¢è¶…é•¿è§†é¢‘ï¼Œå¦‚1000ï¼‰
    
    Returns:
        np.ndarray: shape (N, H, W, 3) å…¶ä¸­ N æ˜¯æ€»å¸§æ•°
        
    Example:
        å¯¹äº 10s Ã— 30fps çš„è§†é¢‘:
        è¿”å›: (300, 160, 256, 3)
    """
    if not HAS_CV2:
        return None
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        return None
    
    frames = []
    frame_count = 0
    
    while True:
        # æ£€æŸ¥æœ€å¤§å¸§æ•°é™åˆ¶
        if max_frames and frame_count >= max_frames:
            logger.warning(f"è§†é¢‘å¸§æ•°è¶…è¿‡é™åˆ¶ {max_frames}ï¼Œæˆªæ–­")
            break
        
        ret, frame = cap.read()
        if not ret:
            break
        
        # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Resize åˆ°ç›®æ ‡å°ºå¯¸
        frame = cv2.resize(frame, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)
        
        frames.append(frame)
        frame_count += 1
    
    cap.release()
    
    if len(frames) == 0:
        return None
    
    # è¿”å›æ‰€æœ‰å¸§ (N, H, W, 3)
    return np.array(frames, dtype=np.uint8)


def extract_frames_fast_cv2(
    video_path: Path,
    num_frames: int = 16,
    frame_height: int = 160,
    frame_width: int = 256
) -> Optional[np.ndarray]:
    """å¿«é€Ÿæå–å¸§ (CPU)"""
    if not HAS_CV2:
        return None
    
    cap = cv2.VideoCapture(str(video_path), cv2.CAP_FFMPEG)
    if not cap.isOpened():
        return None
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames == 0:
        cap.release()
        return None
    
    if total_frames >= num_frames:
        indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
    else:
        indices = list(range(total_frames)) + [total_frames - 1] * (num_frames - total_frames)
    
    frames = np.zeros((num_frames, frame_height, frame_width, 3), dtype=np.uint8)
    
    for i, idx in enumerate(indices):
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)
            frames[i] = frame
    
    cap.release()
    return frames


def extract_frames_gpu_ffmpeg(
    video_path: Path,
    num_frames: int = 16,
    frame_height: int = 160,
    frame_width: int = 256,
    gpu_id: int = 0
) -> Optional[np.ndarray]:
    """GPU ç¡¬ä»¶è§£ç æå–å¸§"""
    try:
        # è·å–æ€»å¸§æ•°
        probe_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-count_packets',
            '-show_entries', 'stream=nb_read_packets',
            '-of', 'csv=p=0',
            str(video_path)
        ]
        
        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=5)
        total_frames = int(result.stdout.strip())
        
        if total_frames == 0:
            return None
        
        step = total_frames / num_frames if total_frames >= num_frames else 1
        
        # GPU è§£ç 
        ffmpeg_cmd = [
            'ffmpeg',
            '-hwaccel', 'cuda',
            '-hwaccel_device', str(gpu_id),
            '-i', str(video_path),
            '-vf', f'select=not(mod(n\\,{int(step)})),scale={frame_width}:{frame_height}',
            '-vsync', '0',
            '-f', 'rawvideo',
            '-pix_fmt', 'rgb24',
            '-frames:v', str(num_frames),
            'pipe:1'
        ]
        
        result = subprocess.run(ffmpeg_cmd, capture_output=True, timeout=30, check=False)
        
        if result.returncode != 0:
            return extract_frames_fast_cv2(video_path, num_frames, frame_height, frame_width)
        
        frame_size = frame_height * frame_width * 3
        frames_data = result.stdout
        
        if len(frames_data) < frame_size * num_frames:
            frames = []
            for i in range(num_frames):
                start = i * frame_size
                end = start + frame_size
                if end <= len(frames_data):
                    frame = np.frombuffer(frames_data[start:end], dtype=np.uint8)
                    frame = frame.reshape((frame_height, frame_width, 3))
                    frames.append(frame)
                else:
                    if frames:
                        frames.append(frames[-1])
                    else:
                        frames.append(np.zeros((frame_height, frame_width, 3), dtype=np.uint8))
            return np.array(frames)
        
        frames = np.frombuffer(frames_data, dtype=np.uint8)
        frames = frames.reshape((-1, frame_height, frame_width, 3))
        return frames[:num_frames]
    
    except Exception:
        return extract_frames_fast_cv2(video_path, num_frames, frame_height, frame_width)


# å…¨å±€ tokenizer ç¼“å­˜ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
_global_tokenizer = None

def get_tokenizer():
    """è·å–æˆ–åˆ›å»º tokenizerï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _global_tokenizer
    if _global_tokenizer is None:
        try:
            import open_clip
            _global_tokenizer = open_clip.get_tokenizer('ViT-B-16')
        except:
            _global_tokenizer = None
    return _global_tokenizer


def tokenize_text_clip(text: str) -> np.ndarray:
    """CLIP tokenizationï¼ˆä¼˜åŒ–ï¼šå¤ç”¨ tokenizerï¼‰"""
    tokenizer = get_tokenizer()
    
    if tokenizer is not None:
        try:
            tokens = tokenizer([text])
            return tokens[0].numpy()
        except:
            pass
    
    # Fallback
    tokens = np.zeros(77, dtype=np.int64)
    tokens[0] = 49406  # SOS
    tokens[-1] = 49407  # EOS
    return tokens


def process_single_sample_cpu(
    task: Tuple[int, Dict[str, Any]],
    clips_dir: Path,
    output_dir: Path,
    frame_height: int,
    frame_width: int
) -> Tuple[bool, Optional[str], Optional[str]]:
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ (CPU worker)
    
    æå–è§†é¢‘çš„æ‰€æœ‰å¸§ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼‰
    """
    idx, pair = task
    
    try:
        vid = pair['vid']
        transcript = pair.get('transcript', pair.get('transcript clip', ''))
        clip_path_str = pair['clip_path']
        
        clip_filename = Path(clip_path_str).name
        clip_path = clips_dir / clip_filename
        
        if not clip_path.exists():
            return False, None, f"æ–‡ä»¶ä¸å­˜åœ¨: {clip_path}"
        
        # æå–æ‰€æœ‰å¸§ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼‰
        frames = extract_all_frames_cv2(clip_path, frame_height, frame_width)
        
        if frames is None:
            return False, None, f"è§£ç å¤±è´¥: {clip_path}"
        
        # è·å–å®é™…å¸§æ•°
        actual_num_frames = frames.shape[0]
        
        # Tokenize
        tokens = tokenize_text_clip(transcript)
        
        # ä¿å­˜
        sample_dir = output_dir / f"sample_{idx:06d}_{vid}"
        sample_dir.mkdir(parents=True, exist_ok=True)
        
        with open(sample_dir / "video_input.pkl", "wb") as f:
            pickle.dump(frames, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        with open(sample_dir / "text_input.pkl", "wb") as f:
            pickle.dump({'tokens': tokens}, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        # Size - é•¿åº¦åº”è¯¥ä¸å®é™…å¸§æ•°ä¸€è‡´
        if 'size' in pair and isinstance(pair['size'], list) and len(pair['size']) > 0:
            size_values = pair['size']
            # é‡é‡‡æ ·åˆ°å®é™…å¸§æ•°
            if len(size_values) != actual_num_frames:
                if len(size_values) >= actual_num_frames:
                    indices = np.linspace(0, len(size_values) - 1, actual_num_frames, dtype=int)
                    size_values = [size_values[i] for i in indices]
                else:
                    size_values = size_values + [size_values[-1]] * (actual_num_frames - len(size_values))
        else:
            size_values = [0.5] * actual_num_frames
        
        with open(sample_dir / "size.json", "w") as f:
            json.dump(size_values, f)
        
        return True, str(sample_dir), None
    
    except Exception as e:
        return False, None, f"å¤„ç†å¼‚å¸¸: {str(e)}"


def gpu_worker(
    gpu_id: int,
    task_queue: Queue,
    result_queue: Queue,
    clips_dir: Path,
    output_dir: Path,
    frame_height: int,
    frame_width: int,
    stop_event
):
    """
    GPU å·¥ä½œè¿›ç¨‹
    
    æ³¨æ„: GPU æ¨¡å¼ä½¿ç”¨ CPU æå–æ‰€æœ‰å¸§ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼‰
    GPU ä»…ç”¨äºå…¶ä»–åŠ é€Ÿï¼Œä¸ç”¨äºå¸§æå–
    """
    logger.info(f"GPU {gpu_id} worker å¯åŠ¨")
    
    if HAS_TORCH:
        torch.cuda.set_device(gpu_id)
    
    processed_count = 0
    
    while not stop_event.is_set():
        try:
            task = task_queue.get(timeout=1)
            
            if task is None:
                break
            
            idx, pair = task
            
            try:
                vid = pair['vid']
                transcript = pair.get('transcript', pair.get('transcript clip', ''))
                clip_path_str = pair['clip_path']
                
                clip_filename = Path(clip_path_str).name
                clip_path = clips_dir / clip_filename
                
                if not clip_path.exists():
                    result_queue.put((False, None, f"æ–‡ä»¶ä¸å­˜åœ¨: {clip_path}"))
                    continue
                
                # æå–æ‰€æœ‰å¸§ï¼ˆä½¿ç”¨ CPUï¼Œå®˜æ–¹ CLIP4MC æ ¼å¼ï¼‰
                frames = extract_all_frames_cv2(clip_path, frame_height, frame_width)
                
                if frames is None:
                    result_queue.put((False, None, f"è§£ç å¤±è´¥: {clip_path}"))
                    continue
                
                # è·å–å®é™…å¸§æ•°
                actual_num_frames = frames.shape[0]
                
                tokens = tokenize_text_clip(transcript)
                
                sample_dir = output_dir / f"sample_{idx:06d}_{vid}"
                sample_dir.mkdir(parents=True, exist_ok=True)
                
                with open(sample_dir / "video_input.pkl", "wb") as f:
                    pickle.dump(frames, f, protocol=pickle.HIGHEST_PROTOCOL)
                
                with open(sample_dir / "text_input.pkl", "wb") as f:
                    pickle.dump({'tokens': tokens}, f, protocol=pickle.HIGHEST_PROTOCOL)
                
                # Size - é•¿åº¦åº”è¯¥ä¸å®é™…å¸§æ•°ä¸€è‡´
                if 'size' in pair and isinstance(pair['size'], list) and len(pair['size']) > 0:
                    size_values = pair['size']
                    if len(size_values) != actual_num_frames:
                        if len(size_values) >= actual_num_frames:
                            indices = np.linspace(0, len(size_values) - 1, actual_num_frames, dtype=int)
                            size_values = [size_values[i] for i in indices]
                        else:
                            size_values = size_values + [size_values[-1]] * (actual_num_frames - len(size_values))
                else:
                    size_values = [0.5] * actual_num_frames
                
                with open(sample_dir / "size.json", "w") as f:
                    json.dump(size_values, f)
                
                result_queue.put((True, str(sample_dir), None))
                processed_count += 1
                
            except Exception as e:
                result_queue.put((False, None, f"å¤„ç†å¼‚å¸¸: {str(e)}"))
        
        except Empty:
            continue
        except Exception as e:
            logger.error(f"Worker å¼‚å¸¸: {e}")
            break
    
    logger.info(f"GPU {gpu_id} worker å®Œæˆï¼Œå¤„ç†äº† {processed_count} ä¸ªè§†é¢‘")


def process_data_cpu(
    pairs: List[Dict[str, Any]],
    clips_dir: Path,
    output_dir: Path,
    num_workers: int,
    frame_height: int = 160,
    frame_width: int = 256,
    resume_from: Optional[Path] = None
) -> List[str]:
    """
    CPU å¤šè¿›ç¨‹å¤„ç†ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼šæå–æ‰€æœ‰å¸§ï¼‰
    """
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ 2: æ•°æ®å‡†å¤‡ (CPU å¤šè¿›ç¨‹)")
    logger.info("=" * 60)
    
    # æ–­ç‚¹ç»­ä¼ 
    processed_samples = set()
    if resume_from and resume_from.exists():
        with open(resume_from) as f:
            checkpoint = json.load(f)
            processed_samples = set(checkpoint.get('processed_indices', []))
        logger.info(f"ä»æ–­ç‚¹æ¢å¤: å·²å¤„ç† {len(processed_samples)} ä¸ªæ ·æœ¬")
    
    tasks = [(i, pair) for i, pair in enumerate(pairs) if i not in processed_samples]
    
    if not tasks:
        logger.info("æ‰€æœ‰æ ·æœ¬å·²å¤„ç†å®Œæˆ")
        return []
    
    logger.info(f"å¾…å¤„ç†: {len(tasks)} ä¸ªæ ·æœ¬")
    logger.info(f"è¿›ç¨‹æ•°: {num_workers}")
    
    process_func = partial(
        process_single_sample_cpu,
        clips_dir=clips_dir,
        output_dir=output_dir,
        frame_height=frame_height,
        frame_width=frame_width
    )
    
    successful_dirs = []
    failed_count = 0
    
    with Pool(num_workers) as pool:
        if HAS_TQDM:
            results = tqdm(
                pool.imap_unordered(process_func, tasks, chunksize=10),
                total=len(tasks),
                desc="ğŸ¬ å¹¶è¡Œå¤„ç†",
                unit="video"
            )
        else:
            results = pool.imap_unordered(process_func, tasks, chunksize=10)
        
        checkpoint_interval = 1000
        processed_count = len(processed_samples)
        
        for success, sample_dir, error_msg in results:
            if success:
                successful_dirs.append(sample_dir)
                processed_count += 1
                
                if resume_from and processed_count % checkpoint_interval == 0:
                    with open(resume_from, 'w') as f:
                        json.dump({
                            'processed_indices': list(processed_samples) + list(range(len(successful_dirs))),
                            'timestamp': time.time()
                        }, f)
            else:
                failed_count += 1
                if error_msg and failed_count <= 10:
                    logger.warning(error_msg)
    
    logger.info(f"å¤„ç†å®Œæˆ: æˆåŠŸ {len(successful_dirs)}, å¤±è´¥ {failed_count}")
    return successful_dirs


def process_data_gpu(
    pairs: List[Dict[str, Any]],
    clips_dir: Path,
    output_dir: Path,
    gpu_ids: List[int],
    num_workers_per_gpu: int = 4,
    frame_height: int = 160,
    frame_width: int = 256,
    resume_from: Optional[Path] = None
) -> List[str]:
    """
    GPU å¤šè¿›ç¨‹å¤„ç†ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼šæå–æ‰€æœ‰å¸§ï¼‰
    
    æ³¨æ„: ä½¿ç”¨ CPU æå–æ‰€æœ‰å¸§ï¼ŒGPU ä»…ç”¨äºå…¶ä»–åŠ é€Ÿ
    
    Args:
        num_workers_per_gpu: æ¯ä¸ª GPU è¿è¡Œçš„ worker æ•°é‡
            - å¢åŠ å¯ä»¥æé«˜ GPU åˆ©ç”¨ç‡
            - ä½†æ¯ä¸ª worker ä¼šå ç”¨ GPU æ˜¾å­˜ï¼ˆ~500MBï¼‰
            - æ¨è: 2-8 ä¸ª worker/GPU
    """
    logger.info("=" * 60)
    logger.info("é˜¶æ®µ 2: æ•°æ®å‡†å¤‡ (GPU åŠ é€Ÿ)")
    logger.info("=" * 60)
    
    processed_samples = set()
    if resume_from and resume_from.exists():
        with open(resume_from) as f:
            checkpoint = json.load(f)
            processed_samples = set(checkpoint.get('processed_indices', []))
        logger.info(f"ä»æ–­ç‚¹æ¢å¤: å·²å¤„ç† {len(processed_samples)} ä¸ªæ ·æœ¬")
    
    tasks = [(i, pair) for i, pair in enumerate(pairs) if i not in processed_samples]
    
    if not tasks:
        logger.info("æ‰€æœ‰æ ·æœ¬å·²å¤„ç†å®Œæˆ")
        return []
    
    total_workers = len(gpu_ids) * num_workers_per_gpu
    logger.info(f"å¾…å¤„ç†: {len(tasks)} ä¸ªæ ·æœ¬")
    logger.info(f"GPU é…ç½®: {len(gpu_ids)} å— GPU Ã— {num_workers_per_gpu} workers = {total_workers} å¹¶è¡Œè¿›ç¨‹")
    
    manager = Manager()
    task_queue = manager.Queue()
    result_queue = manager.Queue()
    stop_event = manager.Event()
    
    for task in tasks:
        task_queue.put(task)
    
    # ä¸ºæ¯ä¸ª worker æ·»åŠ æ¯’ä¸¸ä¿¡å·
    for _ in range(total_workers):
        task_queue.put(None)
    
    # ä¸ºæ¯ä¸ª GPU åˆ›å»ºå¤šä¸ª worker
    workers = []
    for gpu_id in gpu_ids:
        for worker_id in range(num_workers_per_gpu):
            p = Process(
                target=gpu_worker,
                args=(gpu_id, task_queue, result_queue, clips_dir, output_dir,
                      frame_height, frame_width, stop_event),
                name=f"GPU-{gpu_id}-Worker-{worker_id}"
            )
            p.start()
            workers.append(p)
    
    successful_dirs = []
    failed_count = 0
    
    if HAS_TQDM:
        pbar = tqdm(total=len(tasks), desc="ğŸ¬ GPU å¤„ç†", unit="video")
    
    checkpoint_interval = 1000
    processed_count = len(processed_samples)
    
    for _ in range(len(tasks)):
        try:
            success, sample_dir, error_msg = result_queue.get(timeout=60)
            
            if success:
                successful_dirs.append(sample_dir)
                processed_count += 1
                
                if resume_from and processed_count % checkpoint_interval == 0:
                    with open(resume_from, 'w') as f:
                        json.dump({
                            'processed_indices': list(processed_samples) + 
                                               list(range(len(successful_dirs))),
                            'timestamp': time.time()
                        }, f)
            else:
                failed_count += 1
                if error_msg and failed_count <= 10:
                    logger.warning(error_msg)
            
            if HAS_TQDM:
                pbar.update(1)
        
        except Empty:
            logger.warning("ç»“æœé˜Ÿåˆ—è¶…æ—¶")
            break
    
    if HAS_TQDM:
        pbar.close()
    
    for p in workers:
        p.join(timeout=10)
    
    logger.info(f"å¤„ç†å®Œæˆ: æˆåŠŸ {len(successful_dirs)}, å¤±è´¥ {failed_count}")
    return successful_dirs


def generate_dataset_info(
    successful_dirs: List[str],
    output_dir: Path,
    split_mode: str = 'random',
    seed: int = 42
):
    """ç”Ÿæˆ dataset_info.json"""
    n = len(successful_dirs)
    
    if split_mode == 'all_train':
        train_dirs, val_dirs, test_dirs = successful_dirs, [], []
        logger.info(f"[all_train] å…¨éƒ¨ {n} ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†")
    elif split_mode == 'all_test':
        train_dirs, val_dirs, test_dirs = [], [], successful_dirs
        logger.info(f"[all_test] å…¨éƒ¨ {n} ä¸ªæ ·æœ¬ä½œä¸ºæµ‹è¯•é›†")
    else:
        random.seed(seed)
        random.shuffle(successful_dirs)
        n_test = max(1, int(n * 0.1))
        n_val = max(1, int(n * 0.1))
        n_train = n - n_test - n_val
        train_dirs = successful_dirs[:n_train]
        val_dirs = successful_dirs[n_train:n_train + n_val]
        test_dirs = successful_dirs[n_train + n_val:]
        logger.info(f"[random] éšæœºåˆ’åˆ†:")
    
    logger.info(f"  è®­ç»ƒé›†: {len(train_dirs)}")
    logger.info(f"  éªŒè¯é›†: {len(val_dirs)}")
    logger.info(f"  æµ‹è¯•é›†: {len(test_dirs)}")
    
    dataset_info = {
        "train": train_dirs,
        "val": val_dirs,
        "test": test_dirs
    }
    
    with open(output_dir / "dataset_info.json", "w") as f:
        json.dump(dataset_info, f, indent=2)
    
    logger.info(f"âœ“ dataset_info.json å·²ä¿å­˜")


def main():
    parser = argparse.ArgumentParser(
        description="CLIP4MC æ•°æ®å¤„ç†æµæ°´çº¿",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # æ¨¡å¼
    parser.add_argument("--mode", type=str, required=True,
                       choices=['full', 'clip', 'process'],
                       help="è¿è¡Œæ¨¡å¼: full=å®Œæ•´æµç¨‹, clip=ä»…åˆ‡ç‰‡, process=ä»…æ•°æ®å‡†å¤‡")
    
    # åˆ‡ç‰‡é˜¶æ®µå‚æ•°
    parser.add_argument("--videos-dir", type=Path, help="åŸå§‹è§†é¢‘ç›®å½•")
    parser.add_argument("--info-csv", type=Path, help="info.csv æ–‡ä»¶")
    parser.add_argument("--metadata", type=Path, help="CLIP4MC å…ƒæ•°æ® JSON")
    
    # æ•°æ®å‡†å¤‡é˜¶æ®µå‚æ•°
    parser.add_argument("--clips-dir", type=Path, help="è§†é¢‘åˆ‡ç‰‡ç›®å½•")
    parser.add_argument("--pairs-json", type=Path, help="text_video_pairs.json")
    
    # é€šç”¨å‚æ•°
    parser.add_argument("--output-dir", type=Path, required=True, help="è¾“å‡ºç›®å½•")
    
    # å¤„ç†å‚æ•°
    parser.add_argument("--num-workers", type=int, default=None,
                       help=f"CPU è¿›ç¨‹æ•°æˆ–æ¯GPU workeræ•° (é»˜è®¤: ç‰©ç†æ ¸å¿ƒæ•°ï¼Œå½“å‰ç³»ç»Ÿ: {cpu_count()})")
    parser.add_argument("--use-gpu", action='store_true', help="ä½¿ç”¨ GPU åŠ é€Ÿ")
    parser.add_argument("--gpu-ids", type=str, default="0",
                       help="GPU IDs (é€—å·åˆ†éš”)")
    parser.add_argument("--workers-per-gpu", type=int, default=None,
                       help="æ¯ä¸ªGPUçš„workeræ•° (é»˜è®¤: --num-workerså€¼ï¼Œæ¨è4-8)")
    parser.add_argument("--gpu-encode-clip", action='store_true',
                       help="åˆ‡ç‰‡é˜¶æ®µä½¿ç”¨ GPU ç¼–ç  (h264_nvencï¼Œéœ€é…åˆ --use-gpuï¼Œä¸æ¨è)")
    
    # åˆ‡ç‰‡ä¼˜åŒ–å‚æ•°
    parser.add_argument("--clip-preset", type=str, default="ultrafast",
                       choices=['ultrafast', 'superfast', 'veryfast', 'faster', 'fast', 'medium'],
                       help="ffmpeg ç¼–ç é€Ÿåº¦é¢„è®¾ (é»˜è®¤: ultrafastï¼Œæœ€å¿«)")
    parser.add_argument("--clip-crf", type=int, default=28,
                       help="ffmpeg è´¨é‡æ§åˆ¶ CRF (18-30ï¼Œè¶Šå¤§è¶Šå¿«ï¼Œé»˜è®¤: 28)")
    parser.add_argument("--clip-use-copy", action='store_true',
                       help="ç›´æ¥å¤åˆ¶æ¨¡å¼ (ä¸é‡æ–°ç¼–ç ï¼Œæå¿«ä½†ç²¾åº¦é™ä½)")
    parser.add_argument("--clip-height", type=int, default=0,
                       help="åˆ‡ç‰‡ç›®æ ‡åˆ†è¾¨ç‡é«˜åº¦ (0=ä¿æŒåŸæ ·ï¼Œé»˜è®¤: 0)")
    parser.add_argument("--clip-fps", type=float, default=0,
                       help="åˆ‡ç‰‡ç›®æ ‡å¸§ç‡ (0=ä¿æŒåŸæ ·ï¼Œé»˜è®¤: 0)")
    
    # å¸§æå–å‚æ•°ï¼ˆå®˜æ–¹ CLIP4MC æ ¼å¼ï¼šæå–æ‰€æœ‰å¸§ï¼‰
    parser.add_argument("--frame-height", type=int, default=160)
    parser.add_argument("--frame-width", type=int, default=256)
    
    parser.add_argument("--split-mode", type=str, default='random',
                       choices=['random', 'all_train', 'all_test'])
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--max-samples", type=int, default=None)
    
    parser.add_argument("--resume", action='store_true')
    parser.add_argument("--checkpoint-file", type=Path, default=Path("checkpoint.json"))
    
    args = parser.parse_args()
    
    # æ™ºèƒ½è®¾ç½® num_workers é»˜è®¤å€¼
    if args.num_workers is None:
        # å°è¯•è·å–ç‰©ç†æ ¸å¿ƒæ•°ï¼ˆé¿å…è¶…çº¿ç¨‹ï¼‰
        try:
            import psutil
            physical_cores = psutil.cpu_count(logical=False)
            if physical_cores and physical_cores > 0:
                args.num_workers = physical_cores
            else:
                # psutil è¿”å› Noneï¼Œä¿å®ˆä¼°è®¡
                args.num_workers = max(4, cpu_count() // 4)
        except ImportError:
            # å¦‚æœæ²¡æœ‰ psutilï¼Œä¿å®ˆä¼°è®¡
            # é¿å…ä½¿ç”¨è¿‡å¤šè¿›ç¨‹ï¼ˆè¶…çº¿ç¨‹ + èµ„æºç«äº‰ï¼‰
            logical_cores = cpu_count()
            if logical_cores >= 64:
                # å¤§å‹æœåŠ¡å™¨ï¼Œå‡è®¾è¶…çº¿ç¨‹ï¼Œé™¤ä»¥ 4 æ›´å®‰å…¨
                args.num_workers = max(16, logical_cores // 4)
            else:
                args.num_workers = max(4, logical_cores // 2)
        
        logger.info(f"è‡ªåŠ¨è®¾ç½® num_workers = {args.num_workers} (ç³»ç»Ÿé€»è¾‘æ ¸å¿ƒ: {cpu_count()})")
    
    # æ£€æŸ¥ä¾èµ–
    if not HAS_CV2:
        logger.error("éœ€è¦å®‰è£… opencv-python: pip install opencv-python")
        sys.exit(1)
    
    if args.use_gpu and not HAS_TORCH:
        logger.warning("æœªå®‰è£… PyTorchï¼Œå›é€€åˆ° CPU æ¨¡å¼")
        args.use_gpu = False
    
    args.output_dir.mkdir(parents=True, exist_ok=True)
    
    start_time = time.time()
    pairs = None
    clips_dir = None
    
    # è§£æ GPU IDs
    gpu_ids = [int(x.strip()) for x in args.gpu_ids.split(',')]
    
    # é˜¶æ®µ 1: åˆ‡ç‰‡
    if args.mode in ['full', 'clip']:
        if not args.videos_dir or not args.info_csv or not args.metadata:
            logger.error("--mode=clip/full éœ€è¦: --videos-dir, --info-csv, --metadata")
            sys.exit(1)
        
        # GPU ç¼–ç æœ‰å¹¶å‘é™åˆ¶ï¼Œè°ƒæ•´ workers
        clip_workers = args.num_workers
        use_gpu_encode = args.use_gpu and args.gpu_encode_clip
        
        if use_gpu_encode:
            # NVENC åªèƒ½åŒæ—¶å¤„ç† 2-3 ä¸ªä¼šè¯ï¼Œé™åˆ¶ workers
            max_gpu_encode_workers = len(gpu_ids) * 4  # æ¯ä¸ª GPU æœ€å¤š 4 ä¸ªå¹¶å‘
            if clip_workers > max_gpu_encode_workers:
                logger.warning(f"GPU ç¼–ç å¹¶å‘é™åˆ¶: workers {clip_workers} â†’ {max_gpu_encode_workers}")
                logger.warning(f"å»ºè®®: ä¸ä½¿ç”¨ --gpu-encode-clip (CPU ç¼–ç åœ¨å¹¶è¡Œåœºæ™¯ä¸‹æ›´å¿«)")
                clip_workers = max_gpu_encode_workers
        
        pairs, clips_dir = clip_videos(
            args.videos_dir,
            args.info_csv,
            args.metadata,
            args.output_dir,
            num_workers=clip_workers,
            use_gpu=use_gpu_encode,
            gpu_ids=gpu_ids,
            preset=args.clip_preset,
            crf=args.clip_crf,
            use_copy=args.clip_use_copy,
            target_height=args.clip_height,
            target_fps=args.clip_fps
        )
    
    # é˜¶æ®µ 2: æ•°æ®å‡†å¤‡
    if args.mode in ['full', 'process']:
        if args.mode == 'process':
            # ä»…å¤„ç†æ¨¡å¼ï¼ŒåŠ è½½å·²æœ‰çš„ pairs
            if not args.clips_dir or not args.pairs_json:
                logger.error("--mode=process éœ€è¦: --clips-dir, --pairs-json")
                sys.exit(1)
            
            clips_dir = args.clips_dir
            with open(args.pairs_json, encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"åŠ è½½äº† {len(pairs)} ä¸ªæ–‡æœ¬-è§†é¢‘å¯¹")
        
        if args.max_samples:
            pairs = pairs[:args.max_samples]
            logger.info(f"é™åˆ¶ä¸º {args.max_samples} ä¸ªæ ·æœ¬")
        
        # é€‰æ‹©å¤„ç†æ–¹å¼
        if args.use_gpu:
            gpu_ids = [int(x.strip()) for x in args.gpu_ids.split(',')]
            # å¦‚æœæŒ‡å®šäº† workers-per-gpuï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ num-workers
            workers_per_gpu = args.workers_per_gpu if args.workers_per_gpu else args.num_workers
            successful_dirs = process_data_gpu(
                pairs, clips_dir, args.output_dir, gpu_ids,
                num_workers_per_gpu=workers_per_gpu,
                frame_height=args.frame_height,
                frame_width=args.frame_width,
                resume_from=args.checkpoint_file if args.resume else None
            )
        else:
            successful_dirs = process_data_cpu(
                pairs, clips_dir, args.output_dir, args.num_workers,
                args.frame_height, args.frame_width,
                args.checkpoint_file if args.resume else None
            )
        
        if not successful_dirs:
            logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ ·æœ¬")
            sys.exit(1)
        
        # ç”Ÿæˆ dataset_info.json
        generate_dataset_info(successful_dirs, args.output_dir, args.split_mode, args.seed)
    
    elapsed = time.time() - start_time
    
    logger.info("\n" + "=" * 60)
    logger.info("âœ“ å¤„ç†å®Œæˆ")
    logger.info(f"  æ€»è€—æ—¶: {elapsed/3600:.2f} å°æ—¶")
    if args.mode in ['full', 'process']:
        logger.info(f"  å¹³å‡é€Ÿåº¦: {len(successful_dirs)/elapsed:.2f} è§†é¢‘/ç§’")
    logger.info(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()

