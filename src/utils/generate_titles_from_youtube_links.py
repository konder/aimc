#!/usr/bin/env python3
"""
ä» YouTube é“¾æ¥æ–‡ä»¶ç”Ÿæˆ CSVï¼ˆåŒ…å« title å’Œ statusï¼‰

ä½¿ç”¨æ–¹æ³•:
    python src/utils/update_youtube_titles_api.py \
        --input /Users/nanzhang/Downloads/youtube_links.txt \
        --output data/training/youtube_videos.csv \
        --api-key YOUR_API_KEY

ç¯å¢ƒå˜é‡:
    YOUTUBE_API_KEY: å¦‚æœä¸é€šè¿‡ --api-key ä¼ å…¥ï¼Œå¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡
"""

import csv
import re
import os
import time
import logging
from pathlib import Path
from typing import List, Dict
import argparse

import requests
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class YouTubeAPIClient:
    """YouTube Data API v3 å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ– YouTube API å®¢æˆ·ç«¯
        
        Args:
            api_key: YouTube Data API v3 å¯†é’¥
        """
        self.api_key = api_key
        self.base_url = "https://www.googleapis.com/youtube/v3/videos"
        self.quota_used = 0
        
        # API é…é¢ä¿¡æ¯
        # videos.list: æ¯æ¬¡è°ƒç”¨æ¶ˆè€— 1 quota
        # æ¯å¤©é»˜è®¤é…é¢: 10,000
        logger.info("YouTube API v3 å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
    def extract_video_id(self, url: str) -> str:
        """
        ä» YouTube URL æå– video ID
        
        Args:
            url: YouTube URL
        
        Returns:
            video_id: è§†é¢‘ IDï¼Œå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        url = url.strip()
        
        # æ”¯æŒå¤šç§ URL æ ¼å¼
        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/)([a-zA-Z0-9_-]{11})',
            r'youtube\.com/embed/([a-zA-Z0-9_-]{11})',
            r'youtube\.com/v/([a-zA-Z0-9_-]{11})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return ""
    
    def get_videos_info(self, video_ids: List[str]) -> Dict[str, Dict[str, str]]:
        """
        æ‰¹é‡è·å–è§†é¢‘ä¿¡æ¯
        
        YouTube API v3 æ”¯æŒä¸€æ¬¡æŸ¥è¯¢æœ€å¤š 50 ä¸ªè§†é¢‘
        
        Args:
            video_ids: è§†é¢‘ ID åˆ—è¡¨ (æœ€å¤š 50 ä¸ª)
        
        Returns:
            dict: {video_id: {'title': str, 'status': str}}
                status: 'True', 'private', 'unavailable'
        """
        if not video_ids:
            return {}
        
        if len(video_ids) > 50:
            logger.warning(f"è§†é¢‘æ•°é‡è¶…è¿‡ 50ï¼Œå°†åªå¤„ç†å‰ 50 ä¸ª")
            video_ids = video_ids[:50]
        
        # API è¯·æ±‚å‚æ•°
        params = {
            'part': 'snippet,status',
            'id': ','.join(video_ids),
            'key': self.api_key,
            'maxResults': 50
        }
        
        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            self.quota_used += 1
            
            if response.status_code == 200:
                data = response.json()
                results = {}
                
                # è§£æè¿”å›çš„è§†é¢‘ä¿¡æ¯
                for item in data.get('items', []):
                    video_id = item['id']
                    title = item['snippet']['title']
                    
                    # åˆ¤æ–­è§†é¢‘çŠ¶æ€
                    privacy_status = item['status']['privacyStatus']
                    
                    # æ˜ å°„çŠ¶æ€ (åŒ¹é… test2000_formatted.csv çš„æ ¼å¼)
                    if privacy_status == 'private':
                        status = 'private'
                    elif privacy_status in ['public', 'unlisted']:
                        status = 'True'
                    else:
                        status = privacy_status
                    
                    results[video_id] = {
                        'title': title,
                        'status': status
                    }
                
                # å¯¹äºæ²¡æœ‰è¿”å›çš„è§†é¢‘ï¼Œæ ‡è®°ä¸º unavailable
                for vid in video_ids:
                    if vid not in results:
                        results[vid] = {
                            'title': '',
                            'status': 'unavailable'
                        }
                
                return results
            
            elif response.status_code == 403:
                logger.error("API é…é¢å·²ç”¨å°½æˆ– API_KEY æ— æ•ˆ")
                raise Exception("API é…é¢å·²ç”¨å°½æˆ– API_KEY æ— æ•ˆ")
            
            elif response.status_code == 400:
                logger.error(f"API è¯·æ±‚é”™è¯¯: {response.text}")
                # è¿”å›ç©ºç»“æœï¼Œæ ‡è®°ä¸º unavailable
                return {vid: {'title': '', 'status': 'unavailable'} for vid in video_ids}
            
            else:
                logger.error(f"API è¯·æ±‚å¤±è´¥: {response.status_code}")
                return {vid: {'title': '', 'status': 'unavailable'} for vid in video_ids}
        
        except requests.exceptions.RequestException as e:
            logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
            return {vid: {'title': '', 'status': 'unavailable'} for vid in video_ids}
    
    def get_quota_info(self) -> Dict[str, int]:
        """è·å–é…é¢ä½¿ç”¨ä¿¡æ¯"""
        return {
            'used': self.quota_used,
            'remaining_estimate': 10000 - self.quota_used
        }


def generate_csv_from_links(
    input_txt: Path,
    output_csv: Path,
    api_key: str,
    batch_size: int = 50,
    delay: float = 0.1
) -> Dict[str, int]:
    """
    ä» YouTube é“¾æ¥æ–‡ä»¶ç”Ÿæˆ CSV
    
    Args:
        input_txt: è¾“å…¥æ–‡æœ¬æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ª YouTube URLï¼‰
        output_csv: è¾“å‡º CSV æ–‡ä»¶
        api_key: YouTube API å¯†é’¥
        batch_size: æ‰¹é‡æŸ¥è¯¢å¤§å° (æœ€å¤§ 50)
        delay: æ¯æ‰¹ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    # åˆå§‹åŒ– API å®¢æˆ·ç«¯
    client = YouTubeAPIClient(api_key)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total': 0,
        'available': 0,
        'unavailable': 0,
        'private': 0,
        'invalid_url': 0
    }
    
    # è¯»å– URL åˆ—è¡¨
    logger.info(f"è¯»å– URL åˆ—è¡¨: {input_txt}")
    urls = []
    
    with open(input_txt, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                urls.append(line)
    
    stats['total'] = len(urls)
    logger.info(f"å…± {stats['total']} ä¸ª URL")
    
    # æ‰¹é‡å¤„ç†
    batch_size = min(batch_size, 50)  # API é™åˆ¶æœ€å¤š 50
    csv_rows = []
    
    logger.info(f"å¼€å§‹æ‰¹é‡æŸ¥è¯¢ (batch_size={batch_size})")
    
    with tqdm(total=len(urls), desc="ğŸ”„ è·å–è§†é¢‘ä¿¡æ¯") as pbar:
        for i in range(0, len(urls), batch_size):
            batch_urls = urls[i:i+batch_size]
            
            # æå– video IDs
            url_to_vid = {}
            video_ids = []
            
            for url in batch_urls:
                vid = client.extract_video_id(url)
                if vid:
                    url_to_vid[url] = vid
                    video_ids.append(vid)
                else:
                    # æ— æ³•æå– video ID
                    csv_rows.append({
                        'url': url,
                        'title': '',
                        'status': 'unavailable'
                    })
                    stats['invalid_url'] += 1
            
            # è°ƒç”¨ API
            if video_ids:
                results = client.get_videos_info(video_ids)
                
                # æ„å»º CSV è¡Œ
                for url in batch_urls:
                    vid = url_to_vid.get(url)
                    if vid and vid in results:
                        info = results[vid]
                        csv_rows.append({
                            'url': url,
                            'title': info['title'],
                            'status': info['status']
                        })
                        
                        # ç»Ÿè®¡
                        if info['status'] == 'unavailable':
                            stats['unavailable'] += 1
                        elif info['status'] == 'True':
                            stats['available'] += 1
                        elif info['status'] == 'private':
                            stats['private'] += 1
            
            pbar.update(len(batch_urls))
            
            # å»¶è¿Ÿï¼ˆé¿å…è¿‡å¿«è¯·æ±‚ï¼‰
            if i + batch_size < len(urls):
                time.sleep(delay)
    
    # ä¿å­˜ç»“æœ
    logger.info(f"ä¿å­˜ç»“æœåˆ°: {output_csv}")
    with open(output_csv, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ['url', 'title', 'status']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(csv_rows)
    
    # é…é¢ä¿¡æ¯
    quota_info = client.get_quota_info()
    logger.info(f"API é…é¢ä½¿ç”¨: {quota_info['used']} æ¬¡è°ƒç”¨")
    logger.info(f"é¢„è®¡å‰©ä½™é…é¢: {quota_info['remaining_estimate']}")
    
    return stats


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="ä» YouTube é“¾æ¥æ–‡ä»¶ç”Ÿæˆ CSVï¼ˆåŒ…å« title å’Œ statusï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # ä½¿ç”¨ API_KEY å‚æ•°
    python src/utils/update_youtube_titles_api.py \\
        --input /Users/nanzhang/Downloads/youtube_links.txt \\
        --output data/training/youtube_videos.csv \\
        --api-key YOUR_API_KEY
    
    # ä½¿ç”¨ç¯å¢ƒå˜é‡
    export YOUTUBE_API_KEY="YOUR_API_KEY"
    python src/utils/update_youtube_titles_api.py \\
        --input /Users/nanzhang/Downloads/youtube_links.txt \\
        --output data/training/youtube_videos.csv
    
    # è‡ªå®šä¹‰æ‰¹é‡å¤§å°å’Œå»¶è¿Ÿ
    python src/utils/update_youtube_titles_api.py \\
        --input /Users/nanzhang/Downloads/youtube_links.txt \\
        --output data/training/youtube_videos.csv \\
        --api-key YOUR_API_KEY \\
        --batch-size 50 \\
        --delay 0.5

é…é¢è¯´æ˜:
    - æ¯æ¬¡ API è°ƒç”¨æ¶ˆè€— 1 quota
    - æ¯æ‰¹æœ€å¤šæŸ¥è¯¢ 50 ä¸ªè§†é¢‘
    - é»˜è®¤æ¯å¤©é…é¢: 10,000
    - 2196 ä¸ªè§†é¢‘çº¦éœ€ 44 æ¬¡è°ƒç”¨ (44 quota)
        """
    )
    
    parser.add_argument("--input", type=Path, required=True,
                       help="è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ª YouTube URLï¼‰")
    parser.add_argument("--output", type=Path, required=True,
                       help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--api-key", type=str,
                       help="YouTube Data API v3 å¯†é’¥ (æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ YOUTUBE_API_KEY)")
    parser.add_argument("--batch-size", type=int, default=50,
                       help="æ‰¹é‡æŸ¥è¯¢å¤§å° (é»˜è®¤: 50ï¼Œæœ€å¤§: 50)")
    parser.add_argument("--delay", type=float, default=0.1,
                       help="æ¯æ‰¹ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤: 0.1ï¼‰")
    
    args = parser.parse_args()
    
    # è·å– API_KEY
    api_key = args.api_key or os.getenv('YOUTUBE_API_KEY')
    
    if not api_key:
        logger.error("æœªæä¾› API_KEYï¼Œè¯·ä½¿ç”¨ --api-key å‚æ•°æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ YOUTUBE_API_KEY")
        return 1
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not args.input.exists():
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    args.output.parent.mkdir(parents=True, exist_ok=True)
    
    # æ‰§è¡Œç”Ÿæˆ
    logger.info("=" * 60)
    logger.info("å¼€å§‹ä½¿ç”¨ YouTube Data API v3 è·å–è§†é¢‘ä¿¡æ¯")
    logger.info("=" * 60)
    
    try:
        stats = generate_csv_from_links(
            input_txt=args.input,
            output_csv=args.output,
            api_key=api_key,
            batch_size=args.batch_size,
            delay=args.delay
        )
        
        # æ‰“å°ç»Ÿè®¡
        logger.info("\n" + "=" * 60)
        logger.info("CSV ç”Ÿæˆå®Œæˆ")
        logger.info("=" * 60)
        logger.info(f"æ€»æ•°:         {stats['total']}")
        logger.info(f"å¯ç”¨:         {stats['available']}")
        logger.info(f"ä¸å¯ç”¨:       {stats['unavailable']}")
        logger.info(f"ç§å¯†:         {stats['private']}")
        logger.info(f"æ— æ•ˆURL:      {stats['invalid_url']}")
        logger.info("=" * 60)
        
        # éªŒè¯è¡Œæ•°
        with open(args.output, 'r', encoding='utf-8') as f:
            line_count = sum(1 for line in f) - 1  # å‡å»è¡¨å¤´
        
        logger.info(f"\nâœ… CSV æ–‡ä»¶å·²ç”Ÿæˆ: {args.output}")
        logger.info(f"âœ… æ€»è¡Œæ•°: {line_count} è¡Œï¼ˆä¸å«è¡¨å¤´ï¼‰")
        
        if line_count >= 2196:
            logger.info(f"âœ… æ»¡è¶³è¦æ±‚ï¼šè‡³å°‘ 2196 è¡Œ")
        else:
            logger.warning(f"âš ï¸  è­¦å‘Šï¼šåªæœ‰ {line_count} è¡Œï¼Œå°‘äºé¢„æœŸçš„ 2196 è¡Œ")
        
        return 0
    
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
