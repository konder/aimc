#!/usr/bin/env python3
"""
FFmpeg Video Processing Pipeline - Pure FFmpeg Implementation
"""

import json
import pickle
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Iterator, Any
from dataclasses import dataclass
from collections import OrderedDict
import time
from multiprocessing import Pool
from functools import partial
import subprocess
import tempfile

import numpy as np
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(processName)s] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================
# Data Structures
# ============================================================

@dataclass
class VideoSegment:
    """è§†é¢‘ç‰‡æ®µå…ƒæ•°æ®"""
    vid: str                    # è§†é¢‘ ID
    video_path: Path            # è§†é¢‘æ–‡ä»¶è·¯å¾„
    start_time: float           # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end_time: float             # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    transcript: str             # æ–‡æœ¬æè¿°
    size: List[float] = None    # ç›®æ ‡ç‰©ä½“å¤§å°ï¼ˆ16 ä¸ªå€¼ï¼‰
    data_type: str = 'train'    # æ•°æ®ç±»å‹ï¼š'train', 'val', 'test'
    text_input_path: str = None # text_input.pkl æ–‡ä»¶è·¯å¾„ï¼ˆé¢„ç”Ÿæˆï¼‰
    
    @property
    def duration(self) -> float:
        """ç‰‡æ®µæ—¶é•¿"""
        return self.end_time - self.start_time
    
    def __repr__(self):
        return f"VideoSegment(vid={self.vid}, {self.start_time:.1f}s-{self.end_time:.1f}s, type={self.data_type})"


@dataclass
class ProcessedSample:
    """å¤„ç†åçš„æ ·æœ¬"""
    index: int
    vid: str
    frames: np.ndarray          # (N, H, W, 3) uint8
    tokens: np.ndarray          # (77,) int64
    size: List[float]           # [16] float
    sample_dir: Path
    success: bool
    data_type: str = 'train'    # æ•°æ®ç±»å‹ï¼š'train', 'val', 'test'
    error_msg: Optional[str] = None
    error_reason: Optional[str] = None  # å¤±è´¥åŸå› ä»£ç 
    
    # é¢å¤–å…ƒæ•°æ®ï¼ˆç”¨äºå¤±è´¥åˆ†æï¼‰
    video_path: Optional[str] = None
    transcript: Optional[str] = None
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    text_input_path: Optional[str] = None
    
    @property
    def num_frames(self) -> int:
        return self.frames.shape[0] if self.frames is not None else 0
    
    @property
    def duration(self) -> float:
        if self.start_time is not None and self.end_time is not None:
            return self.end_time - self.start_time
        return 0.0


# ============================================================
# Pipeline Components
# ============================================================

class VideoDataSource:
    """
    è§†é¢‘æ•°æ®æº (Data Source)
    
    è´Ÿè´£ï¼š
    1. åŠ è½½é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON
    2. ç”Ÿæˆ VideoSegment åˆ—è¡¨
    
    å…ƒæ•°æ®æ ¼å¼ï¼š
    [
        {
            "vid": "abc123",
            "video_path": "/path/to/video.mp4",
            "start_time": 10.5,
            "end_time": 15.3,
            "transcript": "player mining diamond",
            "size": [0.3, 0.4, 0.5, ...],  # 16 ä¸ªå€¼
            "data_type": "train",  # 'train', 'val', 'test'
            "text_input_path": "/path/to/abc123_text_input.pkl"  # é¢„ç”Ÿæˆçš„ text_input.pkl
        },
        ...
    ]
    """
    
    def __init__(self, metadata_path: Path):
        """
        Args:
            metadata_path: é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON æ–‡ä»¶
                          åŒ…å« vid, video_path, start_time, end_time, transcript, size
        """
        self.metadata_path = Path(metadata_path)
        self.segments: List[VideoSegment] = []
        
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½å…ƒæ•°æ®å¹¶ç”Ÿæˆ VideoSegment åˆ—è¡¨"""
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        logger.info(f"åŠ è½½äº† {len(metadata)} æ¡å…ƒæ•°æ®")
        
        # ç›´æ¥ä»å…ƒæ•°æ®åˆ›å»º VideoSegment
        success_count = 0
        for item in metadata:
            vid = item.get('vid', '')
            video_path_str = item.get('video_path', '')
            
            if not vid or not video_path_str:
                logger.warning(f"è·³è¿‡æ— æ•ˆæ¡ç›®: vid={vid}, video_path={video_path_str}")
                continue
            
            video_path = Path(video_path_str)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not video_path.exists():
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                continue
            
            segment = VideoSegment(
                vid=vid,
                video_path=video_path,
                start_time=item.get('start_time', 0),
                end_time=item.get('end_time', 0),
                transcript=item.get('transcript', ''),
                size=item.get('size', []),
                data_type=item.get('data_type', 'train'),  # é»˜è®¤ä¸º train
                text_input_path=item.get('text_input_path', None)
            )
            self.segments.append(segment)
            success_count += 1
        
        logger.info(f"åŠ è½½æˆåŠŸ: {success_count}/{len(metadata)} ä¸ªè§†é¢‘ç‰‡æ®µ")
    
    def __len__(self) -> int:
        return len(self.segments)
    
    def __getitem__(self, index: int) -> VideoSegment:
        return self.segments[index]
    
    def __iter__(self) -> Iterator[VideoSegment]:
        return iter(self.segments)


class FFmpegProcessor:
    """
    FFmpeg è§†é¢‘å¤„ç†å™¨ (Processor) - çº¯ FFmpeg å®ç°
    
    è´Ÿè´£ï¼š
    1. ä½¿ç”¨ FFmpeg æå–è§†é¢‘å¸§
    2. æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ (NVDEC)
    3. Resize åˆ°ç›®æ ‡å°ºå¯¸
    
    æ”¯æŒä¸‰ç§æ¨¡å¼:
        - cpu: çº¯ CPU è§£ç  + CPU ç¼©æ”¾
        - gpu: å…¨ GPUï¼ˆGPU è§£ç  + GPU ç¼©æ”¾ scale_cudaï¼‰
        - mixed: GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæ¨èï¼Œå…¼å®¹æ€§æœ€å¥½ï¼‰
    """
    
    def __init__(
        self,
        frame_height: int = 160,
        frame_width: int = 256,
        target_fps: int = None,
        device_id: int = 0,
        decode_mode: str = 'mixed'
    ):
        """
        Args:
            frame_height: ç›®æ ‡å¸§é«˜åº¦
            frame_width: ç›®æ ‡å¸§å®½åº¦
            target_fps: ç›®æ ‡å¸§ç‡ (None=ä¿æŒåŸå§‹å¸§ç‡, æ¨è10-20ä»¥èŠ‚çœç©ºé—´)
            device_id: GPU IDï¼ˆç”¨äº NVDECï¼‰
            decode_mode: è§£ç æ¨¡å¼ ('cpu', 'gpu', 'mixed')
                - 'cpu': çº¯ CPU è§£ç  + CPU ç¼©æ”¾
                - 'gpu': å…¨ GPUï¼ˆGPU è§£ç  + GPU ç¼©æ”¾ scale_cudaï¼‰
                - 'mixed': GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæ¨èï¼Œå…¼å®¹æ€§æœ€å¥½ï¼‰
        """
        self.frame_height = frame_height
        self.frame_width = frame_width
        self.target_fps = target_fps
        self.device_id = device_id
        self.decode_mode = decode_mode.lower()
        
        # éªŒè¯æ¨¡å¼
        if self.decode_mode not in ('cpu', 'gpu', 'mixed'):
            raise ValueError(f"æ— æ•ˆçš„ decode_mode: {decode_mode}ï¼Œå¿…é¡»æ˜¯ 'cpu', 'gpu', æˆ– 'mixed'")
        
        # æ£€æŸ¥ GPU å¯ç”¨æ€§
        self.gpu_available = False
        self.scale_cuda_available = False
        
        if self.decode_mode in ('gpu', 'mixed'):
            self.gpu_available = self._check_gpu_support()
            
            if self.decode_mode == 'gpu':
                # GPU æ¨¡å¼éœ€è¦æ£€æŸ¥ scale_cuda
                if not self.gpu_available:
                    raise RuntimeError("GPU æ¨¡å¼å·²å¯ç”¨ï¼Œä½† FFmpeg CUDA æ”¯æŒä¸å¯ç”¨ï¼")
                self.scale_cuda_available = self._check_scale_cuda()
                if not self.scale_cuda_available:
                    logger.warning("scale_cuda æ»¤é•œä¸å¯ç”¨ï¼ŒGPU æ¨¡å¼å°†å›é€€åˆ° Mixed æ¨¡å¼")
                    self.decode_mode = 'mixed'
            
            if self.decode_mode == 'mixed' and not self.gpu_available:
                logger.warning("GPU ä¸å¯ç”¨ï¼ŒMixed æ¨¡å¼å°†å›é€€åˆ° CPU æ¨¡å¼")
                self.decode_mode = 'cpu'
        
        # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
        mode_desc = {
            'cpu': 'CPU (CPUè§£ç  + CPUç¼©æ”¾)',
            'gpu': 'GPU (GPUè§£ç  + GPUç¼©æ”¾ scale_cuda)',
            'mixed': f"Mixed (GPUè§£ç  + CPUç¼©æ”¾) [GPU={'å¯ç”¨' if self.gpu_available else 'ä¸å¯ç”¨'}]"
        }
        logger.info(f"FFmpegProcessor åˆå§‹åŒ–: {mode_desc[self.decode_mode]} (device={device_id})")
    
    def _check_gpu_support(self) -> bool:
        """
        æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ
        
        Returns:
            bool: æ˜¯å¦æ”¯æŒ GPU
        """
        try:
            # æ£€æŸ¥ ffmpeg æ˜¯å¦æ”¯æŒ cuda hwaccel
            result = subprocess.run(
                ['ffmpeg', '-hwaccels'],
                stdin=subprocess.DEVNULL,  # é˜²æ­¢ç»§æ‰¿stdinï¼Œé¿å…å ç”¨ç»ˆç«¯
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=5,
                text=True
            )
            
            if 'cuda' in result.stdout.lower():
                return True
            
            return False
        except Exception:
            return False
    
    def _check_scale_cuda(self) -> bool:
        """
        æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ scale_cuda æ»¤é•œ
        
        Returns:
            bool: æ˜¯å¦æ”¯æŒ scale_cuda
        """
        try:
            result = subprocess.run(
                ['ffmpeg', '-filters'],
                stdin=subprocess.DEVNULL,  # é˜²æ­¢ç»§æ‰¿stdinï¼Œé¿å…å ç”¨ç»ˆç«¯
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=5,
                text=True
            )
            
            if 'scale_cuda' in result.stdout.lower():
                return True
            
            return False
        except Exception:
            return False
    
    def extract_frames(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨ FFmpeg æå–è§†é¢‘å¸§ (æ ¸å¿ƒæ–¹æ³•)
        
        æ ¹æ® decode_mode é€‰æ‹©è§£ç ç­–ç•¥:
            - cpu: çº¯ CPU è§£ç  + CPU ç¼©æ”¾
            - gpu: GPU è§£ç  + GPU ç¼©æ”¾ (scale_cuda)
            - mixed: GPU è§£ç  + CPU ç¼©æ”¾
        
        Args:
            segment: è§†é¢‘ç‰‡æ®µä¿¡æ¯
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼
        """
        # CPU æ¨¡å¼ï¼šçº¯ CPU
        if self.decode_mode == 'cpu':
            return self._extract_frames_cpu(segment)
        
        # GPU æ¨¡å¼ï¼šGPU è§£ç  + GPU ç¼©æ”¾ (scale_cuda)
        if self.decode_mode == 'gpu':
            return self._try_gpu_full(segment)
        
        # Mixed æ¨¡å¼ï¼šGPU è§£ç  + CPU ç¼©æ”¾
        if self.decode_mode == 'mixed':
            return self._try_gpu_mixed(segment)
        
        # ä¸åº”è¯¥åˆ°è¿™é‡Œ
        return self._extract_frames_cpu(segment)
    
    def _try_gpu_decode(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        [å·²åºŸå¼ƒ] æ—§çš„ GPU è§£ç æ–¹æ³•ï¼Œä¿ç•™ä»¥é˜²å¼•ç”¨
        ç°åœ¨ä½¿ç”¨ _try_gpu_full å’Œ _try_gpu_mixed
        """
        return self._try_gpu_mixed(segment)
    
    def _try_gpu_full(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        å…¨ GPU æ¨¡å¼ï¼šGPU è§£ç  + GPU ç¼©æ”¾ (scale_cuda)
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            duration = segment.end_time - segment.start_time
            
            # æ„å»ºè§†é¢‘æ»¤é•œ
            vf_filters = []
            if self.target_fps:
                vf_filters.append(f'fps={self.target_fps}')
            vf_filters.append(f'scale_cuda={self.frame_width}:{self.frame_height},hwdownload,format=nv12')
            vf_str = ','.join(vf_filters)
            
            # å…¨ GPU æµç¨‹ï¼šGPU è§£ç  â†’ GPU ç¼©æ”¾ â†’ ä¼ å› CPU
            cmd = [
                'ffmpeg',
                '-hwaccel', 'cuda',
                '-hwaccel_device', str(self.device_id),
                '-hwaccel_output_format', 'cuda',
                '-ss', str(segment.start_time),
                '-i', str(segment.video_path),
                '-t', str(duration),
                '-vf', vf_str,
                '-f', 'rawvideo',
                '-pix_fmt', 'rgb24',
                '-loglevel', 'error',
                'pipe:1'
            ]
            
            result = subprocess.run(
                cmd,
                stdin=subprocess.DEVNULL,  # é˜²æ­¢ç»§æ‰¿stdinï¼Œé¿å…å ç”¨ç»ˆç«¯
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            if result.returncode == 0 and len(result.stdout) > 0:
                raw_data = result.stdout
                frame_size = self.frame_height * self.frame_width * 3
                
                if len(raw_data) >= frame_size:
                    num_frames = len(raw_data) // frame_size
                    if num_frames > 0:
                        frames = np.frombuffer(raw_data[:num_frames * frame_size], dtype=np.uint8)
                        frames = frames.reshape((num_frames, self.frame_height, self.frame_width, 3))
                        return frames
            
            return None
        
        except subprocess.TimeoutExpired:
            return None
        except Exception:
            return None
    
    def _try_gpu_mixed(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        Mixed æ¨¡å¼ï¼šGPU è§£ç  + CPU ç¼©æ”¾
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            duration = segment.end_time - segment.start_time
            
            # æ„å»ºè§†é¢‘æ»¤é•œ
            vf_filters = ['hwdownload', 'format=nv12']
            if self.target_fps:
                vf_filters.append(f'fps={self.target_fps}')
            vf_filters.append(f'scale={self.frame_width}:{self.frame_height}')
            vf_str = ','.join(vf_filters)
            
            # GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆå…¼å®¹æ€§æœ€å¥½ï¼‰
            cmd = [
                'ffmpeg',
                '-hwaccel', 'cuda',
                '-hwaccel_device', str(self.device_id),
                '-hwaccel_output_format', 'cuda',
                '-ss', str(segment.start_time),
                '-i', str(segment.video_path),
                '-t', str(duration),
                '-vf', vf_str,
                '-f', 'rawvideo',
                '-pix_fmt', 'rgb24',
                '-loglevel', 'error',
                'pipe:1'
            ]
            
            result = subprocess.run(
                cmd,
                stdin=subprocess.DEVNULL,  # é˜²æ­¢ç»§æ‰¿stdinï¼Œé¿å…å ç”¨ç»ˆç«¯
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            if result.returncode == 0 and len(result.stdout) > 0:
                raw_data = result.stdout
                frame_size = self.frame_height * self.frame_width * 3
                
                if len(raw_data) >= frame_size:
                    num_frames = len(raw_data) // frame_size
                    if num_frames > 0:
                        frames = np.frombuffer(raw_data[:num_frames * frame_size], dtype=np.uint8)
                        frames = frames.reshape((num_frames, self.frame_height, self.frame_width, 3))
                        return frames
            
            return None
        
        except subprocess.TimeoutExpired:
            return None
        except Exception:
            return None
    
    def _extract_frames_cpu(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨ CPU æ¨¡å¼æå–è§†é¢‘å¸§ï¼ˆGPU å¤±è´¥æ—¶çš„å¤‡é€‰ï¼‰
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼
        """
        try:
            duration = segment.end_time - segment.start_time
            
            # æ„å»ºè§†é¢‘æ»¤é•œ
            vf_filters = []
            if self.target_fps:
                vf_filters.append(f'fps={self.target_fps}')
            vf_filters.append(f'scale={self.frame_width}:{self.frame_height}')
            vf_str = ','.join(vf_filters)
            
            cmd = [
                'ffmpeg',
                '-ss', str(segment.start_time),
                '-i', str(segment.video_path),
                '-t', str(duration),
                '-vf', vf_str,
                '-f', 'rawvideo',
                '-pix_fmt', 'rgb24',
                '-loglevel', 'error',
                'pipe:1'
            ]
            
            result = subprocess.run(
                cmd,
                stdin=subprocess.DEVNULL,  # é˜²æ­¢ç»§æ‰¿stdinï¼Œé¿å…å ç”¨ç»ˆç«¯
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            if result.returncode != 0:
                return None
            
            raw_data = result.stdout
            frame_size = self.frame_height * self.frame_width * 3
            
            if len(raw_data) < frame_size:
                return None
            
            num_frames = len(raw_data) // frame_size
            if num_frames == 0:
                return None
            
            frames = np.frombuffer(raw_data[:num_frames * frame_size], dtype=np.uint8)
            frames = frames.reshape((num_frames, self.frame_height, self.frame_width, 3))
            
            return frames
        
        except Exception as e:
            logger.error(f"{segment.vid}: CPU è§£ç å¤±è´¥ - {str(e)}")
            return None
    
    def process_segment(self, index: int, segment: VideoSegment) -> ProcessedSample:
        """
        å¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ
        
        Returns:
            ProcessedSample: åŒ…å«å¤„ç†ç»“æœçš„æ•°æ®ç»“æ„
        """
        # åŸºç¡€å…ƒæ•°æ®ï¼ˆç”¨äºå¤±è´¥åˆ†æï¼‰
        base_metadata = {
            'video_path': str(segment.video_path),
            'transcript': segment.transcript,
            'start_time': segment.start_time,
            'end_time': segment.end_time,
            'text_input_path': segment.text_input_path
        }
        
        try:
            # 1. æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not segment.video_path.exists():
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg=f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {segment.video_path}",
                    error_reason="video_file_not_found",
                    **base_metadata
                )
            
            # 2. æå–å¸§
            frames = self.extract_frames(segment)
            if frames is None or len(frames) == 0:
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg=f"FFmpegå¸§æå–å¤±è´¥ï¼ˆå¯èƒ½åŸå› ï¼šè§†é¢‘æŸåã€ç¼–ç ä¸æ”¯æŒã€æ—¶é—´èŒƒå›´æ— æ•ˆï¼‰",
                    error_reason="frame_extraction_failed",
                    **base_metadata
                )
            
            # 3. æ£€æŸ¥ text_input_path
            if not segment.text_input_path:
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg="å…ƒæ•°æ®ä¸­ç¼ºå°‘ text_input_path å­—æ®µ",
                    error_reason="missing_text_input_path",
                    **base_metadata
                )
            
            text_input_path = Path(segment.text_input_path)
            if not text_input_path.exists():
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg=f"text_input.pkl æ–‡ä»¶ä¸å­˜åœ¨: {text_input_path}",
                    error_reason="text_input_file_not_found",
                    **base_metadata
                )
            
            # 4. å¤„ç† size æ•°æ®
            # æ³¨æ„ï¼šå®˜æ–¹ CLIP4MC çš„ size æ•°ç»„å›ºå®šä¸º 16 ä¸ªå€¼
            # è¿™äº›å€¼å¯¹åº” DataLoader åŠ¨æ€é‡‡æ ·çš„ 16 å¸§ï¼Œè€Œéå®é™…æå–çš„æ‰€æœ‰å¸§
            # å› æ­¤ç›´æ¥ä½¿ç”¨å…ƒæ•°æ®ä¸­çš„ sizeï¼Œä¸åšä»»ä½•å¤„ç†
            size_values = segment.size if segment.size else []
            
            if not size_values or len(size_values) == 0:
                # å…ƒæ•°æ®æœªæä¾› sizeï¼Œä½¿ç”¨å ä½ç¬¦ï¼ˆ16 ä¸ªå€¼ï¼‰
                size_values = [0] * 16
            
            return ProcessedSample(
                index=index,
                vid=segment.vid,
                frames=frames,
                tokens=text_input_path,  # å­˜å‚¨ text_input.pkl è·¯å¾„ï¼Œç¨åæ‹·è´
                size=size_values,
                sample_dir=None,  # ç¨åç”± Saver å¡«å……
                success=True,
                data_type=segment.data_type,
                **base_metadata
            )
        
        except Exception as e:
            return ProcessedSample(
                index=index,
                vid=segment.vid,
                frames=None,
                tokens=None,
                size=None,
                sample_dir=None,
                success=False,
                data_type=segment.data_type,
                error_msg=f"å¤„ç†å¼‚å¸¸: {str(e)}",
                error_reason="unknown_exception",
                **base_metadata
            )


class SampleSaver:
    """
    æ ·æœ¬ä¿å­˜å™¨ (Saver)
    
    è´Ÿè´£ï¼š
    1. ä¿å­˜ video_input.pkl
    2. æ‹·è´é¢„ç”Ÿæˆçš„ text_input.pkl
    3. ä¿å­˜ size.json
    """
    
    def __init__(self, output_dir: Path):
        """
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def save_sample(self, sample: ProcessedSample) -> bool:
        """
        ä¿å­˜å•ä¸ªæ ·æœ¬
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not sample.success:
            return False
        
        try:
            import shutil
            
            # åˆ›å»ºæ ·æœ¬ç›®å½•
            sample_dir = self.output_dir / f"sample_{sample.index:06d}_{sample.vid}"
            sample_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ video_input.pkl
            with open(sample_dir / "video_input.pkl", "wb") as f:
                pickle.dump(sample.frames, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            # æ‹·è´é¢„ç”Ÿæˆçš„ text_input.pkl
            # sample.tokens ç°åœ¨å­˜å‚¨çš„æ˜¯ text_input.pkl çš„è·¯å¾„
            text_input_src = sample.tokens  # è¿™æ˜¯ä¸€ä¸ª Path å¯¹è±¡
            if isinstance(text_input_src, (str, Path)):
                text_input_src = Path(text_input_src)
                if text_input_src.exists():
                    shutil.copy2(text_input_src, sample_dir / "text_input.pkl")
                else:
                    logger.error(f"text_input.pkl æºæ–‡ä»¶ä¸å­˜åœ¨: {text_input_src}")
                    return False
            else:
                logger.error(f"text_input.pkl è·¯å¾„æ ¼å¼é”™è¯¯: {type(text_input_src)}")
                return False
            
            # ä¿å­˜ size.json
            with open(sample_dir / "size.json", "w") as f:
                json.dump(sample.size, f)
            
            # æ›´æ–° sample_dir
            sample.sample_dir = sample_dir
            
            return True
        
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥ {sample.vid}: {str(e)}")
            sample.success = False
            sample.error_msg = f"ä¿å­˜å¤±è´¥: {str(e)}"
            return False


# å…¨å±€å˜é‡ï¼ˆç”¨äºè¿›ç¨‹æ± åˆå§‹åŒ–ï¼‰
_worker_processor = None
_worker_saver = None


def _init_worker(output_dir: Path, frame_size: Tuple[int, int], target_fps: int, device_id: int, decode_mode: str):
    """
    åˆå§‹åŒ– worker è¿›ç¨‹ï¼ˆæ¯ä¸ªè¿›ç¨‹åªè°ƒç”¨ä¸€æ¬¡ï¼‰
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        frame_size: (height, width)
        target_fps: ç›®æ ‡å¸§ç‡
        device_id: è®¾å¤‡ ID
        decode_mode: è§£ç æ¨¡å¼ ('cpu', 'gpu', 'mixed')
    """
    global _worker_processor, _worker_saver
    
    _worker_processor = FFmpegProcessor(
        frame_height=frame_size[0],
        frame_width=frame_size[1],
        target_fps=target_fps,
        device_id=device_id,
        decode_mode=decode_mode
    )
    
    _worker_saver = SampleSaver(output_dir=output_dir)


def _process_single_segment_worker(args: Tuple[int, VideoSegment]) -> Dict[str, Any]:
    """
    å¤šè¿›ç¨‹ worker å‡½æ•°ï¼šå¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ
    
    Args:
        args: (index, segment)
    
    Returns:
        dict: å¤„ç†ç»“æœï¼ˆåŒ…å«è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯ï¼‰
    """
    global _worker_processor, _worker_saver
    
    index, segment = args
    
    # ä½¿ç”¨å·²åˆå§‹åŒ–çš„ processor å’Œ saver
    sample = _worker_processor.process_segment(index, segment)
    
    # ä¿å­˜
    if sample.success:
        success = _worker_saver.save_sample(sample)
        if not success:
            sample.success = False
            sample.error_reason = "save_failed"
            sample.error_msg = f"ä¿å­˜å¤±è´¥: {sample.error_msg}"
    
    # è¿”å›ç»“æœï¼ˆåŒ…å«è¯¦ç»†çš„å¤±è´¥ä¿¡æ¯ï¼‰
    result = {
        'index': index,
        'vid': segment.vid,
        'success': sample.success,
        'error_msg': sample.error_msg,
        'error_reason': sample.error_reason,
        'sample_dir': str(sample.sample_dir) if sample.sample_dir else None,
        'data_type': segment.data_type
    }
    
    # å¦‚æœå¤±è´¥ï¼Œæ·»åŠ é¢å¤–çš„å…ƒæ•°æ®ç”¨äºåˆ†æ
    if not sample.success:
        result.update({
            'video_path': sample.video_path,
            'transcript': sample.transcript,
            'start_time': sample.start_time,
            'end_time': sample.end_time,
            'duration': sample.duration,
            'text_input_path': sample.text_input_path
        })
    
    return result


# ============================================================
# Pipeline & Iterator
# ============================================================

class FFmpegPipeline:
    """
    FFmpeg è§†é¢‘å¤„ç† Pipeline (ç±»ä¼¼ DALI Pipeline)
    
    æ¶æ„ï¼š
        VideoDataSource -> FFmpegProcessor -> SampleSaver -> Iterator
    
    ç‰¹ç‚¹ï¼š
        - çº¯ FFmpeg å®ç°
        - æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ (NVDEC)
        - æ”¯æŒæ‰€æœ‰è§†é¢‘æ ¼å¼ (H.264, VP9, HEVC, etc.)
        - Pipeline æ¨¡å¼è®¾è®¡
        - æ”¯æŒæ‰¹é‡è¿­ä»£
        - è¿›åº¦è·Ÿè¸ª
        - ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(
        self,
        metadata_path: Path,
        output_dir: Path,
        batch_size: int = 1,
        frame_size: Tuple[int, int] = (160, 256),
        target_fps: int = None,
        device_id: int = 0,
        decode_mode: str = 'mixed',
        num_workers: int = 1,
        show_progress: bool = True
    ):
        """
        Args:
            metadata_path: é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSONï¼ˆåŒ…å« vid, video_path, start_time, end_time, size, data_type, text_input_pathï¼‰
            output_dir: è¾“å‡ºç›®å½•
            batch_size: æ‰¹é‡å¤§å°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼Œå®é™…ä»æ˜¯é€ä¸ªå¤„ç†ï¼‰
            frame_size: (height, width) ç›®æ ‡å¸§å°ºå¯¸
            target_fps: ç›®æ ‡å¸§ç‡ï¼ˆNone=ä¿æŒåŸå§‹å¸§ç‡ï¼Œæ¨è10-20ä»¥èŠ‚çœç©ºé—´ï¼‰
            device_id: GPU IDï¼ˆç”¨äº FFmpeg NVDECï¼‰
            decode_mode: è§£ç æ¨¡å¼ ('cpu', 'gpu', 'mixed')
                - 'cpu': çº¯ CPU è§£ç  + CPU ç¼©æ”¾
                - 'gpu': å…¨ GPU (GPUè§£ç  + GPUç¼©æ”¾ scale_cuda)
                - 'mixed': GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæ¨èï¼‰
            num_workers: å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤: 1ï¼Œå•çº¿ç¨‹ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        """
        self.batch_size = batch_size
        self.show_progress = show_progress
        self.num_workers = num_workers
        self.frame_size = frame_size
        self.target_fps = target_fps
        self.device_id = device_id
        self.decode_mode = decode_mode.lower()
        
        # éªŒè¯æ¨¡å¼
        if self.decode_mode not in ('cpu', 'gpu', 'mixed'):
            raise ValueError(f"æ— æ•ˆçš„ decode_mode: {decode_mode}ï¼Œå¿…é¡»æ˜¯ 'cpu', 'gpu', æˆ– 'mixed'")
        
        # 1. åˆå§‹åŒ–ç»„ä»¶
        logger.info("=" * 60)
        logger.info("åˆå§‹åŒ– FFmpeg Pipeline")
        logger.info("=" * 60)
        
        self.data_source = VideoDataSource(metadata_path=metadata_path)
        
        # å•è¿›ç¨‹æ¨¡å¼ï¼šåˆå§‹åŒ– processor
        if num_workers == 1:
            self.processor = FFmpegProcessor(
                frame_height=frame_size[0],
                frame_width=frame_size[1],
                target_fps=target_fps,
                device_id=device_id,
                decode_mode=decode_mode
            )
        else:
            # å¤šè¿›ç¨‹æ¨¡å¼ï¼šä¸åœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ– processorï¼ˆæ¯ä¸ªå­è¿›ç¨‹ä¼šåˆå§‹åŒ–è‡ªå·±çš„ï¼‰
            self.processor = None
        
        self.saver = SampleSaver(output_dir=output_dir)
        
        # 2. ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total': len(self.data_source),
            'processed': 0,
            'success': 0,
            'failed': 0,
            'failed_samples': [],
            'successful_samples': [],  # å­˜å‚¨æˆåŠŸçš„æ ·æœ¬ä¿¡æ¯ï¼ˆåŒ…å« data_typeï¼‰
            'start_time': None,
            'end_time': None
        }
        
        mode_desc = {
            'cpu': 'CPU (CPUè§£ç  + CPUç¼©æ”¾)',
            'gpu': 'GPU (GPUè§£ç  + GPUç¼©æ”¾ scale_cuda)',
            'mixed': 'Mixed (GPUè§£ç  + CPUç¼©æ”¾, æ¨è)'
        }
        
        logger.info(f"å¾…å¤„ç†: {self.stats['total']} ä¸ªè§†é¢‘ç‰‡æ®µ")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"è§£ç å™¨: FFmpeg")
        logger.info(f"è§£ç æ¨¡å¼: {mode_desc[self.decode_mode]} (device={device_id})")
        logger.info(f"å¸§å°ºå¯¸: {frame_size[0]}x{frame_size[1]}")
        logger.info(f"å¹¶è¡Œè¿›ç¨‹: {num_workers}")
        logger.info("=" * 60)
    
    def __len__(self) -> int:
        """Pipeline ä¸­çš„æ ·æœ¬æ€»æ•°"""
        return len(self.data_source)
    
    def __iter__(self) -> Iterator[Dict[str, Any]]:
        """
        è¿­ä»£å¤„ç†å™¨ï¼ˆæ”¯æŒå¤šè¿›ç¨‹ï¼‰
        
        Yields:
            batch_result: åŒ…å«æ‰¹æ¬¡å¤„ç†ç»“æœçš„å­—å…¸
        """
        self.stats['start_time'] = time.time()
        
        if self.num_workers == 1:
            # å•è¿›ç¨‹æ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
            yield from self._iter_single_process()
        else:
            # å¤šè¿›ç¨‹æ¨¡å¼ï¼šä½¿ç”¨ Pool
            yield from self._iter_multi_process()
        
        self.stats['end_time'] = time.time()
    
    def _iter_single_process(self) -> Iterator[Dict[str, Any]]:
        """å•è¿›ç¨‹è¿­ä»£å™¨"""
        # åˆ›å»ºè¿›åº¦æ¡
        if self.show_progress:
            mode_desc = {
                'cpu': 'CPU',
                'gpu': 'GPU',
                'mixed': 'Mixed'
            }
            mode = mode_desc.get(self.decode_mode, self.decode_mode)
            pbar = tqdm(
                total=len(self.data_source),
                desc=f"ğŸ¬ FFmpeg Pipeline ({mode})",
                unit="video"
            )
        else:
            pbar = None
        
        # é€ä¸ªå¤„ç†
        for index, segment in enumerate(self.data_source):
            # 1. å¤„ç†
            sample = self.processor.process_segment(index, segment)
            
            # 2. ä¿å­˜
            if sample.success:
                save_success = self.saver.save_sample(sample)
                if save_success:
                    self.stats['success'] += 1
                    self.stats['successful_samples'].append({
                        'sample_dir': str(sample.sample_dir),
                        'data_type': sample.data_type,
                        'vid': sample.vid
                    })
                else:
                    self.stats['failed'] += 1
                    failure_detail = {
                        'vid': sample.vid,
                        'data_type': sample.data_type,
                        'error_msg': sample.error_msg,
                        'error_reason': sample.error_reason or 'save_failed',
                        'video_path': sample.video_path,
                        'transcript': sample.transcript,
                        'start_time': sample.start_time,
                        'end_time': sample.end_time,
                        'duration': sample.duration,
                        'text_input_path': sample.text_input_path
                    }
                    self.stats['failed_samples'].append(failure_detail)
            else:
                self.stats['failed'] += 1
                failure_detail = {
                    'vid': sample.vid,
                    'data_type': sample.data_type,
                    'error_msg': sample.error_msg,
                    'error_reason': sample.error_reason,
                    'video_path': sample.video_path,
                    'transcript': sample.transcript,
                    'start_time': sample.start_time,
                    'end_time': sample.end_time,
                    'duration': sample.duration,
                    'text_input_path': sample.text_input_path
                }
                self.stats['failed_samples'].append(failure_detail)
                if self.stats['failed'] <= 10:
                    pass#logger.warning(f"å¤„ç†å¤±è´¥: {sample.vid} - {sample.error_reason}: {sample.error_msg}")
            
            self.stats['processed'] += 1
            
            # 3. æ›´æ–°è¿›åº¦
            if pbar:
                pbar.update(1)
                pbar.set_postfix({
                    'success': self.stats['success'],
                    'failed': self.stats['failed']
                })
            
            # 4. Yield æ‰¹æ¬¡ç»“æœ
            yield {
                'index': index,
                'vid': segment.vid,
                'success': sample.success,
                'num_frames': sample.frames.shape[0] if sample.success and sample.frames is not None else 0,
                'sample_dir': str(sample.sample_dir) if sample.sample_dir else None,
                'error_msg': sample.error_msg,
                'batch_size': 1,
                'num_success': self.stats['success'],
                'num_failed': self.stats['failed']
            }
        
        if pbar:
            pbar.close()
    
    def _iter_multi_process(self) -> Iterator[Dict[str, Any]]:
        """å¤šè¿›ç¨‹è¿­ä»£å™¨"""
        # åˆ›å»ºè¿›åº¦æ¡
        if self.show_progress:
            mode_desc = {
                'cpu': 'CPU',
                'gpu': 'GPU',
                'mixed': 'Mixed'
            }
            mode = mode_desc.get(self.decode_mode, self.decode_mode)
            pbar = tqdm(
                total=len(self.data_source),
                desc=f"ğŸ¬ FFmpeg Pipeline ({mode}, {self.num_workers}è¿›ç¨‹)",
                unit="video"
            )
        else:
            pbar = None
        
        # å‡†å¤‡å‚æ•°åˆ—è¡¨ï¼ˆåªä¼ é€’ index å’Œ segmentï¼‰
        args_list = [
            (index, segment)
            for index, segment in enumerate(self.data_source)
        ]
        
        # ä½¿ç”¨ Pool.imap è¿›è¡Œå¹¶è¡Œå¤„ç†ï¼ˆä¿æŒé¡ºåºï¼‰
        # ä½¿ç”¨ initializer è®©æ¯ä¸ªè¿›ç¨‹åªåˆå§‹åŒ–ä¸€æ¬¡
        with Pool(
            processes=self.num_workers,
            initializer=_init_worker,
            initargs=(self.saver.output_dir, self.frame_size, self.target_fps, self.device_id, self.decode_mode)
        ) as pool:
            for result in pool.imap(_process_single_segment_worker, args_list):
                # ç»Ÿè®¡
                if result['success']:
                    self.stats['success'] += 1
                    self.stats['successful_samples'].append({
                        'sample_dir': result['sample_dir'],
                        'data_type': result['data_type'],
                        'vid': result['vid']
                    })
                else:
                    self.stats['failed'] += 1
                    failure_detail = {
                        'vid': result['vid'],
                        'data_type': result['data_type'],
                        'error_msg': result.get('error_msg'),
                        'error_reason': result.get('error_reason'),
                        'video_path': result.get('video_path'),
                        'transcript': result.get('transcript'),
                        'start_time': result.get('start_time'),
                        'end_time': result.get('end_time'),
                        'duration': result.get('duration'),
                        'text_input_path': result.get('text_input_path')
                    }
                    self.stats['failed_samples'].append(failure_detail)
                    if self.stats['failed'] <= 10:
                        pass#logger.warning(f"å¤„ç†å¤±è´¥: {result['vid']} - {result.get('error_reason')}: {result.get('error_msg')}")
                
                self.stats['processed'] += 1
                
                # æ›´æ–°è¿›åº¦
                if pbar:
                    pbar.update(1)
                    pbar.set_postfix({
                        'success': self.stats['success'],
                        'failed': self.stats['failed']
                    })
                
                # Yield ç»“æœï¼ˆæ·»åŠ é¢å¤–å­—æ®µä¿æŒå…¼å®¹ï¼‰
                result['batch_size'] = 1
                result['num_success'] = self.stats['success']
                result['num_failed'] = self.stats['failed']
                yield result
        
        if pbar:
            pbar.close()
    
    def run(self) -> Dict[str, Any]:
        """
        è¿è¡Œæ•´ä¸ª pipelineï¼ˆä¾¿æ·æ–¹æ³•ï¼‰
        
        Returns:
            stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        for _ in self:
            pass  # è¿­ä»£å®Œæˆ
        
        return self.get_stats()
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        
        if stats['start_time'] and stats['end_time']:
            elapsed = stats['end_time'] - stats['start_time']
            stats['elapsed_time'] = elapsed
            stats['speed'] = stats['success'] / elapsed if elapsed > 0 else 0
        
        return stats
    
    def summary(self):
        """æ‰“å°æ‘˜è¦å¹¶ç”Ÿæˆè¯¦ç»†çš„å¤±è´¥åˆ†ææŠ¥å‘Š"""
        stats = self.get_stats()
        
        logger.info("\n" + "=" * 60)
        logger.info("Pipeline å¤„ç†å®Œæˆ")
        logger.info("=" * 60)
        logger.info(f"æ€»æ•°: {stats['total']}")
        logger.info(f"æˆåŠŸ: {stats['success']}")
        logger.info(f"å¤±è´¥: {stats['failed']}")
        
        if 'elapsed_time' in stats:
            logger.info(f"è€—æ—¶: {stats['elapsed_time']/60:.2f} åˆ†é’Ÿ")
            logger.info(f"é€Ÿåº¦: {stats['speed']:.2f} è§†é¢‘/ç§’")
        
        # ç”Ÿæˆå¹¶ä¿å­˜è¯¦ç»†çš„å¤±è´¥åˆ†ææŠ¥å‘Š
        if stats['failed_samples']:
            self._generate_failure_analysis_report(stats['failed_samples'])
        
        # ç”Ÿæˆ dataset_info.json
        self._generate_dataset_info(stats['successful_samples'])
        
        logger.info("=" * 60)
    
    def _generate_failure_analysis_report(self, failed_samples: List[Dict]):
        """
        ç”Ÿæˆè¯¦ç»†çš„å¤±è´¥åˆ†ææŠ¥å‘Š
        
        Args:
            failed_samples: å¤±è´¥æ ·æœ¬åˆ—è¡¨
        """
        # ç»Ÿè®¡å„ç§å¤±è´¥åŸå› 
        failure_stats = {}
        for item in failed_samples:
            reason = item.get('error_reason', 'unknown')
            failure_stats[reason] = failure_stats.get(reason, 0) + 1
        
        # æŒ‰data_typeåˆ†ç±»
        failure_by_type = {'train': [], 'val': [], 'test': []}
        for item in failed_samples:
            data_type = item.get('data_type', 'unknown')
            if data_type in failure_by_type:
                failure_by_type[data_type].append(item)
        
        # æ„å»ºå®Œæ•´æŠ¥å‘Š
        failure_report = {
            'summary': {
                'total_samples': self.stats['total'],
                'successful': self.stats['success'],
                'failed': self.stats['failed'],
                'success_rate': f"{self.stats['success']/self.stats['total']*100:.2f}%" if self.stats['total'] > 0 else "0%",
                'failure_breakdown': failure_stats,
                'failure_by_data_type': {
                    'train': len(failure_by_type['train']),
                    'val': len(failure_by_type['val']),
                    'test': len(failure_by_type['test'])
                }
            },
            'failure_analysis': {
                'video_file_not_found': {
                    'description': 'è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå…ƒæ•°æ®ä¸­æŒ‡å®šçš„è·¯å¾„æ— æ•ˆï¼‰',
                    'count': failure_stats.get('video_file_not_found', 0),
                    'solution': '1. æ£€æŸ¥å…ƒæ•°æ®ä¸­çš„video_pathæ˜¯å¦æ­£ç¡®\n2. ç¡®è®¤è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n3. æ£€æŸ¥æ–‡ä»¶æƒé™'
                },
                'frame_extraction_failed': {
                    'description': 'FFmpegæ— æ³•æå–è§†é¢‘å¸§',
                    'count': failure_stats.get('frame_extraction_failed', 0),
                    'solution': '1. æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸå\n2. ç¡®è®¤è§†é¢‘ç¼–ç æ ¼å¼æ˜¯å¦æ”¯æŒ\n3. æ£€æŸ¥æ—¶é—´èŒƒå›´(start_time/end_time)æ˜¯å¦æœ‰æ•ˆ\n4. å°è¯•ç”¨ffmpegæ‰‹åŠ¨æ’­æ”¾è¯¥è§†é¢‘'
                },
                'missing_text_input_path': {
                    'description': 'å…ƒæ•°æ®ä¸­ç¼ºå°‘text_input_pathå­—æ®µ',
                    'count': failure_stats.get('missing_text_input_path', 0),
                    'solution': '1. è¿è¡Œgenerate_clip4mc_metadata.pyé‡æ–°ç”Ÿæˆå…ƒæ•°æ®\n2. ç¡®ä¿å…ƒæ•°æ®åŒ…å«text_input_pathå­—æ®µ'
                },
                'text_input_file_not_found': {
                    'description': 'text_input.pklæ–‡ä»¶ä¸å­˜åœ¨',
                    'count': failure_stats.get('text_input_file_not_found', 0),
                    'solution': '1. è¿è¡Œgenerate_clip4mc_metadata.pyç”Ÿæˆtext_input.pkl\n2. æ£€æŸ¥text_input_pathè·¯å¾„æ˜¯å¦æ­£ç¡®\n3. ç¡®è®¤æ–‡ä»¶æƒé™'
                },
                'save_failed': {
                    'description': 'æ•°æ®ä¿å­˜å¤±è´¥',
                    'count': failure_stats.get('save_failed', 0),
                    'solution': '1. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³\n2. ç¡®è®¤è¾“å‡ºç›®å½•æƒé™\n3. æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿæ˜¯å¦æ­£å¸¸'
                },
                'unknown_exception': {
                    'description': 'æœªçŸ¥å¼‚å¸¸',
                    'count': failure_stats.get('unknown_exception', 0),
                    'solution': '1. æŸ¥çœ‹è¯¦ç»†çš„error_msg\n2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶\n3. å¯èƒ½éœ€è¦è°ƒè¯•ä»£ç '
                }
            },
            'failed_samples': failed_samples
        }
        
        # ä¿å­˜æŠ¥å‘Š
        failed_json = self.saver.output_dir / "failure_analysis.json"
        with open(failed_json, 'w', encoding='utf-8') as f:
            json.dump(failure_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"\nå¤±è´¥åˆ†ææŠ¥å‘Š: {failed_json}")
        logger.info(f"å¤±è´¥åŸå› ç»Ÿè®¡:")
        for reason, count in failure_stats.items():
            logger.info(f"  - {reason}: {count} ä¸ªæ ·æœ¬")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å¤±è´¥æ¡ˆä¾‹ï¼ˆå‰3ä¸ªï¼‰
        if len(failed_samples) > 0:
            logger.info(f"\nå¤±è´¥æ¡ˆä¾‹ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
            for i, sample in enumerate(failed_samples[:3], 1):
                logger.info(f"  {i}. vid={sample['vid']}, reason={sample.get('error_reason')}")
                logger.info(f"     {sample.get('error_msg', 'N/A')[:80]}")
        
        return failure_report
    
    def _generate_dataset_info(self, successful_samples: List[Dict[str, str]]):
        """
        ç”Ÿæˆ dataset_info.json
        
        æ ¹æ®å…ƒæ•°æ®ä¸­çš„ data_type å­—æ®µåˆ†é…æ ·æœ¬åˆ° train/val/test
        
        Args:
            successful_samples: æˆåŠŸå¤„ç†çš„æ ·æœ¬åˆ—è¡¨
                [
                    {
                        'sample_dir': '/path/to/sample_000000_xxx',
                        'data_type': 'train',
                        'vid': 'xxx'
                    },
                    ...
                ]
        """
        dataset_info_path = self.saver.output_dir / "dataset_info.json"
        
        # æ ¹æ® data_type åˆ†ç»„
        dataset_info = {
            "train": [],
            "val": [],
            "test": []
        }
        
        for sample in successful_samples:
            sample_dir = sample['sample_dir']
            data_type = sample.get('data_type', 'train')
            
            # ç¡®ä¿ data_type æœ‰æ•ˆ
            if data_type not in ['train', 'val', 'test']:
                logger.warning(f"æ— æ•ˆçš„ data_type: {data_type}ï¼Œé»˜è®¤ä¸º train")
                data_type = 'train'
            
            dataset_info[data_type].append(sample_dir)
        
        # ä¿å­˜
        with open(dataset_info_path, "w") as f:
            json.dump(dataset_info, f, indent=2)
        
        # æ‰“å°ç»Ÿè®¡
        logger.info(f"dataset_info.json ç”ŸæˆæˆåŠŸ:")
        logger.info(f"  train: {len(dataset_info['train'])} ä¸ªæ ·æœ¬")
        logger.info(f"  val:   {len(dataset_info['val'])} ä¸ªæ ·æœ¬")
        logger.info(f"  test:  {len(dataset_info['test'])} ä¸ªæ ·æœ¬")


# ============================================================
# Command Line Interface
# ============================================================

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="FFmpeg Video Processing Pipeline (Pure FFmpeg Implementation)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # CPU æ¨¡å¼ï¼ˆçº¯ CPU è§£ç  + ç¼©æ”¾ï¼‰
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata metadata.json \\
        --output-dir output \\
        --decode-mode cpu \\
        --num-workers 8

    # Mixed æ¨¡å¼ï¼ˆGPUè§£ç  + CPUç¼©æ”¾ï¼Œæ¨èï¼‰
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata metadata.json \\
        --output-dir output \\
        --decode-mode mixed \\
        --num-workers 4

    # GPU æ¨¡å¼ï¼ˆå…¨ GPUï¼šGPUè§£ç  + GPUç¼©æ”¾ï¼‰
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata metadata.json \\
        --output-dir output \\
        --decode-mode gpu \\
        --num-workers 2

ä¸‰ç§è§£ç æ¨¡å¼:
    - cpu:   çº¯ CPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæœ€ç¨³å®šï¼‰
    - mixed: GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæ¨èï¼Œå…¼å®¹æ€§å¥½ï¼‰
    - gpu:   GPU è§£ç  + GPU ç¼©æ”¾ scale_cudaï¼ˆæœ€å¿«ï¼Œéœ€è¦å®Œæ•´CUDAæ”¯æŒï¼‰

å…ƒæ•°æ® JSON æ ¼å¼:
    [
        {
            "vid": "abc123",
            "video_path": "/path/to/video.mp4",
            "start_time": 10.5,
            "end_time": 15.3,
            "transcript": "player mining diamond",
            "size": [0.3, 0.4, 0.5, ...],  # 16 ä¸ªå€¼
            "data_type": "train",  # 'train', 'val', 'test'
            "text_input_path": "/path/to/abc123_text_input.pkl"
        },
        ...
    ]
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--metadata", type=Path, required=True,
                       help="é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON æ–‡ä»¶ï¼ˆåŒ…å« vid, video_path, start_time, end_time, transcript, sizeï¼‰")
    parser.add_argument("--output-dir", type=Path, required=True,
                       help="è¾“å‡ºç›®å½•")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--frame-height", type=int, default=160,
                       help="ç›®æ ‡å¸§é«˜åº¦ (é»˜è®¤: 160)")
    parser.add_argument("--frame-width", type=int, default=256,
                       help="ç›®æ ‡å¸§å®½åº¦ (é»˜è®¤: 256)")
    parser.add_argument("--target-fps", type=int, default=None,
                       help="ç›®æ ‡å¸§ç‡ (é»˜è®¤: Noneä¿æŒåŸå§‹å¸§ç‡ï¼Œæ¨è10-20ä»¥èŠ‚çœ67%%ç©ºé—´)")
    parser.add_argument("--decode-mode", type=str, default='mixed',
                       choices=['cpu', 'gpu', 'mixed'],
                       help="è§£ç æ¨¡å¼: cpu(çº¯CPU) | gpu(å…¨GPU scale_cuda) | mixed(GPUè§£ç +CPUç¼©æ”¾,æ¨è)")
    parser.add_argument("--device-id", type=int, default=0,
                       help="GPU è®¾å¤‡ ID (é»˜è®¤: 0)")
    parser.add_argument("--num-workers", type=int, default=1,
                       help="å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: 1ï¼Œå•çº¿ç¨‹)")
    parser.add_argument("--batch-size", type=int, default=1,
                       help="æ‰¹é‡å¤§å°ï¼ˆæš‚ä»…ç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰")
    parser.add_argument("--no-progress", action='store_true',
                       help="ç¦ç”¨è¿›åº¦æ¡")
    
    args = parser.parse_args()
    
    # åˆ›å»º pipeline
    pipeline = FFmpegPipeline(
        metadata_path=args.metadata,
        output_dir=args.output_dir,
        batch_size=args.batch_size,
        frame_size=(args.frame_height, args.frame_width),
        target_fps=args.target_fps,
        device_id=args.device_id,
        decode_mode=args.decode_mode,
        num_workers=args.num_workers,
        show_progress=not args.no_progress
    )
    
    # è¿è¡Œ pipeline
    pipeline.run()
    
    # æ‰“å°æ‘˜è¦
    pipeline.summary()
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())

