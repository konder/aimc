#!/usr/bin/env python3
"""
FFmpeg Video Processing Pipeline - Pure FFmpeg Implementation
"""

import json
import pickle
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Iterator, Any
from dataclasses import dataclass
from collections import OrderedDict
import time
from multiprocessing import Pool
from functools import partial
import subprocess
import tempfile

import numpy as np
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(processName)s] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================
# Data Structures
# ============================================================

@dataclass
class VideoSegment:
    """è§†é¢‘ç‰‡æ®µå…ƒæ•°æ®"""
    vid: str                    # è§†é¢‘ ID
    video_path: Path            # è§†é¢‘æ–‡ä»¶è·¯å¾„
    start_time: float           # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end_time: float             # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    transcript: str             # æ–‡æœ¬æè¿°
    size: List[float] = None    # ç›®æ ‡ç‰©ä½“å¤§å°ï¼ˆ16 ä¸ªå€¼ï¼‰
    data_type: str = 'train'    # æ•°æ®ç±»å‹ï¼š'train', 'val', 'test'
    text_input_path: str = None # text_input.pkl æ–‡ä»¶è·¯å¾„ï¼ˆé¢„ç”Ÿæˆï¼‰
    
    @property
    def duration(self) -> float:
        """ç‰‡æ®µæ—¶é•¿"""
        return self.end_time - self.start_time
    
    def __repr__(self):
        return f"VideoSegment(vid={self.vid}, {self.start_time:.1f}s-{self.end_time:.1f}s, type={self.data_type})"


@dataclass
class ProcessedSample:
    """å¤„ç†åçš„æ ·æœ¬"""
    index: int
    vid: str
    frames: np.ndarray          # (N, H, W, 3) uint8
    tokens: np.ndarray          # (77,) int64
    size: List[float]           # [16] float
    sample_dir: Path
    success: bool
    data_type: str = 'train'    # æ•°æ®ç±»å‹ï¼š'train', 'val', 'test'
    error_msg: Optional[str] = None
    
    @property
    def num_frames(self) -> int:
        return self.frames.shape[0] if self.frames is not None else 0


# ============================================================
# Pipeline Components
# ============================================================

class VideoDataSource:
    """
    è§†é¢‘æ•°æ®æº (Data Source)
    
    è´Ÿè´£ï¼š
    1. åŠ è½½é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON
    2. ç”Ÿæˆ VideoSegment åˆ—è¡¨
    
    å…ƒæ•°æ®æ ¼å¼ï¼š
    [
        {
            "vid": "abc123",
            "video_path": "/path/to/video.mp4",
            "start_time": 10.5,
            "end_time": 15.3,
            "transcript": "player mining diamond",
            "size": [0.3, 0.4, 0.5, ...],  # 16 ä¸ªå€¼
            "data_type": "train",  # 'train', 'val', 'test'
            "text_input_path": "/path/to/abc123_text_input.pkl"  # é¢„ç”Ÿæˆçš„ text_input.pkl
        },
        ...
    ]
    """
    
    def __init__(self, metadata_path: Path):
        """
        Args:
            metadata_path: é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON æ–‡ä»¶
                          åŒ…å« vid, video_path, start_time, end_time, transcript, size
        """
        self.metadata_path = Path(metadata_path)
        self.segments: List[VideoSegment] = []
        
        self._load_data()
    
    def _load_data(self):
        """åŠ è½½å…ƒæ•°æ®å¹¶ç”Ÿæˆ VideoSegment åˆ—è¡¨"""
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        logger.info(f"åŠ è½½äº† {len(metadata)} æ¡å…ƒæ•°æ®")
        
        # ç›´æ¥ä»å…ƒæ•°æ®åˆ›å»º VideoSegment
        success_count = 0
        for item in metadata:
            vid = item.get('vid', '')
            video_path_str = item.get('video_path', '')
            
            if not vid or not video_path_str:
                logger.warning(f"è·³è¿‡æ— æ•ˆæ¡ç›®: vid={vid}, video_path={video_path_str}")
                continue
            
            video_path = Path(video_path_str)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not video_path.exists():
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                continue
            
            segment = VideoSegment(
                vid=vid,
                video_path=video_path,
                start_time=item.get('start_time', 0),
                end_time=item.get('end_time', 0),
                transcript=item.get('transcript', ''),
                size=item.get('size', []),
                data_type=item.get('data_type', 'train'),  # é»˜è®¤ä¸º train
                text_input_path=item.get('text_input_path', None)
            )
            self.segments.append(segment)
            success_count += 1
        
        logger.info(f"åŠ è½½æˆåŠŸ: {success_count}/{len(metadata)} ä¸ªè§†é¢‘ç‰‡æ®µ")
    
    def __len__(self) -> int:
        return len(self.segments)
    
    def __getitem__(self, index: int) -> VideoSegment:
        return self.segments[index]
    
    def __iter__(self) -> Iterator[VideoSegment]:
        return iter(self.segments)


class FFmpegProcessor:
    """
    FFmpeg è§†é¢‘å¤„ç†å™¨ (Processor) - çº¯ FFmpeg å®ç°
    
    è´Ÿè´£ï¼š
    1. ä½¿ç”¨ FFmpeg æå–è§†é¢‘å¸§
    2. æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ (NVDEC)
    3. Resize åˆ°ç›®æ ‡å°ºå¯¸
    """
    
    def __init__(
        self,
        frame_height: int = 160,
        frame_width: int = 256,
        device_id: int = 0,
        use_gpu: bool = False
    ):
        """
        Args:
            frame_height: ç›®æ ‡å¸§é«˜åº¦
            frame_width: ç›®æ ‡å¸§å®½åº¦
            device_id: GPU IDï¼ˆç”¨äº NVDECï¼‰
            use_gpu: æ˜¯å¦ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿ
        """
        self.frame_height = frame_height
        self.frame_width = frame_width
        self.device_id = device_id
        self.use_gpu = use_gpu
        
        # æ£€æŸ¥ ffmpeg æ˜¯å¦æ”¯æŒ GPU åŠ é€Ÿ
        self.gpu_available = False
        if use_gpu:
            self.gpu_available = self._check_gpu_support()
            if not self.gpu_available:
                logger.warning("GPU åŠ é€Ÿä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU æ¨¡å¼")
        
        mode = "GPU (NVDEC)" if (use_gpu and self.gpu_available) else "CPU"
        logger.info(f"FFmpegProcessor åˆå§‹åŒ–: {mode} (device={device_id})")
    
    def _check_gpu_support(self) -> bool:
        """
        æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ
        
        Returns:
            bool: æ˜¯å¦æ”¯æŒ GPU
        """
        try:
            # æ£€æŸ¥ ffmpeg æ˜¯å¦æ”¯æŒ cuda hwaccel
            result = subprocess.run(
                ['ffmpeg', '-hwaccels'],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=5,
                text=True
            )
            
            if 'cuda' in result.stdout.lower():
                return True
            
            return False
        except Exception:
            return False
    
    def extract_frames(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨ FFmpeg æå–è§†é¢‘å¸§ (æ ¸å¿ƒæ–¹æ³•)
        
        Args:
            segment: è§†é¢‘ç‰‡æ®µä¿¡æ¯
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼
        """
        # GPU æ¨¡å¼ï¼šå…ˆå°è¯• GPUï¼Œå¤±è´¥åˆ™å›é€€ CPU
        if self.use_gpu and self.gpu_available:
            frames = self._try_gpu_decode(segment)
            if frames is not None:
                return frames
            # GPU å¤±è´¥ï¼Œå›é€€åˆ° CPUï¼ˆé™é»˜å›é€€ï¼Œä¸æ‰“å°è­¦å‘Šï¼‰
        
        # CPU æ¨¡å¼
        return self._extract_frames_cpu(segment)
    
    def _try_gpu_decode(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        å°è¯•ä½¿ç”¨ GPU è§£ç ï¼ˆNVDECï¼‰
        
        ç­–ç•¥:
        1. å…ˆå°è¯• hwaccel cuda + scale (GPU è§£ç  + CPU ç¼©æ”¾)
        2. å¤±è´¥åˆ™è¿”å› Noneï¼Œç”±ä¸»æµç¨‹å›é€€åˆ°çº¯ CPU
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            duration = segment.end_time - segment.start_time
            
            # GPU è§£ç  + CPU ç¼©æ”¾ï¼ˆæœ€å…¼å®¹çš„æ–¹æ¡ˆï¼‰
            # -ss æ”¾åœ¨ -i å‰é¢ï¼ˆè¾“å…¥å‰ seekï¼Œæ›´å¿«ï¼‰
            cmd = [
                'ffmpeg',
                '-hwaccel', 'cuda',
                '-hwaccel_device', str(self.device_id),
                '-hwaccel_output_format', 'cuda',  # æ˜ç¡®æŒ‡å®šè¾“å‡ºæ ¼å¼
                '-ss', str(segment.start_time),
                '-i', str(segment.video_path),
                '-t', str(duration),
                '-vf', f'hwdownload,format=nv12,scale={self.frame_width}:{self.frame_height}',
                '-f', 'rawvideo',
                '-pix_fmt', 'rgb24',
                '-loglevel', 'error',
                'pipe:1'
            ]
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            if result.returncode == 0 and len(result.stdout) > 0:
                raw_data = result.stdout
                frame_size = self.frame_height * self.frame_width * 3
                
                if len(raw_data) >= frame_size:
                    num_frames = len(raw_data) // frame_size
                    if num_frames > 0:
                        frames = np.frombuffer(raw_data[:num_frames * frame_size], dtype=np.uint8)
                        frames = frames.reshape((num_frames, self.frame_height, self.frame_width, 3))
                        return frames
            
            # GPU è§£ç å¤±è´¥ï¼Œè¿”å› None
            return None
        
        except subprocess.TimeoutExpired:
            return None
        except Exception:
            return None
    
    def _extract_frames_cpu(self, segment: VideoSegment) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨ CPU æ¨¡å¼æå–è§†é¢‘å¸§ï¼ˆGPU å¤±è´¥æ—¶çš„å¤‡é€‰ï¼‰
        
        Returns:
            frames: (N, H, W, 3) uint8, RGB æ ¼å¼
        """
        try:
            duration = segment.end_time - segment.start_time
            
            cmd = [
                'ffmpeg',
                '-ss', str(segment.start_time),
                '-i', str(segment.video_path),
                '-t', str(duration),
                '-vf', f'scale={self.frame_width}:{self.frame_height}',
                '-f', 'rawvideo',
                '-pix_fmt', 'rgb24',
                '-loglevel', 'error',
                'pipe:1'
            ]
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30
            )
            
            if result.returncode != 0:
                return None
            
            raw_data = result.stdout
            frame_size = self.frame_height * self.frame_width * 3
            
            if len(raw_data) < frame_size:
                return None
            
            num_frames = len(raw_data) // frame_size
            if num_frames == 0:
                return None
            
            frames = np.frombuffer(raw_data[:num_frames * frame_size], dtype=np.uint8)
            frames = frames.reshape((num_frames, self.frame_height, self.frame_width, 3))
            
            return frames
        
        except Exception as e:
            logger.error(f"{segment.vid}: CPU è§£ç å¤±è´¥ - {str(e)}")
            return None
    
    def process_segment(self, index: int, segment: VideoSegment) -> ProcessedSample:
        """
        å¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ
        
        Returns:
            ProcessedSample: åŒ…å«å¤„ç†ç»“æœçš„æ•°æ®ç»“æ„
        """
        try:
            # 1. æå–å¸§
            frames = self.extract_frames(segment)
            if frames is None or len(frames) == 0:
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg="å¸§æå–å¤±è´¥"
                )
            
            # 2. æ£€æŸ¥ text_input_path
            if not segment.text_input_path:
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg="å…ƒæ•°æ®ç¼ºå°‘ text_input_path"
                )
            
            text_input_path = Path(segment.text_input_path)
            if not text_input_path.exists():
                return ProcessedSample(
                    index=index,
                    vid=segment.vid,
                    frames=None,
                    tokens=None,
                    size=None,
                    sample_dir=None,
                    success=False,
                    data_type=segment.data_type,
                    error_msg=f"text_input.pkl æ–‡ä»¶ä¸å­˜åœ¨: {text_input_path}"
                )
            
            # 3. å¤„ç† size æ•°æ®
            # æ³¨æ„ï¼šå®˜æ–¹ CLIP4MC çš„ size æ•°ç»„å›ºå®šä¸º 16 ä¸ªå€¼
            # è¿™äº›å€¼å¯¹åº” DataLoader åŠ¨æ€é‡‡æ ·çš„ 16 å¸§ï¼Œè€Œéå®é™…æå–çš„æ‰€æœ‰å¸§
            # å› æ­¤ç›´æ¥ä½¿ç”¨å…ƒæ•°æ®ä¸­çš„ sizeï¼Œä¸åšä»»ä½•å¤„ç†
            size_values = segment.size if segment.size else []
            
            if not size_values or len(size_values) == 0:
                # å…ƒæ•°æ®æœªæä¾› sizeï¼Œä½¿ç”¨å ä½ç¬¦ï¼ˆ16 ä¸ªå€¼ï¼‰
                size_values = [0] * 16
            
            return ProcessedSample(
                index=index,
                vid=segment.vid,
                frames=frames,
                tokens=text_input_path,  # å­˜å‚¨ text_input.pkl è·¯å¾„ï¼Œç¨åæ‹·è´
                size=size_values,
                sample_dir=None,  # ç¨åç”± Saver å¡«å……
                success=True,
                data_type=segment.data_type
            )
        
        except Exception as e:
            return ProcessedSample(
                index=index,
                vid=segment.vid,
                frames=None,
                tokens=None,
                size=None,
                sample_dir=None,
                success=False,
                data_type=segment.data_type,
                error_msg=f"å¤„ç†å¼‚å¸¸: {str(e)}"
            )


class SampleSaver:
    """
    æ ·æœ¬ä¿å­˜å™¨ (Saver)
    
    è´Ÿè´£ï¼š
    1. ä¿å­˜ video_input.pkl
    2. æ‹·è´é¢„ç”Ÿæˆçš„ text_input.pkl
    3. ä¿å­˜ size.json
    """
    
    def __init__(self, output_dir: Path):
        """
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def save_sample(self, sample: ProcessedSample) -> bool:
        """
        ä¿å­˜å•ä¸ªæ ·æœ¬
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not sample.success:
            return False
        
        try:
            import shutil
            
            # åˆ›å»ºæ ·æœ¬ç›®å½•
            sample_dir = self.output_dir / f"sample_{sample.index:06d}_{sample.vid}"
            sample_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ video_input.pkl
            with open(sample_dir / "video_input.pkl", "wb") as f:
                pickle.dump(sample.frames, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            # æ‹·è´é¢„ç”Ÿæˆçš„ text_input.pkl
            # sample.tokens ç°åœ¨å­˜å‚¨çš„æ˜¯ text_input.pkl çš„è·¯å¾„
            text_input_src = sample.tokens  # è¿™æ˜¯ä¸€ä¸ª Path å¯¹è±¡
            if isinstance(text_input_src, (str, Path)):
                text_input_src = Path(text_input_src)
                if text_input_src.exists():
                    shutil.copy2(text_input_src, sample_dir / "text_input.pkl")
                else:
                    logger.error(f"text_input.pkl æºæ–‡ä»¶ä¸å­˜åœ¨: {text_input_src}")
                    return False
            else:
                logger.error(f"text_input.pkl è·¯å¾„æ ¼å¼é”™è¯¯: {type(text_input_src)}")
                return False
            
            # ä¿å­˜ size.json
            with open(sample_dir / "size.json", "w") as f:
                json.dump(sample.size, f)
            
            # æ›´æ–° sample_dir
            sample.sample_dir = sample_dir
            
            return True
        
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥ {sample.vid}: {str(e)}")
            sample.success = False
            sample.error_msg = f"ä¿å­˜å¤±è´¥: {str(e)}"
            return False


# å…¨å±€å˜é‡ï¼ˆç”¨äºè¿›ç¨‹æ± åˆå§‹åŒ–ï¼‰
_worker_processor = None
_worker_saver = None


def _init_worker(output_dir: Path, frame_size: Tuple[int, int], device_id: int, use_gpu: bool):
    """
    åˆå§‹åŒ– worker è¿›ç¨‹ï¼ˆæ¯ä¸ªè¿›ç¨‹åªè°ƒç”¨ä¸€æ¬¡ï¼‰
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        frame_size: (height, width)
        device_id: è®¾å¤‡ ID
        use_gpu: æ˜¯å¦ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿ
    """
    global _worker_processor, _worker_saver
    
    _worker_processor = FFmpegProcessor(
        frame_height=frame_size[0],
        frame_width=frame_size[1],
        device_id=device_id,
        use_gpu=use_gpu
    )
    
    _worker_saver = SampleSaver(output_dir=output_dir)


def _process_single_segment_worker(args: Tuple[int, VideoSegment]) -> Dict[str, Any]:
    """
    å¤šè¿›ç¨‹ worker å‡½æ•°ï¼šå¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ
    
    Args:
        args: (index, segment)
    
    Returns:
        dict: å¤„ç†ç»“æœ
    """
    global _worker_processor, _worker_saver
    
    index, segment = args
    
    # ä½¿ç”¨å·²åˆå§‹åŒ–çš„ processor å’Œ saver
    sample = _worker_processor.process_segment(index, segment)
    
    # ä¿å­˜
    if sample.success:
        success = _worker_saver.save_sample(sample)
        if not success:
            sample.success = False
    
    # è¿”å›ç»“æœ
    return {
        'index': index,
        'vid': segment.vid,
        'success': sample.success,
        'error_msg': sample.error_msg,
        'sample_dir': str(sample.sample_dir) if sample.sample_dir else None,
        'data_type': segment.data_type
    }


# ============================================================
# Pipeline & Iterator
# ============================================================

class FFmpegPipeline:
    """
    FFmpeg è§†é¢‘å¤„ç† Pipeline (ç±»ä¼¼ DALI Pipeline)
    
    æ¶æ„ï¼š
        VideoDataSource -> FFmpegProcessor -> SampleSaver -> Iterator
    
    ç‰¹ç‚¹ï¼š
        - çº¯ FFmpeg å®ç°
        - æ”¯æŒ GPU ç¡¬ä»¶åŠ é€Ÿ (NVDEC)
        - æ”¯æŒæ‰€æœ‰è§†é¢‘æ ¼å¼ (H.264, VP9, HEVC, etc.)
        - Pipeline æ¨¡å¼è®¾è®¡
        - æ”¯æŒæ‰¹é‡è¿­ä»£
        - è¿›åº¦è·Ÿè¸ª
        - ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(
        self,
        metadata_path: Path,
        output_dir: Path,
        batch_size: int = 1,
        frame_size: Tuple[int, int] = (160, 256),
        device_id: int = 0,
        use_gpu: bool = False,
        num_workers: int = 1,
        show_progress: bool = True
    ):
        """
        Args:
            metadata_path: é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSONï¼ˆåŒ…å« vid, video_path, start_time, end_time, size, data_type, text_input_pathï¼‰
            output_dir: è¾“å‡ºç›®å½•
            batch_size: æ‰¹é‡å¤§å°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼Œå®é™…ä»æ˜¯é€ä¸ªå¤„ç†ï¼‰
            frame_size: (height, width) ç›®æ ‡å¸§å°ºå¯¸
            device_id: GPU IDï¼ˆç”¨äº FFmpeg NVDECï¼‰
            use_gpu: æ˜¯å¦ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿï¼ˆFFmpeg NVDECï¼‰
            num_workers: å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤: 1ï¼Œå•çº¿ç¨‹ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        """
        self.batch_size = batch_size
        self.show_progress = show_progress
        self.num_workers = num_workers
        self.frame_size = frame_size
        self.device_id = device_id
        self.use_gpu = use_gpu
        
        # 1. åˆå§‹åŒ–ç»„ä»¶
        logger.info("=" * 60)
        logger.info("åˆå§‹åŒ– Decord Pipeline")
        logger.info("=" * 60)
        
        self.data_source = VideoDataSource(metadata_path=metadata_path)
        
        # å•è¿›ç¨‹æ¨¡å¼ï¼šåˆå§‹åŒ– processor
        if num_workers == 1:
            self.processor = FFmpegProcessor(
                frame_height=frame_size[0],
                frame_width=frame_size[1],
                device_id=device_id,
                use_gpu=use_gpu
            )
        else:
            # å¤šè¿›ç¨‹æ¨¡å¼ï¼šä¸åœ¨ä¸»è¿›ç¨‹åˆå§‹åŒ– processorï¼ˆæ¯ä¸ªå­è¿›ç¨‹ä¼šåˆå§‹åŒ–è‡ªå·±çš„ï¼‰
            self.processor = None
        
        self.saver = SampleSaver(output_dir=output_dir)
        
        # 2. ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total': len(self.data_source),
            'processed': 0,
            'success': 0,
            'failed': 0,
            'failed_samples': [],
            'successful_samples': [],  # å­˜å‚¨æˆåŠŸçš„æ ·æœ¬ä¿¡æ¯ï¼ˆåŒ…å« data_typeï¼‰
            'start_time': None,
            'end_time': None
        }
        
        logger.info(f"å¾…å¤„ç†: {self.stats['total']} ä¸ªè§†é¢‘ç‰‡æ®µ")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"è§£ç å™¨: FFmpeg (çº¯å®ç°)")
        logger.info(f"ç¡¬ä»¶åŠ é€Ÿ: {'GPU (NVDEC)' if use_gpu else 'CPU'} (ID={device_id})")
        logger.info(f"å¸§å°ºå¯¸: {frame_size[0]}x{frame_size[1]}")
        logger.info(f"å¹¶è¡Œè¿›ç¨‹: {num_workers}")
        logger.info("=" * 60)
    
    def __len__(self) -> int:
        """Pipeline ä¸­çš„æ ·æœ¬æ€»æ•°"""
        return len(self.data_source)
    
    def __iter__(self) -> Iterator[Dict[str, Any]]:
        """
        è¿­ä»£å¤„ç†å™¨ï¼ˆæ”¯æŒå¤šè¿›ç¨‹ï¼‰
        
        Yields:
            batch_result: åŒ…å«æ‰¹æ¬¡å¤„ç†ç»“æœçš„å­—å…¸
        """
        self.stats['start_time'] = time.time()
        
        if self.num_workers == 1:
            # å•è¿›ç¨‹æ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
            yield from self._iter_single_process()
        else:
            # å¤šè¿›ç¨‹æ¨¡å¼ï¼šä½¿ç”¨ Pool
            yield from self._iter_multi_process()
        
        self.stats['end_time'] = time.time()
    
    def _iter_single_process(self) -> Iterator[Dict[str, Any]]:
        """å•è¿›ç¨‹è¿­ä»£å™¨"""
        # åˆ›å»ºè¿›åº¦æ¡
        if self.show_progress:
            mode = "GPU" if self.use_gpu else "CPU"
            pbar = tqdm(
                total=len(self.data_source),
                desc=f"ğŸ¬ FFmpeg Pipeline ({mode})",
                unit="video"
            )
        else:
            pbar = None
        
        # é€ä¸ªå¤„ç†
        for index, segment in enumerate(self.data_source):
            # 1. å¤„ç†
            sample = self.processor.process_segment(index, segment)
            
            # 2. ä¿å­˜
            if sample.success:
                save_success = self.saver.save_sample(sample)
                if save_success:
                    self.stats['success'] += 1
                    self.stats['successful_samples'].append({
                        'sample_dir': str(sample.sample_dir),
                        'data_type': sample.data_type,
                        'vid': sample.vid
                    })
                else:
                    self.stats['failed'] += 1
                    self.stats['failed_samples'].append({
                        'vid': sample.vid,
                        'error': sample.error_msg
                    })
            else:
                self.stats['failed'] += 1
                self.stats['failed_samples'].append({
                    'vid': sample.vid,
                    'error': sample.error_msg
                })
                if self.stats['failed'] <= 10:
                    logger.warning(f"å¤„ç†å¤±è´¥: {sample.vid} - {sample.error_msg}")
            
            self.stats['processed'] += 1
            
            # 3. æ›´æ–°è¿›åº¦
            if pbar:
                pbar.update(1)
                pbar.set_postfix({
                    'success': self.stats['success'],
                    'failed': self.stats['failed']
                })
            
            # 4. Yield æ‰¹æ¬¡ç»“æœ
            yield {
                'index': index,
                'vid': segment.vid,
                'success': sample.success,
                'num_frames': sample.frames.shape[0] if sample.success and sample.frames is not None else 0,
                'sample_dir': str(sample.sample_dir) if sample.sample_dir else None,
                'error_msg': sample.error_msg,
                'batch_size': 1,
                'num_success': self.stats['success'],
                'num_failed': self.stats['failed']
            }
        
        if pbar:
            pbar.close()
    
    def _iter_multi_process(self) -> Iterator[Dict[str, Any]]:
        """å¤šè¿›ç¨‹è¿­ä»£å™¨"""
        # åˆ›å»ºè¿›åº¦æ¡
        if self.show_progress:
            mode = "GPU" if self.use_gpu else "CPU"
            pbar = tqdm(
                total=len(self.data_source),
                desc=f"ğŸ¬ FFmpeg Pipeline ({mode}, {self.num_workers}è¿›ç¨‹)",
                unit="video"
            )
        else:
            pbar = None
        
        # å‡†å¤‡å‚æ•°åˆ—è¡¨ï¼ˆåªä¼ é€’ index å’Œ segmentï¼‰
        args_list = [
            (index, segment)
            for index, segment in enumerate(self.data_source)
        ]
        
        # ä½¿ç”¨ Pool.imap è¿›è¡Œå¹¶è¡Œå¤„ç†ï¼ˆä¿æŒé¡ºåºï¼‰
        # ä½¿ç”¨ initializer è®©æ¯ä¸ªè¿›ç¨‹åªåˆå§‹åŒ–ä¸€æ¬¡
        with Pool(
            processes=self.num_workers,
            initializer=_init_worker,
            initargs=(self.saver.output_dir, self.frame_size, self.device_id, self.use_gpu)
        ) as pool:
            for result in pool.imap(_process_single_segment_worker, args_list):
                # ç»Ÿè®¡
                if result['success']:
                    self.stats['success'] += 1
                    self.stats['successful_samples'].append({
                        'sample_dir': result['sample_dir'],
                        'data_type': result['data_type'],
                        'vid': result['vid']
                    })
                else:
                    self.stats['failed'] += 1
                    self.stats['failed_samples'].append({
                        'vid': result['vid'],
                        'error': result['error_msg']
                    })
                    if self.stats['failed'] <= 10:
                        logger.warning(f"å¤„ç†å¤±è´¥: {result['vid']} - {result['error_msg']}")
                
                self.stats['processed'] += 1
                
                # æ›´æ–°è¿›åº¦
                if pbar:
                    pbar.update(1)
                    pbar.set_postfix({
                        'success': self.stats['success'],
                        'failed': self.stats['failed']
                    })
                
                # Yield ç»“æœï¼ˆæ·»åŠ é¢å¤–å­—æ®µä¿æŒå…¼å®¹ï¼‰
                result['batch_size'] = 1
                result['num_success'] = self.stats['success']
                result['num_failed'] = self.stats['failed']
                yield result
        
        if pbar:
            pbar.close()
    
    def run(self) -> Dict[str, Any]:
        """
        è¿è¡Œæ•´ä¸ª pipelineï¼ˆä¾¿æ·æ–¹æ³•ï¼‰
        
        Returns:
            stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        for _ in self:
            pass  # è¿­ä»£å®Œæˆ
        
        return self.get_stats()
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        
        if stats['start_time'] and stats['end_time']:
            elapsed = stats['end_time'] - stats['start_time']
            stats['elapsed_time'] = elapsed
            stats['speed'] = stats['success'] / elapsed if elapsed > 0 else 0
        
        return stats
    
    def summary(self):
        """æ‰“å°æ‘˜è¦"""
        stats = self.get_stats()
        
        logger.info("\n" + "=" * 60)
        logger.info("Pipeline å¤„ç†å®Œæˆ")
        logger.info("=" * 60)
        logger.info(f"æ€»æ•°: {stats['total']}")
        logger.info(f"æˆåŠŸ: {stats['success']}")
        logger.info(f"å¤±è´¥: {stats['failed']}")
        
        if 'elapsed_time' in stats:
            logger.info(f"è€—æ—¶: {stats['elapsed_time']/60:.2f} åˆ†é’Ÿ")
            logger.info(f"é€Ÿåº¦: {stats['speed']:.2f} è§†é¢‘/ç§’")
        
        # ä¿å­˜å¤±è´¥åˆ—è¡¨
        if stats['failed_samples']:
            failed_json = self.saver.output_dir / "failed_samples.json"
            with open(failed_json, 'w', encoding='utf-8') as f:
                json.dump(stats['failed_samples'], f, indent=2, ensure_ascii=False)
            logger.info(f"å¤±è´¥åˆ—è¡¨: {failed_json}")
        
        # ç”Ÿæˆ dataset_info.json
        self._generate_dataset_info(stats['successful_samples'])
        
        logger.info("=" * 60)
    
    def _generate_dataset_info(self, successful_samples: List[Dict[str, str]]):
        """
        ç”Ÿæˆ dataset_info.json
        
        æ ¹æ®å…ƒæ•°æ®ä¸­çš„ data_type å­—æ®µåˆ†é…æ ·æœ¬åˆ° train/val/test
        
        Args:
            successful_samples: æˆåŠŸå¤„ç†çš„æ ·æœ¬åˆ—è¡¨
                [
                    {
                        'sample_dir': '/path/to/sample_000000_xxx',
                        'data_type': 'train',
                        'vid': 'xxx'
                    },
                    ...
                ]
        """
        dataset_info_path = self.saver.output_dir / "dataset_info.json"
        
        # æ ¹æ® data_type åˆ†ç»„
        dataset_info = {
            "train": [],
            "val": [],
            "test": []
        }
        
        for sample in successful_samples:
            sample_dir = sample['sample_dir']
            data_type = sample.get('data_type', 'train')
            
            # ç¡®ä¿ data_type æœ‰æ•ˆ
            if data_type not in ['train', 'val', 'test']:
                logger.warning(f"æ— æ•ˆçš„ data_type: {data_type}ï¼Œé»˜è®¤ä¸º train")
                data_type = 'train'
            
            dataset_info[data_type].append(sample_dir)
        
        # ä¿å­˜
        with open(dataset_info_path, "w") as f:
            json.dump(dataset_info, f, indent=2)
        
        # æ‰“å°ç»Ÿè®¡
        logger.info(f"dataset_info.json ç”ŸæˆæˆåŠŸ:")
        logger.info(f"  train: {len(dataset_info['train'])} ä¸ªæ ·æœ¬")
        logger.info(f"  val:   {len(dataset_info['val'])} ä¸ªæ ·æœ¬")
        logger.info(f"  test:  {len(dataset_info['test'])} ä¸ªæ ·æœ¬")


# ============================================================
# Command Line Interface
# ============================================================

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="FFmpeg Video Processing Pipeline (Pure FFmpeg Implementation)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # åŸºæœ¬ä½¿ç”¨ (CPU æ¨¡å¼)
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata preprocessed_metadata.json \\
        --output-dir /path/to/output \\
        --num-workers 8

    # GPU åŠ é€Ÿ (NVDEC)
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata preprocessed_metadata.json \\
        --output-dir /path/to/output \\
        --use-gpu \\
        --device-id 0 \\
        --num-workers 4

    # è‡ªå®šä¹‰å‚æ•°
    python src/utils/generate_clip4mc_training_datas.py \\
        --metadata preprocessed_metadata.json \\
        --output-dir /path/to/output \\
        --num-workers 8 \\
        --frame-height 160 \\
        --frame-width 256

å…ƒæ•°æ® JSON æ ¼å¼:
    [
        {
            "vid": "abc123",
            "video_path": "/path/to/video.mp4",
            "start_time": 10.5,
            "end_time": 15.3,
            "transcript": "player mining diamond",
            "size": [0.3, 0.4, 0.5, ...],  # 16 ä¸ªå€¼
            "data_type": "train",  # 'train', 'val', 'test'
            "text_input_path": "/path/to/abc123_text_input.pkl"  # é¢„ç”Ÿæˆçš„ text_input.pkl
        },
        ...
    ]
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--metadata", type=Path, required=True,
                       help="é¢„å¤„ç†å¥½çš„å…ƒæ•°æ® JSON æ–‡ä»¶ï¼ˆåŒ…å« vid, video_path, start_time, end_time, transcript, sizeï¼‰")
    parser.add_argument("--output-dir", type=Path, required=True,
                       help="è¾“å‡ºç›®å½•")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--frame-height", type=int, default=160,
                       help="ç›®æ ‡å¸§é«˜åº¦ (é»˜è®¤: 160)")
    parser.add_argument("--frame-width", type=int, default=256,
                       help="ç›®æ ‡å¸§å®½åº¦ (é»˜è®¤: 256)")
    parser.add_argument("--device-id", type=int, default=0,
                       help="GPU ID (é»˜è®¤: 0)")
    parser.add_argument("--use-gpu", action='store_true',
                       help="ä½¿ç”¨ GPU ç¡¬ä»¶åŠ é€Ÿ (FFmpeg NVDEC)")
    parser.add_argument("--num-workers", type=int, default=1,
                       help="å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: 1ï¼Œå•çº¿ç¨‹)")
    parser.add_argument("--batch-size", type=int, default=1,
                       help="æ‰¹é‡å¤§å°ï¼ˆæš‚ä»…ç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰")
    parser.add_argument("--no-progress", action='store_true',
                       help="ç¦ç”¨è¿›åº¦æ¡")
    
    args = parser.parse_args()
    
    # åˆ›å»º pipeline
    pipeline = FFmpegPipeline(
        metadata_path=args.metadata,
        output_dir=args.output_dir,
        batch_size=args.batch_size,
        frame_size=(args.frame_height, args.frame_width),
        device_id=args.device_id,
        use_gpu=args.use_gpu,
        num_workers=args.num_workers,
        show_progress=not args.no_progress
    )
    
    # è¿è¡Œ pipeline
    pipeline.run()
    
    # æ‰“å°æ‘˜è¦
    pipeline.summary()
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())

