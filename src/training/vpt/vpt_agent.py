"""
VPT Agent Wrapper for MineDojo

æ¶æ„è®¾è®¡ï¼š
1. ç»„åˆå®˜æ–¹VPTçš„MineRLAgentï¼ˆä¸ä¿®æ”¹å®˜æ–¹ä»£ç ï¼‰
2. VPTAgentåªè´Ÿè´£MineDojoè§‚å¯Ÿ/åŠ¨ä½œçš„è½¬æ¢
3. æ‰€æœ‰VPTé€»è¾‘å®Œå…¨å§”æ‰˜ç»™å®˜æ–¹agent

å®˜æ–¹VPTå‚è€ƒï¼š
- https://github.com/openai/Video-Pre-Training
- æœ¬åœ°å®˜æ–¹ä»£ç ï¼šsrc/models/Video-Pre-Training/
- å·²ä¿®æ”¹ï¼šVideo-Pre-Training/lib/actions.pyä½¿ç”¨æœ¬åœ°mc.pyï¼ˆå»é™¤minerlä¾èµ–ï¼‰
"""

import sys
import numpy as np
from pathlib import Path

# æ·»åŠ å®˜æ–¹VPTä»£ç è·¯å¾„
VPT_PATH = Path(__file__).resolve().parent.parent.parent / "models" / "Video-Pre-Training"
if not VPT_PATH.exists():
    raise FileNotFoundError(f"å®˜æ–¹VPTä»£ç æœªæ‰¾åˆ°: {VPT_PATH}")

vpt_path_str = str(VPT_PATH)
if vpt_path_str not in sys.path:
    sys.path.insert(0, vpt_path_str)

try:
    # å¯¼å…¥å®˜æ–¹VPT Agentå’Œé…ç½®
    from agent import MineRLAgent, ENV_KWARGS
finally:
    # ç§»é™¤è·¯å¾„ï¼ˆä¿æŒsys.pathå¹²å‡€ï¼‰
    if vpt_path_str in sys.path:
        sys.path.remove(vpt_path_str)

from ..agent.agent_base import AgentBase


class MineRLActionToMineDojo:
    """MineRL Action -> MineDojo Action Converter"""

    def __init__(self, conflict_strategy='priority'):
        """
        Args:
            conflict_strategy: å†²çªå¤„ç†ç­–ç•¥
                - 'priority': ä¼˜å…ˆçº§ç­–ç•¥ï¼ˆforward > back, left > rightç­‰ï¼‰
                - 'cancel': å†²çªæ—¶å–æ¶ˆ
        """
        self.conflict_strategy = conflict_strategy
    
    def convert(self, minerl_action: dict, debug=False) -> np.ndarray:
        """
        å°†MineRLåŠ¨ä½œè½¬æ¢ä¸ºMineDojoåŠ¨ä½œ
        
        Args:
            minerl_action: MineRLæ ¼å¼çš„åŠ¨ä½œå­—å…¸
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
            
        Returns:
            MineDojoæ ¼å¼çš„åŠ¨ä½œæ•°ç»„ [8]
        """
        minedojo_action = np.zeros(8, dtype=np.int32)
        
        # å‰åç§»åŠ¨
        forward = minerl_action.get('forward', 0)
        back = minerl_action.get('back', 0)
        if forward and back:
            if self.conflict_strategy == 'priority':
                minedojo_action[0] = 1
        elif forward:
            minedojo_action[0] = 1
        elif back:
            minedojo_action[0] = 2
        
        # å·¦å³ç§»åŠ¨
        left = minerl_action.get('left', 0)
        right = minerl_action.get('right', 0)
        if left and right:
            if self.conflict_strategy == 'priority':
                minedojo_action[1] = 1
        elif left:
            minedojo_action[1] = 1
        elif right:
            minedojo_action[1] = 2
        
        # è·³è·ƒ/æ½œè¡Œ/ç–¾è·‘
        if minerl_action.get('jump', 0):
            minedojo_action[2] = 1
        elif minerl_action.get('sneak', 0):
            minedojo_action[2] = 2
        elif minerl_action.get('sprint', 0):
            minedojo_action[2] = 3
        
        # ç›¸æœº
        camera = minerl_action.get('camera', np.array([0.0, 0.0]))
        # cameraæ˜¯ä¸€ä¸ªnumpyæ•°ç»„ï¼Œå¯èƒ½æ˜¯[[x, y]]æˆ–[x, y]
        camera = np.asarray(camera).flatten()  # å±•å¹³ä¸º1Dæ•°ç»„
        camera_x = float(camera[0])
        camera_y = float(camera[1])
        minedojo_action[3] = int(np.clip(camera_x, -10, 10)) + 12
        minedojo_action[4] = int(np.clip(camera_y, -10, 10)) + 12
        
        # æ”»å‡»
        if minerl_action.get('attack', 0):
            minedojo_action[5] = 1
        
        # ä½¿ç”¨
        if minerl_action.get('use', 0):
            minedojo_action[6] = 1
        
        if debug:
            print(f"\n  ğŸ” MineRL Action:")
            active_keys = [k for k, v in minerl_action.items() if np.any(v != 0)]
            for key in active_keys:
                print(f"    {key}: {minerl_action[key]}")
            
            print(f"\n  ğŸ¯ MineDojo Action: {minedojo_action}")
        
        return minedojo_action


class VPTAgent(AgentBase):
    """
    VPT Agent for MineDojo - ç»„åˆæ¨¡å¼
    
    è®¾è®¡ï¼š
    1. æŒæœ‰ä¸€ä¸ªå®˜æ–¹MineRLAgentå®ä¾‹
    2. æ‰€æœ‰VPTæ“ä½œå§”æ‰˜ç»™å®˜æ–¹agent
    3. åªå®ç°MineDojo <-> MineRLçš„è½¬æ¢
    
    å®˜æ–¹VPTå‚è€ƒï¼š
    - GitHub: https://github.com/openai/Video-Pre-Training
    - æœ¬åœ°: src/models/Video-Pre-Training/agent.py
    """
    
    def __init__(
        self,
        vpt_weights_path: str,
        device: str = 'auto',
        conflict_strategy: str = 'priority',
        verbose: bool = False,
        debug_actions: bool = False
    ):
        """
        åˆå§‹åŒ–VPT Agent
        
        Args:
            vpt_weights_path: VPTé¢„è®­ç»ƒæƒé‡è·¯å¾„
            device: 'cpu', 'cuda', 'mps', or 'auto'
            conflict_strategy: MineRLâ†’MineDojoè½¬æ¢çš„å†²çªå¤„ç†ç­–ç•¥
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            debug_actions: æ˜¯å¦æ‰“å°åŠ¨ä½œè½¬æ¢è°ƒè¯•ä¿¡æ¯
        """
        super().__init__(device, verbose)
        
        self.vpt_weights_path = vpt_weights_path
        self.debug_actions = debug_actions
        
        if self.verbose:
            print("\n" + "="*70)
            print("ğŸ¤– åˆå§‹åŒ–VPT Agent (ç»„åˆå®˜æ–¹MineRLAgent)")
            print("="*70)
            print(f"æƒé‡: {vpt_weights_path}")
            print(f"è®¾å¤‡: {self.device}")
            print(f"å®˜æ–¹Agent: src/models/Video-Pre-Training/agent.py")
            print(f"é€‚é…å±‚: MineDojoè§‚å¯Ÿ/åŠ¨ä½œè½¬æ¢")
        
        # å¤„ç†è®¾å¤‡
        import torch as th
        if self.device == 'auto':
            if th.cuda.is_available():
                device_str = 'cuda'
            elif hasattr(th.backends, 'mps') and th.backends.mps.is_available():
                device_str = 'mps'
            else:
                device_str = 'cpu'
        else:
            device_str = self.device
        
        # ========================================
        # åˆ›å»ºå®˜æ–¹MineRLAgentï¼ˆç»„åˆæ¨¡å¼ï¼‰
        # ========================================
        # å®˜æ–¹agentéœ€è¦ä¸€ä¸ªMineRLç¯å¢ƒæ¥validate
        # ä½¿ç”¨MineRL 1.0+çš„HumanSurvivalç¯å¢ƒï¼ˆä¸å®˜æ–¹run_agent.pyç›¸åŒï¼‰
        from minerl.herobraine.env_specs.human_survival_specs import HumanSurvival
        
        # åˆ›å»ºMineRLç¯å¢ƒï¼ˆåªç”¨äºåˆå§‹åŒ–éªŒè¯ï¼‰
        # ä½¿ç”¨å®˜æ–¹ENV_KWARGSç¡®ä¿ç¯å¢ƒé…ç½®æ­£ç¡®
        minerl_env = HumanSurvival(**ENV_KWARGS).make()
        
        if self.verbose:
            print("\nğŸ“¦ åˆ›å»ºå®˜æ–¹MineRLAgent...")
        
        # åˆ›å»ºå®˜æ–¹agentï¼ˆå®Œå…¨ä½¿ç”¨å®˜æ–¹ä»£ç ï¼‰
        self.vpt_agent = MineRLAgent(
            env=minerl_env,
            device=device_str,
            policy_kwargs=None,  # ä½¿ç”¨å®˜æ–¹é»˜è®¤é…ç½®
            pi_head_kwargs=None
        )
        
        # å…³é—­MineRLç¯å¢ƒï¼ˆåªç”¨äºéªŒè¯ï¼Œä¸å†éœ€è¦ï¼‰
        minerl_env.close()
        
        # åŠ è½½æƒé‡ï¼ˆè°ƒç”¨å®˜æ–¹load_weightsæ–¹æ³•ï¼‰
        if self.verbose:
            print(f"ğŸ“¥ åŠ è½½VPTæƒé‡ï¼ˆè°ƒç”¨å®˜æ–¹load_weightsï¼‰...")
        
        self.vpt_agent.load_weights(vpt_weights_path)
        
        if self.verbose:
            print(f"  âœ“ å®˜æ–¹MineRLAgentåˆ›å»ºå®Œæˆ")
            print(f"  âœ“ policy.actä¼šè‡ªåŠ¨æ·»åŠ æ—¶é—´ç»´åº¦T")
        
        # ========================================
        # åˆ›å»ºMineDojoé€‚é…å±‚
        # ========================================
        self.action_converter = MineRLActionToMineDojo(conflict_strategy)
        
        if self.verbose:
            print("\nâœ… VPT Agentåˆå§‹åŒ–å®Œæˆ!")
            print("="*70)
    
    def reset(self):
        """
        é‡ç½®Agent - ç›´æ¥è°ƒç”¨å®˜æ–¹agent.reset()
        """
        self.vpt_agent.reset()
        if self.verbose:
            print("ğŸ”„ VPT Agent reset (è°ƒç”¨å®˜æ–¹agent.reset)")
    
    def _convert_obs_to_minerl(self, minedojo_obs) -> dict:
        """
        Convert MineDojo observation to MineRL format
        
        MineDojo returns CHW format (C, H, W), but MineRL/VPT expects HWC format (H, W, C).
        This method handles the conversion.
        
        Args:
            minedojo_obs: MineDojo observation
                - Can be dict with 'rgb' key: {'rgb': [C, H, W]}
                - Or numpy array: [C, H, W] uint8
        
        Returns:
            MineRL observation dict: {"pov": [H, W, C] uint8}
        """
        # Extract POV from observation
        if isinstance(minedojo_obs, dict):
            pov = minedojo_obs['rgb']
        else:
            pov = minedojo_obs
        
        # Validate POV is numpy array
        if not isinstance(pov, np.ndarray):
            raise TypeError(f"POV must be numpy array, got {type(pov)}")
        
        # Convert CHW to HWC if needed
        # MineDojo: (C, H, W) -> MineRL: (H, W, C)
        if pov.shape[0] == 3 and len(pov.shape) == 3:
            pov = np.transpose(pov, (1, 2, 0))  # (C, H, W) -> (H, W, C)
        
        # Ensure contiguous array for cv2.resize
        pov = np.ascontiguousarray(pov)
        
        return {"pov": pov}
    
    def predict(self, minedojo_obs, deterministic: bool = False) -> np.ndarray:
        """
        Predict MineDojo action using VPT agent
        
        Pipeline:
        1. Convert MineDojo obs -> MineRL obs (adapter layer)
        2. Call official agent.get_action()
        3. Convert MineRL action -> MineDojo action (adapter layer)
        
        Args:
            minedojo_obs: MineDojo observation
                - Can be dict with 'rgb' key: {'rgb': [C, H, W]}
                - Or numpy array: [C, H, W] uint8
            deterministic: Whether to use deterministic prediction (VPT defaults to stochastic)
            
        Returns:
            MineDojo action [8] int32
        """
        # Step 1: Convert MineDojo obs -> MineRL obs
        minerl_obs = self._convert_obs_to_minerl(minedojo_obs)
        
        # Step 2: Call official agent.get_action()
        minerl_action = self.vpt_agent.get_action(minerl_obs)
        
        # Step 3: Convert MineRL action -> MineDojo action
        minedojo_action = self.action_converter.convert(
            minerl_action,
            debug=self.debug_actions
        )
        
        return minedojo_action


# For backward compatibility
MineRLToMinedojoConverter = MineRLActionToMineDojo
