"""
VPT Agent for MineDojo Training/Evaluation

æ¶æ„å±‚æ¬¡ï¼š
1. src/models/vpt/agent.py::MineRLAgent - å®˜æ–¹VPTå®ç°ï¼ˆä¸ä¿®æ”¹ï¼‰
2. src/models/vpt/minedojo_agent.py::MineDojoAgent - MineDojoé€‚é…å±‚ï¼ˆé‡è½½obs/actionè½¬æ¢ï¼‰
3. src/training/vpt/vpt_agent.py::VPTAgent - è®­ç»ƒ/è¯„ä¼°æ¥å£ï¼ˆæœ¬æ–‡ä»¶ï¼Œå®ç°AgentBaseï¼‰

VPTAgentèŒè´£ï¼š
- å¤šé‡ç»§æ‰¿: MineDojoAgentï¼ˆæä¾›VPTåŠŸèƒ½ï¼‰+ AgentBaseï¼ˆæä¾›ç»Ÿä¸€æ¥å£ï¼‰
- å®ç° predict() æ–¹æ³•ï¼ˆAgentBaseè¦æ±‚ï¼‰
- å®ç° reset() æ–¹æ³•ï¼ˆAgentBaseè¦æ±‚ï¼‰
- æä¾›è®­ç»ƒ/è¯„ä¼°æ‰€éœ€çš„ç»Ÿä¸€æ¥å£

å®˜æ–¹VPTå‚è€ƒï¼š
- GitHub: https://github.com/openai/Video-Pre-Training
- æœ¬åœ°VPTä»£ç ï¼šsrc/models/vpt/
"""

import sys
import numpy as np
from pathlib import Path

# æ·»åŠ  VPT ä»£ç è·¯å¾„
VPT_PATH = Path(__file__).resolve().parent.parent.parent / "models" / "vpt"
if not VPT_PATH.exists():
    raise FileNotFoundError(f"VPTä»£ç æœªæ‰¾åˆ°: {VPT_PATH}")

vpt_path_str = str(VPT_PATH)
if vpt_path_str not in sys.path:
    sys.path.insert(0, vpt_path_str)

try:
    from minedojo_agent import MineDojoAgent
    from agent import ENV_KWARGS
finally:
    if vpt_path_str in sys.path:
        sys.path.remove(vpt_path_str)

from ..agent.agent_base import AgentBase


class VPTAgent(MineDojoAgent, AgentBase):
    """
    VPT Agent for MineDojo Training/Evaluation
    
    å¤šé‡ç»§æ‰¿ï¼š
    - MineDojoAgent: æä¾›VPTæ ¸å¿ƒåŠŸèƒ½å’ŒMineDojoé€‚é…
    - AgentBase: æä¾›ç»Ÿä¸€çš„è®­ç»ƒ/è¯„ä¼°æ¥å£
    
    ä½¿ç”¨æ–¹å¼ï¼š
        agent = VPTAgent(
            vpt_weights_path='path/to/weights.weights',
            device='auto',
            cam_interval=0.01
        )
        
        # è®­ç»ƒ/è¯„ä¼°
        obs = env.reset()
        action = agent.predict(obs, deterministic=True)
        
        # é‡ç½®
        agent.reset()
    """
    
    def __init__(
        self,
        vpt_weights_path: str,
        device: str = 'auto',
        cam_interval: float = 0.01,
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–VPT Agent
        
        Args:
            vpt_weights_path: VPTé¢„è®­ç»ƒæƒé‡è·¯å¾„
            device: 'cpu', 'cuda', 'mps', or 'auto'
            cam_interval: MineDojoç¯å¢ƒçš„cameraé—´éš”ï¼ˆåº¦æ•°ï¼‰
                - 0.01 = 0.01åº¦ç²¾åº¦ï¼ˆæ¨èï¼ŒåŒ¹é…VPTçš„[-10,10]èŒƒå›´ï¼‰
                - 1.0 = 1åº¦ç²¾åº¦
                - 15.0 = 15åº¦ç²¾åº¦ï¼ˆMineDojoé»˜è®¤ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        # ä¿å­˜å‚æ•°
        self.vpt_weights_path = vpt_weights_path
        self.verbose = verbose
        
        # å¤„ç†è®¾å¤‡
        import torch as th
        if device == 'auto':
            if th.cuda.is_available():
                device_str = 'cuda'
            elif hasattr(th.backends, 'mps') and th.backends.mps.is_available():
                device_str = 'mps'
            else:
                device_str = 'cpu'
        else:
            device_str = device
        
        if self.verbose:
            print("\n" + "="*70)
            print("ğŸ¤– åˆå§‹åŒ– VPT Agent for MineDojo")
            print("="*70)
            print(f"æƒé‡: {vpt_weights_path}")
            print(f"è®¾å¤‡: {device_str}")
            print(f"Cameraç²¾åº¦: {cam_interval}åº¦/å•ä½")
            print("="*70)
        
        # åˆ›å»ºä¸´æ—¶ MineRL ç¯å¢ƒç”¨äºåˆå§‹åŒ–éªŒè¯
        from minerl.herobraine.env_specs.human_survival_specs import HumanSurvival
        minerl_env = HumanSurvival(**ENV_KWARGS).make()
        
        try:
            # åˆå§‹åŒ– MineDojoAgentï¼ˆä¼šè°ƒç”¨MineRLAgent.__init__ï¼‰
            MineDojoAgent.__init__(
                self,
                env=minerl_env,
                device=device_str,
                policy_kwargs=None,
                pi_head_kwargs=None,
                cam_interval=cam_interval
            )
            
            # åˆå§‹åŒ– AgentBase
            AgentBase.__init__(self, device=device_str, verbose=verbose)
            
            # åŠ è½½æƒé‡
            if self.verbose:
                print(f"\nğŸ“¥ åŠ è½½VPTæƒé‡...")
            
            self.load_weights(vpt_weights_path)
            
            if self.verbose:
                print(f"âœ… VPT Agentåˆå§‹åŒ–å®Œæˆ!")
                print("="*70)
        
        finally:
            # å…³é—­ä¸´æ—¶ç¯å¢ƒ
            minerl_env.close()
    
    def predict(self, obs, deterministic: bool = False) -> np.ndarray:
        """
        é¢„æµ‹åŠ¨ä½œï¼ˆAgentBaseæ¥å£è¦æ±‚ï¼‰
        
        Args:
            obs: MineDojoè§‚å¯Ÿ {'rgb': [C, H, W]}
            deterministic: æ˜¯å¦ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼ˆVPTå¿½ç•¥æ­¤å‚æ•°ï¼Œæ€»æ˜¯ç¡®å®šæ€§ï¼‰
        
        Returns:
            MineDojoåŠ¨ä½œæ•°ç»„ [8]
        """
        # è°ƒç”¨ get_action (ç»§æ‰¿è‡ªMineRLAgent)
        # å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨é‡è½½çš„ _env_obs_to_agent å’Œ _agent_action_to_env
        return self.get_action(obs)
    
    def reset(self):
        """
        é‡ç½®AgentçŠ¶æ€ï¼ˆAgentBaseæ¥å£è¦æ±‚ï¼‰
        
        è°ƒç”¨ MineRLAgent.reset() æ¥é‡ç½®éšè—çŠ¶æ€
        """
        # MineRLAgent.reset() ç»§æ‰¿è‡ªçˆ¶ç±»
        super(MineDojoAgent, self).reset()  # è°ƒç”¨ MineRLAgent.reset()
        
        if self.verbose:
            print("ğŸ”„ VPT Agent reset")
    
    def __repr__(self):
        return (
            f"VPTAgent(\n"
            f"  weights='{self.vpt_weights_path}',\n"
            f"  device='{self.device}',\n"
            f"  cam_interval={self.cam_interval}\n"
            f")"
        )


# å‘åå…¼å®¹ï¼šå¯¼å‡ºæ—§çš„ç±»å
MineRLToMinedojoConverter = None  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥é¿å…ç ´åæ€§æ›´æ”¹
