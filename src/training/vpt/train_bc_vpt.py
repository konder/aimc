#!/usr/bin/env python3
"""
ä½¿ç”¨VPTé¢„è®­ç»ƒæƒé‡è¿›è¡ŒBCè®­ç»ƒ

æ ¸å¿ƒæ”¹è¿›ï¼š
1. âœ… ä½¿ç”¨çœŸæ­£çš„VPT MinecraftPolicyï¼ˆä»å®˜æ–¹ä»“åº“ï¼‰
2. âœ… æ­£ç¡®åŠ è½½VPTæƒé‡ï¼ˆä¿®å¤keyå‰ç¼€é—®é¢˜ï¼‰
3. âœ… MineDojo action spaceé€‚é…
4. âœ… ä¸“å®¶æ•°æ®åŠ è½½å’Œå¢å¼º
"""

import os
import sys
import argparse
import numpy as np
import torch as th
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
from tqdm import tqdm
import yaml
from datetime import datetime
from typing import Dict, List, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
sys.path.insert(0, PROJECT_ROOT)

# æ·»åŠ externalè·¯å¾„ï¼ˆç”¨äºminerlä¾èµ–ï¼‰
EXTERNAL_PATH = os.path.join(PROJECT_ROOT, 'external')
sys.path.insert(0, EXTERNAL_PATH)

from src.models.vpt.weights_loader import load_vpt_policy, create_vpt_policy
from src.models.vpt.lib.policy import MinecraftPolicy


class MinedojoActionAdapter(nn.Module):
    """
    é€‚é…VPTçš„MineRL action spaceåˆ°MineDojo
    
    MineRL: å¤æ‚çš„hierarchical action space
    MineDojo: MultiDiscrete [3, 3, 4, 25, 25, 8, 244, 36]
    """
    
    def __init__(self, vpt_policy: MinecraftPolicy):
        super().__init__()
        self.vpt_policy = vpt_policy
        
        # MineDojo action dimensions
        self.minedojo_action_dim = [3, 3, 4, 25, 25, 8, 244, 36]
        
        # åˆ›å»ºaction headå°†VPTçš„latentæ˜ å°„åˆ°MineDojo action space
        hidden_dim = 2048  # VPTçš„hidsize
        self.action_heads = nn.ModuleList([
            nn.Linear(hidden_dim, dim) for dim in self.minedojo_action_dim
        ])
        
        print(f"MinedojoActionAdapteråˆ›å»º:")
        print(f"  MineDojo action dims: {self.minedojo_action_dim}")
        print(f"  Action headså‚æ•°: {sum(p.numel() for p in self.action_heads.parameters()):,}")
    
    def forward(self, obs):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            obs: (B, H, W, C) å›¾åƒè§‚å¯Ÿï¼ŒèŒƒå›´[0, 1]
        
        Returns:
            action_logits: List of (B, action_dim[i])
        """
        batch_size = obs.shape[0]
        
        # æ·»åŠ æ—¶é—´ç»´åº¦ï¼š(B, H, W, C) -> (B, T=1, H, W, C)
        # ImpalaCNNæœŸæœ›BHWCæ ¼å¼ï¼Œä¼šå†…éƒ¨è½¬æ¢æˆBCHW
        obs_vpt = obs.unsqueeze(1)  # (B, 1, H, W, C)
        
        # é€šè¿‡VPTçš„è§†è§‰encoder
        # img_preprocess: å½’ä¸€åŒ–åˆ°[0, 1]ï¼ˆå¦‚æœè¾“å…¥å·²ç»æ˜¯[0,1]åˆ™ä¸å˜ï¼‰
        x = self.vpt_policy.img_preprocess(obs_vpt)  # (B, 1, H, W, C)
        
        # img_process: CNNç‰¹å¾æå– + linear
        # ImpalaCNNå†…éƒ¨ä¼šreshapeæˆ (B*T, C, H, W)ï¼Œå¤„ç†åreshapeå› (B, T, feature_dim)
        x = self.vpt_policy.img_process(x)  # (B, 1, feature_dim)
        
        # ç§»é™¤æ—¶é—´ç»´åº¦ (B, 1, feature_dim) -> (B, feature_dim)
        x = x.squeeze(1)
        
        # lastlayer: æ˜ å°„åˆ°hidsize
        latent = self.vpt_policy.lastlayer(x)  # (B, hidsize=2048)
        
        # é€šè¿‡MineDojo action heads
        action_logits = [head(latent) for head in self.action_heads]
        
        return action_logits


class ExpertDataset(Dataset):
    """ä¸“å®¶æ•°æ®é›†ï¼ˆä»Webå½•åˆ¶ç³»ç»Ÿçš„æ•°æ®æ ¼å¼åŠ è½½ï¼‰"""
    
    def __init__(self, expert_dir: str, target_size=(128, 128)):
        """
        Args:
            expert_dir: ä¸“å®¶æ¼”ç¤ºç›®å½•ï¼ˆåŒ…å«episode_000, episode_001ç­‰ï¼‰
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸ (H, W)ï¼ŒVPTä½¿ç”¨128x128
        """
        import cv2
        self.expert_dir = expert_dir
        self.target_size = target_size
        self.cv2 = cv2
        
        # æŸ¥æ‰¾æ‰€æœ‰episodeç›®å½•
        episode_dirs = []
        for item in sorted(os.listdir(expert_dir)):
            item_path = os.path.join(expert_dir, item)
            if os.path.isdir(item_path) and item.startswith('episode_'):
                episode_dirs.append(item_path)
        
        print(f"æ‰¾åˆ° {len(episode_dirs)} ä¸ªepisodeç›®å½•")
        
        # é¢„åŠ è½½æ‰€æœ‰æ•°æ®
        self.all_obs = []
        self.all_actions = []
        
        for ep_path in tqdm(episode_dirs, desc="Loading data"):
            # æŸ¥æ‰¾æ‰€æœ‰frameæ–‡ä»¶
            frame_files = sorted([f for f in os.listdir(ep_path) 
                                if f.startswith('frame_') and f.endswith('.npy')])
            
            if len(frame_files) == 0:
                continue
            
            # åŠ è½½æ¯ä¸ªframe
            for frame_file in frame_files:
                frame_path = os.path.join(ep_path, frame_file)
                try:
                    # åŠ è½½.npyæ–‡ä»¶ï¼ˆåŒ…å«observationå’Œactionï¼‰
                    data = np.load(frame_path, allow_pickle=True).item()
                    
                    # æå–è§‚å¯Ÿå’ŒåŠ¨ä½œ
                    obs = data['observation']  # RGBå›¾åƒ (H, W, C)
                    action = data['action']    # MineDojoåŠ¨ä½œ (8,)
                    
                    self.all_obs.append(obs)
                    self.all_actions.append(action)
                    
                except Exception as e:
                    print(f"è­¦å‘Š: åŠ è½½ {frame_path} å¤±è´¥: {e}")
                    continue
        
        if len(self.all_obs) == 0:
            raise ValueError(f"æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®ï¼è¯·æ£€æŸ¥ç›®å½•: {expert_dir}")
        
        print(f"âœ“ åŠ è½½å®Œæˆ")
        print(f"  æ€»æ ·æœ¬æ•°: {len(self.all_obs)}")
        print(f"  åŸå§‹å›¾åƒshape: {self.all_obs[0].shape}")
        print(f"  ç›®æ ‡å›¾åƒshape: {target_size}")
        print(f"  åŠ¨ä½œshape: {self.all_actions[0].shape}")
        print(f"  åŠ¨ä½œç»´åº¦: {len(self.all_actions[0])}")
    
    def __len__(self):
        return len(self.all_obs)
    
    def __getitem__(self, idx):
        obs = self.all_obs[idx]  # å¯èƒ½æ˜¯ (C, H, W) æˆ– (H, W, C)
        action = self.all_actions[idx]  # (action_dim,)
        
        # æ£€æŸ¥å¹¶è½¬æ¢ä¸ºHWCæ ¼å¼
        if obs.shape[0] == 3 or obs.shape[0] == 1:  # å¾ˆå¯èƒ½æ˜¯CHWæ ¼å¼
            if len(obs.shape) == 3 and obs.shape[0] < obs.shape[1] and obs.shape[0] < obs.shape[2]:
                # (C, H, W) -> (H, W, C)
                obs = np.transpose(obs, (1, 2, 0))
        
        # ç¡®ä¿æ˜¯uint8ç±»å‹
        if obs.dtype != np.uint8:
            if obs.max() <= 1.0:
                obs = (obs * 255).astype(np.uint8)
            else:
                obs = obs.astype(np.uint8)
        
        # Resizeå›¾åƒåˆ°VPTæœŸæœ›çš„å°ºå¯¸
        if obs.shape[:2] != self.target_size:
            obs = self.cv2.resize(obs, (self.target_size[1], self.target_size[0]), 
                                 interpolation=self.cv2.INTER_LINEAR)
        
        # è½¬æ¢ä¸ºtensor
        # å›¾åƒ: (H, W, C) uint8 [0, 255] -> (H, W, C) float32 [0, 1]
        obs = th.from_numpy(obs).float() / 255.0
        
        # åŠ¨ä½œ: (action_dim,) -> long
        action = th.from_numpy(action).long()
        
        return obs, action


class BCTrainer:
    """BCè®­ç»ƒå™¨ï¼ˆä½¿ç”¨VPTåˆå§‹åŒ–ï¼‰"""
    
    def __init__(
        self,
        model: nn.Module,
        learning_rate: float = 1e-4,
        device: str = "auto"
    ):
        if device == "auto":
            if th.cuda.is_available():
                device = "cuda"
            elif th.backends.mps.is_available():
                device = "mps"
            else:
                device = "cpu"
        
        self.device = device
        self.model = model.to(device)
        
        # ä¼˜åŒ–å™¨ - ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆå› ä¸ºæ˜¯å¾®è°ƒï¼‰
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=1e-5
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        param_count = sum(p.numel() for p in model.parameters())
        trainable_count = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"BC Traineråˆå§‹åŒ–:")
        print(f"  è®¾å¤‡: {device}")
        print(f"  å­¦ä¹ ç‡: {learning_rate}")
        print(f"  æ€»å‚æ•°: {param_count:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_count:,}")
    
    def compute_loss(self, obs_batch, action_batch):
        """è®¡ç®—BCæŸå¤±"""
        obs_batch = obs_batch.to(self.device)
        action_batch = action_batch.to(self.device)
        
        # å‰å‘ä¼ æ’­
        action_logits = self.model(obs_batch)  # List of (B, action_dim[i])
        
        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„æŸå¤±
        losses = []
        for i, logits in enumerate(action_logits):
            target = action_batch[:, i]
            loss = self.criterion(logits, target)
            losses.append(loss)
        
        total_loss = sum(losses)
        return total_loss, losses
    
    def train_epoch(self, dataloader: DataLoader, epoch: int) -> dict:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0
        total_correct = [0] * 8  # MineDojo action_dim
        total_samples = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch}")
        
        for obs_batch, action_batch in pbar:
            # è®¡ç®—æŸå¤±
            loss, losses = self.compute_loss(obs_batch, action_batch)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            th.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_samples += obs_batch.size(0)
            
            # è®¡ç®—å‡†ç¡®ç‡
            with th.no_grad():
                obs_batch = obs_batch.to(self.device)
                action_batch = action_batch.to(self.device)
                action_logits = self.model(obs_batch)
                
                for i, logits in enumerate(action_logits):
                    pred = logits.argmax(dim=-1)
                    target = action_batch[:, i]
                    correct = (pred == target).sum().item()
                    total_correct[i] += correct
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'avg_loss': f"{total_loss / (pbar.n + 1):.4f}"
            })
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_loss = total_loss / len(dataloader)
        accuracies = [correct / total_samples for correct in total_correct]
        avg_accuracy = np.mean(accuracies)
        
        return {
            'loss': avg_loss,
            'accuracy': avg_accuracy,
            'accuracies': accuracies
        }
    
    def validate(self, dataloader: DataLoader) -> dict:
        """éªŒè¯"""
        self.model.eval()
        
        total_loss = 0
        total_correct = [0] * 8
        total_samples = 0
        
        with th.no_grad():
            for obs_batch, action_batch in tqdm(dataloader, desc="Validating"):
                loss, losses = self.compute_loss(obs_batch, action_batch)
                total_loss += loss.item()
                
                obs_batch = obs_batch.to(self.device)
                action_batch = action_batch.to(self.device)
                action_logits = self.model(obs_batch)
                
                for i, logits in enumerate(action_logits):
                    pred = logits.argmax(dim=-1)
                    target = action_batch[:, i]
                    correct = (pred == target).sum().item()
                    total_correct[i] += correct
                
                total_samples += obs_batch.size(0)
        
        avg_loss = total_loss / len(dataloader)
        accuracies = [correct / total_samples for correct in total_correct]
        avg_accuracy = np.mean(accuracies)
        
        return {
            'loss': avg_loss,
            'accuracy': avg_accuracy,
            'accuracies': accuracies
        }
    
    def save_checkpoint(self, path: str, epoch: int, metrics: dict):
        """ä¿å­˜checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'metrics': metrics,
            'vpt_weights_path': getattr(self, 'vpt_weights_path', None),
            'freeze_vpt': getattr(self, 'freeze_vpt', False)
        }
        th.save(checkpoint, path)
        print(f"âœ“ Checkpointä¿å­˜: {path}")


def main():
    parser = argparse.ArgumentParser(description="VPT BCè®­ç»ƒ")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--expert-dir", type=str, 
                       default="data/tasks/harvest_1_log/expert_demos",
                       help="ä¸“å®¶æ¼”ç¤ºç›®å½•")
    parser.add_argument("--val-split", type=float, default=0.1,
                       help="éªŒè¯é›†æ¯”ä¾‹")
    
    # VPTå‚æ•°
    parser.add_argument("--vpt-weights", type=str,
                       default="data/pretrained/vpt/rl-from-early-game-2x.weights",
                       help="VPT weightsæ–‡ä»¶")
    parser.add_argument("--no-pretrain", action="store_true",
                       help="ä¸ä½¿ç”¨VPTé¢„è®­ç»ƒ")
    parser.add_argument("--freeze-vpt", action="store_true",
                       help="å†»ç»“VPTè§†è§‰ç‰¹å¾æå–å™¨ï¼ˆæ¨èï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼‰")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=20,
                       help="è®­ç»ƒepochs")
    parser.add_argument("--batch-size", type=int, default=32,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning-rate", type=float, default=1e-4,
                       help="å­¦ä¹ ç‡ï¼ˆå†»ç»“VPTæ—¶å»ºè®®ç”¨1e-4ï¼Œå…¨å‚æ•°å¾®è°ƒæ—¶å»ºè®®ç”¨1e-5ï¼‰")
    parser.add_argument("--device", type=str, default="auto",
                       help="è®­ç»ƒè®¾å¤‡")
    parser.add_argument("--num-workers", type=int, default=0,
                       help="æ•°æ®åŠ è½½çº¿ç¨‹æ•°")
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument("--output-dir", type=str,
                       default="data/tasks/harvest_1_log/vpt_bc_model",
                       help="æœ€ç»ˆæ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆbest_model.pth, final_model.pth, configç­‰ï¼‰")
    parser.add_argument("--checkpoint-dir", type=str, default=None,
                       help="Checkpointä¿å­˜ç›®å½•ï¼ˆå¦‚ä¸æŒ‡å®šï¼Œåˆ™ä½¿ç”¨output-dirï¼‰ã€‚å¯æŒ‡å‘å¤§å®¹é‡ç£ç›˜")
    parser.add_argument("--save-freq", type=int, default=5,
                       help="ä¿å­˜checkpointé¢‘ç‡ï¼ˆè®¾ä¸º0åˆ™ä¸ä¿å­˜checkpointï¼Œåªä¿å­˜best/finalï¼‰")
    parser.add_argument("--keep-checkpoints", type=int, default=3,
                       help="ä¿ç•™çš„checkpointæ•°é‡ï¼ˆé˜²æ­¢ç£ç›˜å ç”¨è¿‡å¤§ï¼‰")
    
    args = parser.parse_args()
    
    # å¦‚æœæœªæŒ‡å®šcheckpoint-dirï¼Œåˆ™ä½¿ç”¨output-dir
    if args.checkpoint_dir is None:
        args.checkpoint_dir = args.output_dir
    
    print("=" * 70)
    print("ğŸš€ VPT BCè®­ç»ƒ")
    print("=" * 70)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    
    # ä¿å­˜é…ç½®
    config_path = os.path.join(args.output_dir, "train_config.yaml")
    with open(config_path, 'w') as f:
        yaml.dump(vars(args), f, default_flow_style=False)
    print(f"é…ç½®ä¿å­˜: {config_path}")
    print(f"æ¨¡å‹è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"Checkpointç›®å½•: {args.checkpoint_dir}")
    if args.checkpoint_dir != args.output_dir:
        print(f"  â„¹ï¸  Checkpointä½¿ç”¨ç‹¬ç«‹ç›®å½•ï¼ˆå¤§å®¹é‡ç£ç›˜ï¼‰")
    print()
    
    # åŠ è½½æ•°æ®
    print("ğŸ“‚ åŠ è½½ä¸“å®¶æ•°æ®...")
    full_dataset = ExpertDataset(args.expert_dir)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    val_size = int(len(full_dataset) * args.val_split)
    train_size = len(full_dataset) - val_size
    train_dataset, val_dataset = random_split(
        full_dataset,
        [train_size, val_size],
        generator=th.Generator().manual_seed(42)
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )
    
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    print(f"  Batchå¤§å°: {args.batch_size}\n")
    
    # åˆ›å»ºVPT policy
    print("ğŸ¤– åˆ›å»ºVPT Policy...")
    if not args.no_pretrain:
        print(f"  åŠ è½½VPTé¢„è®­ç»ƒæƒé‡: {args.vpt_weights}")
        vpt_policy, result = load_vpt_policy(args.vpt_weights, device='cpu', verbose=False)
        print(f"  âœ“ VPTæƒé‡åŠ è½½æˆåŠŸ (Missing: {len(result.missing_keys)}, Unexpected: {len(result.unexpected_keys)})")
    else:
        print("  ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼ˆ--no-pretrainï¼‰")
        vpt_policy = create_vpt_policy(device='cpu')
    
    # åˆ›å»ºMineDojoé€‚é…å™¨
    print("\nğŸ”„ åˆ›å»ºMineDojoé€‚é…å™¨...")
    model = MinedojoActionAdapter(vpt_policy)
    
    # å‚æ•°å†»ç»“ç­–ç•¥ï¼ˆé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼‰
    if not args.no_pretrain and args.freeze_vpt:
        print("\nâ„ï¸  å†»ç»“VPTå‚æ•°...")
        frozen_params = 0
        trainable_params = 0
        
        for name, param in model.named_parameters():
            # ç­–ç•¥ï¼šå†»ç»“æ‰€æœ‰vpt_policyå‚æ•°ï¼Œåªè®­ç»ƒaction_heads
            if 'vpt_policy' in name:
                param.requires_grad = False
                frozen_params += param.numel()
            else:
                # action_headsä¿æŒå¯è®­ç»ƒ
                trainable_params += param.numel()
        
        print(f"  å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params/(frozen_params+trainable_params)*100:.1f}%)")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/(frozen_params+trainable_params)*100:.1f}%)")
        print(f"  ç­–ç•¥: å†»ç»“æ•´ä¸ªVPTæ¨¡å‹ï¼Œåªè®­ç»ƒMineDojo action heads")
        print(f"  ä¼˜åŠ¿: å®Œå…¨ä¿ç•™VPTé¢„è®­ç»ƒçŸ¥è¯†ï¼ˆè·³è·ƒã€ç§»åŠ¨ã€æˆ˜æ–—ç­‰ï¼‰ï¼Œåªå­¦ä¹ åŠ¨ä½œæ˜ å°„")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    print("\nğŸ“ åˆ›å»ºBCè®­ç»ƒå™¨...")
    trainer = BCTrainer(
        model=model,
        learning_rate=args.learning_rate,
        device=args.device
    )
    
    # ä¿å­˜è®­ç»ƒé…ç½®åˆ°trainerï¼ˆç”¨äºcheckpointï¼‰
    trainer.vpt_weights_path = args.vpt_weights if not args.no_pretrain else None
    trainer.freeze_vpt = args.freeze_vpt
    
    # è®­ç»ƒ
    print("\n" + "=" * 70)
    print("å¼€å§‹è®­ç»ƒ")
    print("=" * 70)
    
    best_val_loss = float('inf')
    train_history = []
    
    for epoch in range(1, args.epochs + 1):
        print(f"\nEpoch {epoch}/{args.epochs}")
        print("-" * 70)
        
        # è®­ç»ƒ
        train_metrics = trainer.train_epoch(train_loader, epoch)
        print(f"è®­ç»ƒ - Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}")
        
        # éªŒè¯
        val_metrics = trainer.validate(val_loader)
        print(f"éªŒè¯ - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}")
        
        # è¯¦ç»†å‡†ç¡®ç‡
        print(f"  å„ç»´åº¦å‡†ç¡®ç‡: {[f'{acc:.3f}' for acc in val_metrics['accuracies']]}")
        
        # è®°å½•å†å²
        train_history.append({
            'epoch': epoch,
            'train': train_metrics,
            'val': val_metrics
        })
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            best_path = os.path.join(args.output_dir, "best_model.pth")
            trainer.save_checkpoint(best_path, epoch, val_metrics)
            print(f"  âœ“ æ–°çš„æœ€ä½³æ¨¡å‹ï¼")
        
        # å®šæœŸä¿å­˜checkpointï¼ˆåªä¿ç•™æœ€æ–°çš„Nä¸ªï¼‰
        if args.save_freq > 0 and epoch % args.save_freq == 0:
            ckpt_path = os.path.join(args.checkpoint_dir, f"checkpoint_epoch_{epoch}.pth")
            trainer.save_checkpoint(ckpt_path, epoch, val_metrics)
            
            # æ¸…ç†æ—§çš„checkpointï¼Œåªä¿ç•™æœ€æ–°çš„Nä¸ª
            checkpoint_files = sorted([
                f for f in os.listdir(args.checkpoint_dir) 
                if f.startswith('checkpoint_epoch_') and f.endswith('.pth')
            ], key=lambda x: int(x.split('_')[-1].split('.')[0]))
            
            # åˆ é™¤æ—§çš„checkpointï¼ˆä¿ç•™æœ€æ–°Nä¸ªï¼‰
            if len(checkpoint_files) > args.keep_checkpoints:
                for old_ckpt in checkpoint_files[:-args.keep_checkpoints]:
                    old_path = os.path.join(args.checkpoint_dir, old_ckpt)
                    try:
                        os.remove(old_path)
                        print(f"  ğŸ—‘ï¸  åˆ é™¤æ—§checkpoint: {old_ckpt}")
                    except Exception as e:
                        print(f"  âš ï¸  åˆ é™¤å¤±è´¥: {e}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = os.path.join(args.output_dir, "final_model.pth")
    trainer.save_checkpoint(final_path, args.epochs, val_metrics)
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = os.path.join(args.output_dir, "train_history.yaml")
    with open(history_path, 'w') as f:
        yaml.dump(train_history, f, default_flow_style=False)
    
    print("\n" + "=" * 70)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print("=" * 70)
    print(f"æœ€ä½³éªŒè¯loss: {best_val_loss:.4f}")
    print(f"æ¨¡å‹ä¿å­˜åœ¨: {args.output_dir}/")
    print("\nä¸‹ä¸€æ­¥:")
    print(f"  python src/training/evaluate_bc_vpt.py --model {args.output_dir}/best_model.pth")


if __name__ == "__main__":
    main()
