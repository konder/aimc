# VPTæƒé‡åŠ è½½è¯¦è§£

**ğŸ“š é‡è¦æ›´æ–°ï¼š** æœ¬æ–‡æ¡£å·²æ›´æ–°ä¸ºå‡†ç¡®æè¿°OpenAIå®˜æ–¹VPTçš„å®ç°æ–¹å¼ã€‚

**è¯¦ç»†çš„é—®é¢˜å‘ç°å’Œè§£å†³è¿‡ç¨‹è¯·å‚è€ƒï¼š**
- `docs/summaries/VPT_WEIGHT_LOADING_FINAL_SUMMARY.md` - å®Œæ•´çš„é—®é¢˜è¯Šæ–­å’Œä¿®å¤è¿‡ç¨‹
- `docs/summaries/VPT_WEIGHT_LOADING_CLARIFICATION.md` - é—®é¢˜æ ¹æºå’Œæ­£ç¡®å®ç°

---

## OpenAIå®˜æ–¹å®ç°

**å‚è€ƒï¼š** [`/tmp/Video-Pre-Training/agent.py`](https://github.com/openai/Video-Pre-Training/blob/main/agent.py#L132-L135)

```python
def load_weights(self, path):
    """Load model weights from a path, and reset hidden state"""
    self.policy.load_state_dict(th.load(path, map_location=self.device), strict=False)
    self.reset()
```

**å…³é”®ç‰¹ç‚¹ï¼š**
1. âœ… ç›´æ¥åŠ è½½æ•´ä¸ªstate_dict
2. âœ… ä¸åšä»»ä½•å‰ç¼€å¤„ç†æˆ–è¿‡æ»¤
3. âœ… ä½¿ç”¨`strict=False`

---

## æƒé‡æ–‡ä»¶å’Œæ¨¡å‹ç»“æ„

### æƒé‡æ–‡ä»¶åŒ…å«ï¼ˆ139ä¸ªkeysï¼‰ï¼š

```
net.* (125ä¸ª)          - è§†è§‰ç‰¹å¾æå–å™¨ (MinecraftPolicy)
pi_head.* (4ä¸ª)        - RLçš„action head
value_head.* (5ä¸ª)     - RLçš„value head
aux_value_head.* (5ä¸ª) - RLè®­ç»ƒæ—¶çš„è¾…åŠ©head
```

### MinecraftAgentPolicyæ¨¡å‹ç»“æ„ï¼š

```python
class MinecraftAgentPolicy(nn.Module):
    def __init__(self, action_space, policy_kwargs, pi_head_kwargs):
        super().__init__()
        self.net = MinecraftPolicy(**policy_kwargs)   # â† å¯¹åº” net.*
        self.pi_head = make_action_head(...)          # â† å¯¹åº” pi_head.*
        self.value_head = ScaledMSEHead(...)          # â† å¯¹åº” value_head.*
        # æ³¨æ„ï¼šæ²¡æœ‰ aux_value_headï¼ˆä»…åœ¨RLè®­ç»ƒæ—¶å­˜åœ¨ï¼‰
```

### å®˜æ–¹åŠ è½½ç»“æœï¼š

```
åŠ è½½ï¼š
  âœ… net.* â†’ self.net (125ä¸ªå‚æ•°)
  âœ… pi_head.* â†’ self.pi_head (4ä¸ªå‚æ•°)
  âœ… value_head.* â†’ self.value_head (5ä¸ªå‚æ•°)
  âš ï¸ aux_value_head.* â†’ Unexpected keys (5ä¸ª) - è¢«å¿½ç•¥

Missing keys: 0
Unexpected keys: 5 (aux_value_head.*)
```

---

## ä¸ºä»€ä¹ˆæœ‰Unexpected Keysï¼Ÿ

### aux_value_headçš„æ¥æº

**VPTè®­ç»ƒè¿‡ç¨‹ï¼š**
1. **RLé¢„è®­ç»ƒï¼ˆPPOï¼‰ï¼š** ä½¿ç”¨å¼ºåŒ–å­¦ä¹ åœ¨Minecraftä¸­é¢„è®­ç»ƒ
   - éœ€è¦value headä¼°è®¡çŠ¶æ€ä»·å€¼
   - ä½¿ç”¨aux_value_headä½œä¸ºè¾…åŠ©valueä¼°è®¡å™¨
   - æƒé‡æ–‡ä»¶åŒ…å«ï¼šnet.*, pi_head.*, value_head.*, aux_value_head.*

2. **BC fine-tuningï¼š** ä½¿ç”¨è¡Œä¸ºå…‹éš†åœ¨ç‰¹å®šä»»åŠ¡ä¸Šfine-tune
   - åªéœ€è¦policy (net + pi_head)æ¥é¢„æµ‹åŠ¨ä½œ
   - value_headä¿ç•™ï¼ˆç”¨äºæœªæ¥çš„RL fine-tuningï¼‰
   - **ä¸éœ€è¦aux_value_head**

### ç»“æœ

- æƒé‡æ–‡ä»¶æœ‰`aux_value_head.*`ï¼ˆRLè®­ç»ƒçš„äº§ç‰©ï¼‰
- BCæ¨¡å‹æ²¡æœ‰`aux_value_head`
- åŠ è½½æ—¶æˆä¸ºunexpected keys
- ä½¿ç”¨`strict=False`å¿½ç•¥è¿™äº›å¤šä½™çš„å‚æ•°

**è¿™æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼** âœ…

---

## æˆ‘ä»¬çš„å®ç°ï¼ˆå·²å¯¹é½å®˜æ–¹ï¼‰

```python
def _load_weights(self, path: str):
    """å®Œå…¨éµå¾ªOpenAIå®˜æ–¹å®ç°"""
    state_dict = th.load(path, map_location=self.device)
    
    # ç›´æ¥åŠ è½½å…¨éƒ¨æƒé‡ï¼Œä¸åšä»»ä½•å¤„ç†ï¼ˆä¸å®˜æ–¹å®Œå…¨ä¸€è‡´ï¼‰
    result = self.policy.load_state_dict(state_dict, strict=False)
    
    if self.verbose:
        print(f"  âœ“ æƒé‡åŠ è½½å®Œæˆ")
        
        if len(result.unexpected_keys) > 0:
            print(f"\n  â„¹ï¸  Unexpected keys: {len(result.unexpected_keys)}ä¸ª")
            print(f"      â†’ aux_value_head.* (RLè®­ç»ƒä¸“ç”¨ï¼ŒBCè®­ç»ƒæ—¶ä¸éœ€è¦)")
            print(f"      â†’ å·²è¢«å¿½ç•¥ (strict=False)")
    
    self.policy.eval()
```

**é¢„æœŸç»“æœï¼š**
- Missing keys: **0** âœ…
- Unexpected keys: **5** (aux_value_head.*) âœ…

---

## strict=Falseçš„ä½œç”¨

### PyTorchå®˜æ–¹æ–‡æ¡£

å‚è€ƒï¼š[torch.nn.Module.load_state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict)

```python
torch.nn.Module.load_state_dict(state_dict, strict=True)
```

**å‚æ•°è¯´æ˜ï¼š**
- `strict` (bool) â€“ æ˜¯å¦ä¸¥æ ¼å¼ºåˆ¶state_dictä¸­çš„é”®ä¸æ¨¡å‹çš„state_dict()è¿”å›çš„é”®åŒ¹é…

**å½“strict=Falseæ—¶ï¼š**
- å…è®¸åŠ è½½éƒ¨åˆ†æƒé‡
- å¿½ç•¥Missing keysï¼ˆæ¨¡å‹éœ€è¦ä½†æƒé‡ä¸­æ²¡æœ‰çš„å‚æ•°ä¼šä½¿ç”¨é»˜è®¤åˆå§‹åŒ–ï¼‰
- å¿½ç•¥Unexpected keysï¼ˆæƒé‡ä¸­æœ‰ä½†æ¨¡å‹ä¸éœ€è¦çš„å‚æ•°ä¼šè¢«ä¸¢å¼ƒï¼‰

### ä½¿ç”¨åœºæ™¯

`strict=False`å¸¸ç”¨äºï¼š
- è¿ç§»å­¦ä¹ ï¼ˆä¿®æ”¹äº†æ¨¡å‹çš„éƒ¨åˆ†ç»“æ„ï¼‰
- Fine-tuningï¼ˆæ›¿æ¢äº†åˆ†ç±»å¤´ç­‰ï¼‰
- åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆæƒé‡æ–‡ä»¶æ¯”æ¨¡å‹åŒ…å«æ›´å¤šå‚æ•°ï¼‰

åœ¨VPTçš„æƒ…å†µä¸‹ï¼Œ`strict=False`ç”¨äºå¿½ç•¥`aux_value_head.*`ã€‚

---

## éªŒè¯æƒé‡åŠ è½½

### æ–¹æ³•1ï¼šæ£€æŸ¥æ¨¡å‹å‚æ•°

```python
# æ‰“å°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°å
for name, param in agent.policy.named_parameters():
    print(name, param.shape)
```

### æ–¹æ³•2ï¼šéªŒè¯è¾“å‡º

```python
# åˆ›å»ºdummyè¾“å…¥æµ‹è¯•å‰å‘ä¼ æ’­
import torch as th
dummy_obs = th.randn(1, 128, 128, 3)
agent_input = {"img": dummy_obs}
dummy_first = th.from_numpy(np.array((False,)))

# æµ‹è¯•
with th.no_grad():
    output = agent.policy(agent_input, dummy_first, agent.hidden_state)
    print(f"è¾“å‡ºå½¢çŠ¶: {output}")
```

### æ–¹æ³•3ï¼šé›¶æ ·æœ¬è¯„ä¼°

```bash
bash scripts/evaluate_vpt_zero_shot.sh 1 auto 100
```

å¦‚æœagentèƒ½æ­£å¸¸è¿è¡Œå¹¶äº§ç”Ÿåˆç†çš„åŠ¨ä½œï¼Œè¯´æ˜æƒé‡åŠ è½½æ­£ç¡®ã€‚

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¹‹å‰æœ‰125ä¸ªMissing keyså’Œ130ä¸ªUnexpected keysï¼Ÿ

**A:** ä¹‹å‰çš„ä»£ç é”™è¯¯åœ°å»æ‰äº†'net.'å‰ç¼€ï¼š

```python
# âŒ é”™è¯¯ä»£ç 
if any(k.startswith('net.') for k in state_dict.keys()):
    state_dict = {k.replace('net.', ''): v for k, v in state_dict.items()}
```

è¿™å¯¼è‡´ï¼š
- `net.img_process.xxx` â†’ `img_process.xxx`
- æ¨¡å‹æœŸæœ›`net.*`ä½†æƒé‡å˜æˆäº†`img_process.*`
- å®Œå…¨ä¸åŒ¹é…ï¼

**ä¿®å¤ï¼š** ç§»é™¤è¿™æ®µé”™è¯¯çš„ä»£ç ï¼Œç›´æ¥åŠ è½½åŸå§‹æƒé‡ã€‚

### Q2: æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰pi_headå’Œvalue_headï¼Ÿ

**A:** ä¸åº”è¯¥ï¼å®˜æ–¹çš„åšæ³•æ˜¯åŠ è½½æ‰€æœ‰å¯ç”¨çš„æƒé‡ï¼š

```python
# âœ… æ­£ç¡®ï¼šåŠ è½½æ‰€æœ‰æƒé‡ï¼ˆåŒ…æ‹¬pi_headå’Œvalue_headï¼‰
result = self.policy.load_state_dict(state_dict, strict=False)
```

è¿™æ ·åœ¨BC fine-tuningæ—¶ï¼š
- å¦‚æœè¦fine-tune pi_headï¼Œä»é¢„è®­ç»ƒæƒé‡å¼€å§‹
- å¦‚æœè¦ä»å¤´è®­ç»ƒpi_headï¼Œå¯ä»¥freezeå…¶ä»–å±‚

ä¿ç•™é¢„è®­ç»ƒçš„pi_headæƒé‡ç»™æˆ‘ä»¬æ›´å¤šçµæ´»æ€§ã€‚

### Q3: 5ä¸ªUnexpected keysä¼šå½±å“æ€§èƒ½å—ï¼Ÿ

**A:** ä¸ä¼šï¼è¿™äº›æ˜¯`aux_value_head.*`ï¼Œè¢«`strict=False`å¿½ç•¥ï¼Œä¸ä¼šåŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚

æ ¸å¿ƒçš„`net.*`ã€`pi_head.*`ã€`value_head.*`éƒ½å·²æ­£ç¡®åŠ è½½ã€‚

---

## å‚è€ƒèµ„æ–™

1. **å®˜æ–¹VPTä»£ç **
   - GitHub: https://github.com/openai/Video-Pre-Training
   - å…³é”®æ–‡ä»¶ï¼š`agent.py`, `lib/policy.py`, `behavioural_cloning.py`

2. **PyTorchæ–‡æ¡£**
   - load_state_dict: https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict

3. **VPTè®ºæ–‡**
   - Paper: Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos
   - arXiv: https://arxiv.org/abs/2206.11795

4. **æˆ‘ä»¬çš„æ–‡æ¡£**
   - é—®é¢˜è¯Šæ–­ï¼š`docs/summaries/VPT_WEIGHT_LOADING_FINAL_SUMMARY.md`
   - é—®é¢˜æ¾„æ¸…ï¼š`docs/summaries/VPT_WEIGHT_LOADING_CLARIFICATION.md`

---

**æ€»ç»“ï¼š** Missing keyså’ŒUnexpected keysä¸ä¸€å®šæ˜¯é”™è¯¯ï¼Œå…³é”®æ˜¯è¦ç†è§£å…¶åŸå› å¹¶ç¡®è®¤æ ¸å¿ƒæƒé‡å·²æ­£ç¡®åŠ è½½ã€‚åœ¨VPTçš„æƒ…å†µä¸‹ï¼Œ5ä¸ªunexpected keys (aux_value_head.*) æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼âœ…
