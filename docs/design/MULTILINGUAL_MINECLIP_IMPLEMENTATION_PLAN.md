# æ–¹æ¡ˆBï¼šå¤šè¯­è¨€MineCLIPé€‚é…å®æ–½æ–¹æ¡ˆ

> **ç›®æ ‡**: è®­ç»ƒå¯¹é½å±‚ï¼Œè®©ä¸­æ–‡æŒ‡ä»¤ç›´æ¥æ˜ å°„åˆ°MineCLIPç©ºé—´  
> **å‰æ**: æ–¹æ¡ˆAï¼ˆç¿»è¯‘æ¡¥æ¥ï¼‰å·²å®ç°å¹¶éªŒè¯  
> **ä¼˜åŠ¿**: æ¶ˆé™¤ç¿»è¯‘ä¾èµ–ï¼Œæå‡ä¸­æ–‡ç†è§£è´¨é‡å’Œæ¨ç†é€Ÿåº¦  
>
> **è®¾è®¡æ—¥æœŸ**: 2025-11-10

---

## ğŸ“Š ç°çŠ¶åˆ†æ

### 1.1 å·²æœ‰åŸºç¡€è®¾æ–½ï¼ˆæ–¹æ¡ˆAï¼‰

```
âœ… è¯„ä¼°æ¡†æ¶å®Œæ•´
   â”œâ”€ EvaluationFramework (ä»»åŠ¡è°ƒåº¦)
   â”œâ”€ STEVE1Evaluator (æ‰§è¡Œå™¨)
   â”œâ”€ TaskLoader (ä»»åŠ¡åŠ è½½)
   â”œâ”€ ReportGenerator (æŠ¥å‘Šç”Ÿæˆ)
   â””â”€ Metrics (è¯„ä¼°æŒ‡æ ‡)

âœ… ä¸­æ–‡æ”¯æŒæ¨¡å—
   â”œâ”€ ChineseTranslator (ç¿»è¯‘å™¨)
   â”œâ”€ chinese_terms.json (100+æœ¯è¯­)
   â””â”€ è‡ªåŠ¨ä¸­è‹±æ–‡æ£€æµ‹

âœ… æ•°æ®èµ„æº
   â”œâ”€ eval_tasks.yaml (å¤šä»»åŠ¡é…ç½®)
   â”œâ”€ ä¸­è‹±æ–‡å¯¹ç…§æœ¯è¯­ (100å¯¹)
   â””â”€ è¯„ä¼°åŸºçº¿æ•°æ®

âœ… æ¨¡å‹å’Œç¯å¢ƒ
   â”œâ”€ MineCLIP (åŸç”Ÿè‹±æ–‡)
   â”œâ”€ STEVE-1 (VPT + æƒé‡)
   â”œâ”€ Prior (VAE)
   â””â”€ MineRLHarvestEnv (è‡ªå®šä¹‰ç¯å¢ƒ)
```

### 1.2 å½“å‰æ¶æ„æµç¨‹

```python
# æ–¹æ¡ˆA: ç¿»è¯‘æ¡¥æ¥
ä¸­æ–‡æŒ‡ä»¤ "ç æ ‘"
    â†“
ChineseTranslator (ç¿»è¯‘)
    â†“
è‹±æ–‡ "chop tree"
    â†“
MineCLIP.encode_text()
    â†“
512ç»´åµŒå…¥
    â†“
STEVE-1ç­–ç•¥ â†’ åŠ¨ä½œ
```

### 1.3 æ–¹æ¡ˆBç›®æ ‡æ¶æ„

```python
# æ–¹æ¡ˆB: å¯¹é½å±‚
ä¸­æ–‡æŒ‡ä»¤ "ç æ ‘"                      è‹±æ–‡æŒ‡ä»¤ "chop tree"
    â†“                                    â†“
Chinese-CLIP                          MineCLIP
    â†“                                    â†“
512ç»´ä¸­æ–‡åµŒå…¥                         512ç»´è‹±æ–‡åµŒå…¥
    â†“                                    â†“
å¯¹é½å±‚ (Alignment Layer) â”€â”€â”€â”€â”€â†’   MineCLIPç©ºé—´
    â†“
512ç»´å¯¹é½åµŒå…¥
    â†“
STEVE-1ç­–ç•¥ â†’ åŠ¨ä½œ

è®­ç»ƒç›®æ ‡:
  loss = ||å¯¹é½å±‚(Chinese-CLIP("ç æ ‘")) - MineCLIP("chop tree")||Â²
```

---

## ğŸ—ï¸ æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 2.1 MultilingualMineCLIP ç±»

**æ–‡ä»¶**: `src/models/multilingual_mineclip.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
å¤šè¯­è¨€MineCLIPé€‚é…å™¨
Multilingual MineCLIP Adapter for Chinese-English Support
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Literal, Optional
import logging

from transformers import ChineseCLIPModel, ChineseCLIPProcessor

logger = logging.getLogger(__name__)


class AlignmentLayer(nn.Module):
    """
    å¯¹é½å±‚: Chinese-CLIPåµŒå…¥ â†’ MineCLIPç©ºé—´
    
    æ¶æ„è®¾è®¡:
        - è¾“å…¥: 512ç»´ (Chinese-CLIP è¾“å‡º)
        - è¾“å‡º: 512ç»´ (MineCLIP ç©ºé—´)
        - ç»“æ„: MLP (2å±‚ + ReLU + Dropout)
    """
    
    def __init__(
        self,
        input_dim: int = 512,
        hidden_dim: int = 512,
        output_dim: int = 512,
        dropout: float = 0.1
    ):
        super().__init__()
        
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim)
        )
        
        # åˆå§‹åŒ–ä¸ºæ¥è¿‘æ’ç­‰æ˜ å°„ï¼ˆä¾¿äºè®­ç»ƒåˆæœŸï¼‰
        nn.init.xavier_uniform_(self.net[0].weight, gain=0.1)
        nn.init.zeros_(self.net[0].bias)
        nn.init.xavier_uniform_(self.net[3].weight, gain=0.1)
        nn.init.zeros_(self.net[3].bias)
    
    def forward(self, x):
        """
        Args:
            x: [batch_size, 512] Chinese-CLIPåµŒå…¥
        Returns:
            aligned: [batch_size, 512] å¯¹é½åçš„åµŒå…¥
        """
        return self.net(x)


class MultilingualMineCLIP:
    """
    å¤šè¯­è¨€MineCLIPé€‚é…å™¨
    
    èŒè´£:
    1. åŠ è½½å’Œç®¡ç† MineCLIP (è‹±æ–‡) å’Œ Chinese-CLIP (ä¸­æ–‡)
    2. æä¾›ç»Ÿä¸€çš„ encode_text() æ¥å£ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
    3. ä½¿ç”¨å¯¹é½å±‚æ˜ å°„ä¸­æ–‡åµŒå…¥åˆ°MineCLIPç©ºé—´
    
    ä½¿ç”¨ç¤ºä¾‹:
        model = MultilingualMineCLIP(
            mineclip_config="data/weights/mineclip/config.pth",
            alignment_path="data/weights/alignment_layer.pth"
        )
        
        # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
        embed_zh = model.encode_text("ç æ ‘")
        embed_en = model.encode_text("chop tree")
        
        # ä¸¤ä¸ªåµŒå…¥éƒ½åœ¨MineCLIPç©ºé—´ï¼Œå¯ä»¥ç›´æ¥ç”¨äºSTEVE-1
    """
    
    def __init__(
        self,
        mineclip_model=None,  # å¦‚æœå·²åŠ è½½åˆ™ä¼ å…¥
        mineclip_config: Optional[str] = None,
        chinese_clip_model: str = "OFA-Sys/chinese-clip-vit-base-patch16",
        alignment_path: Optional[str] = None,
        device: str = "cuda" if torch.cuda.is_available() else "cpu"
    ):
        """
        åˆå§‹åŒ–å¤šè¯­è¨€MineCLIP
        
        Args:
            mineclip_model: å·²åŠ è½½çš„MineCLIPæ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
            mineclip_config: MineCLIPé…ç½®è·¯å¾„ï¼ˆå¦‚æœmineclip_model=Noneï¼‰
            chinese_clip_model: Chinese-CLIPæ¨¡å‹åç§°æˆ–è·¯å¾„
            alignment_path: å¯¹é½å±‚æƒé‡è·¯å¾„ï¼ˆå¦‚æœå·²è®­ç»ƒï¼‰
            device: è®¾å¤‡
        """
        self.device = device
        
        # 1. åŠ è½½MineCLIPï¼ˆè‹±æ–‡ç¼–ç å™¨ï¼‰
        if mineclip_model is not None:
            logger.info("ä½¿ç”¨å·²åŠ è½½çš„MineCLIPæ¨¡å‹")
            self.mineclip = mineclip_model
        else:
            logger.info(f"ä»é…ç½®åŠ è½½MineCLIP: {mineclip_config}")
            from steve1.mineclip_code.load_mineclip import load
            self.mineclip = load(mineclip_config, device=device)
        
        # 2. åŠ è½½Chinese-CLIPï¼ˆä¸­æ–‡ç¼–ç å™¨ï¼‰
        logger.info(f"åŠ è½½Chinese-CLIP: {chinese_clip_model}")
        self.chinese_clip = ChineseCLIPModel.from_pretrained(
            chinese_clip_model,
            cache_dir="data/huggingface_cache"  # ç»Ÿä¸€ç¼“å­˜ç›®å½•
        ).to(device)
        self.chinese_clip.eval()  # å›ºå®šå‚æ•°
        
        self.chinese_processor = ChineseCLIPProcessor.from_pretrained(
            chinese_clip_model,
            cache_dir="data/huggingface_cache"
        )
        
        # 3. åˆ›å»ºå¯¹é½å±‚
        self.alignment_layer = AlignmentLayer().to(device)
        
        # 4. åŠ è½½å¯¹é½å±‚æƒé‡ï¼ˆå¦‚æœå·²è®­ç»ƒï¼‰
        if alignment_path:
            logger.info(f"åŠ è½½å¯¹é½å±‚æƒé‡: {alignment_path}")
            self.alignment_layer.load_state_dict(
                torch.load(alignment_path, map_location=device)
            )
            self.alignment_layer.eval()
        else:
            logger.warning("æœªåŠ è½½å¯¹é½å±‚æƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼ˆéœ€è¦è®­ç»ƒï¼‰")
    
    def encode_text(
        self,
        text: str,
        language: Literal['auto', 'zh', 'en'] = 'auto',
        return_numpy: bool = True
    ):
        """
        ç¼–ç æ–‡æœ¬ä¸ºMineCLIPåµŒå…¥
        
        Args:
            text: æ–‡æœ¬æŒ‡ä»¤ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
            language: è¯­è¨€
                - 'auto': è‡ªåŠ¨æ£€æµ‹
                - 'zh': å¼ºåˆ¶ä¸­æ–‡
                - 'en': å¼ºåˆ¶è‹±æ–‡
            return_numpy: æ˜¯å¦è¿”å›numpyæ•°ç»„ï¼ˆSTEVE-1éœ€è¦ï¼‰
        
        Returns:
            embed: [512] ç»´MineCLIPåµŒå…¥
        """
        # 1. è¯­è¨€æ£€æµ‹
        if language == 'auto':
            language = self._detect_language(text)
        
        # 2. ç¼–ç 
        with torch.no_grad():
            if language == 'en':
                # è‹±æ–‡: ç›´æ¥ç”¨MineCLIP
                embed = self._encode_english(text)
            else:  # language == 'zh'
                # ä¸­æ–‡: Chinese-CLIP + å¯¹é½å±‚
                embed = self._encode_chinese(text)
        
        # 3. è½¬æ¢æ ¼å¼
        if return_numpy:
            return embed.cpu().numpy()
        else:
            return embed
    
    def _encode_english(self, text: str) -> torch.Tensor:
        """ä½¿ç”¨MineCLIPç¼–ç è‹±æ–‡"""
        return self.mineclip.encode_text(text)
    
    def _encode_chinese(self, text: str) -> torch.Tensor:
        """ä½¿ç”¨Chinese-CLIP + å¯¹é½å±‚ç¼–ç ä¸­æ–‡"""
        # 1. Chinese-CLIPç¼–ç 
        inputs = self.chinese_processor(
            text=[text],
            return_tensors="pt",
            padding=True
        ).to(self.device)
        
        # è·å–æ–‡æœ¬åµŒå…¥
        outputs = self.chinese_clip.get_text_features(**inputs)
        zh_embed = outputs / outputs.norm(dim=-1, keepdim=True)  # å½’ä¸€åŒ–
        
        # 2. å¯¹é½å±‚æ˜ å°„åˆ°MineCLIPç©ºé—´
        aligned_embed = self.alignment_layer(zh_embed)
        
        # 3. å½’ä¸€åŒ–ï¼ˆä¿æŒå’ŒMineCLIPä¸€è‡´ï¼‰
        aligned_embed = aligned_embed / aligned_embed.norm(dim=-1, keepdim=True)
        
        return aligned_embed.squeeze(0)  # [512]
    
    def _detect_language(self, text: str) -> Literal['zh', 'en']:
        """
        è‡ªåŠ¨æ£€æµ‹è¯­è¨€
        
        è§„åˆ™:
            - åŒ…å«ä¸­æ–‡å­—ç¬¦ â†’ 'zh'
            - å¦åˆ™ â†’ 'en'
        """
        import re
        # æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if re.search(r'[\u4e00-\u9fff]', text):
            return 'zh'
        else:
            return 'en'
    
    def encode_image(self, image):
        """
        ç¼–ç å›¾åƒï¼ˆä½¿ç”¨MineCLIPè§†è§‰ç¼–ç å™¨ï¼‰
        
        æ³¨æ„: è§†è§‰ç¼–ç å™¨ä¿æŒä¸å˜ï¼Œåªæœ‰æ–‡æœ¬ç¼–ç å™¨éœ€è¦å¤šè¯­è¨€æ”¯æŒ
        """
        return self.mineclip.encode_image(image)
```

---

### 2.2 å¯¹é½å±‚è®­ç»ƒå™¨

**æ–‡ä»¶**: `src/training/alignment_trainer.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
å¯¹é½å±‚è®­ç»ƒå™¨
Alignment Layer Trainer for Multilingual MineCLIP
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from typing import List, Tuple, Dict, Optional
from pathlib import Path
import json
import logging
from tqdm import tqdm
import numpy as np

logger = logging.getLogger(__name__)


class ChineseEnglishPairDataset(Dataset):
    """
    ä¸­è‹±æ–‡å¯¹ç…§æ•°æ®é›†
    
    æ•°æ®æ ¼å¼:
        [
            {"zh": "ç æ ‘", "en": "chop tree"},
            {"zh": "æŒ–çŸ¿", "en": "mine"},
            ...
        ]
    """
    
    def __init__(self, data_path: str):
        """
        Args:
            data_path: JSONæ–‡ä»¶è·¯å¾„ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
        """
        with open(data_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        logger.info(f"åŠ è½½æ•°æ®é›†: {len(self.data)} å¯¹")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        return item['zh'], item['en']


class AlignmentTrainer:
    """
    å¯¹é½å±‚è®­ç»ƒå™¨
    
    è®­ç»ƒç›®æ ‡:
        è®© Align(Chinese-CLIP("ç æ ‘")) â‰ˆ MineCLIP("chop tree")
    
    æŸå¤±å‡½æ•°:
        L2è·ç¦»: ||aligned_embed - target_embed||Â²
        ä½™å¼¦ç›¸ä¼¼åº¦: 1 - cosine_similarity(aligned, target)
    """
    
    def __init__(
        self,
        model,  # MultilingualMineCLIPå®ä¾‹
        train_data_path: str,
        val_data_path: Optional[str] = None,
        batch_size: int = 32,
        learning_rate: float = 1e-4,
        device: str = "cuda" if torch.cuda.is_available() else "cpu"
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: MultilingualMineCLIPå®ä¾‹
            train_data_path: è®­ç»ƒæ•°æ®è·¯å¾„
            val_data_path: éªŒè¯æ•°æ®è·¯å¾„
            batch_size: æ‰¹å¤§å°
            learning_rate: å­¦ä¹ ç‡
            device: è®¾å¤‡
        """
        self.model = model
        self.device = device
        
        # æ•°æ®é›†
        self.train_dataset = ChineseEnglishPairDataset(train_data_path)
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=4
        )
        
        if val_data_path:
            self.val_dataset = ChineseEnglishPairDataset(val_data_path)
            self.val_loader = DataLoader(
                self.val_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=4
            )
        else:
            self.val_loader = None
        
        # ä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ–å¯¹é½å±‚ï¼‰
        self.optimizer = optim.AdamW(
            model.alignment_layer.parameters(),
            lr=learning_rate,
            weight_decay=0.01
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=100,  # epochs
            eta_min=1e-6
        )
        
        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.cos_sim = nn.CosineSimilarity(dim=1)
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.train_losses = []
        self.val_losses = []
    
    def train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.alignment_layer.train()
        
        epoch_loss = 0.0
        epoch_mse = 0.0
        epoch_cos = 0.0
        
        with tqdm(self.train_loader, desc=f"Epoch {self.current_epoch}") as pbar:
            for zh_texts, en_texts in pbar:
                # 1. ç¼–ç ä¸­æ–‡ï¼ˆChinese-CLIP + æœªè®­ç»ƒçš„å¯¹é½å±‚ï¼‰
                zh_embeds = []
                for zh_text in zh_texts:
                    # éœ€è¦æ¢¯åº¦ï¼Œç”¨äºåå‘ä¼ æ’­
                    inputs = self.model.chinese_processor(
                        text=[zh_text],
                        return_tensors="pt",
                        padding=True
                    ).to(self.device)
                    
                    with torch.no_grad():
                        outputs = self.model.chinese_clip.get_text_features(**inputs)
                        zh_embed = outputs / outputs.norm(dim=-1, keepdim=True)
                    
                    zh_embeds.append(zh_embed)
                
                zh_embeds = torch.cat(zh_embeds, dim=0)  # [batch, 512]
                
                # 2. å¯¹é½å±‚ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
                aligned_embeds = self.model.alignment_layer(zh_embeds)
                
                # å½’ä¸€åŒ–
                aligned_embeds = aligned_embeds / aligned_embeds.norm(dim=-1, keepdim=True)
                
                # 3. ç¼–ç è‹±æ–‡ï¼ˆMineCLIPï¼Œä½œä¸ºç›®æ ‡ï¼‰
                en_embeds = []
                with torch.no_grad():
                    for en_text in en_texts:
                        en_embed = self.model.mineclip.encode_text(en_text)
                        en_embeds.append(en_embed)
                
                en_embeds = torch.stack(en_embeds, dim=0)  # [batch, 512]
                
                # 4. è®¡ç®—æŸå¤±
                mse = self.mse_loss(aligned_embeds, en_embeds)
                cos = 1 - self.cos_sim(aligned_embeds, en_embeds).mean()
                
                # ç»„åˆæŸå¤±ï¼ˆMSEä¸»å¯¼ + ä½™å¼¦ç›¸ä¼¼åº¦è¾…åŠ©ï¼‰
                loss = mse + 0.1 * cos
                
                # 5. åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(
                    self.model.alignment_layer.parameters(),
                    max_norm=1.0
                )
                
                self.optimizer.step()
                
                # 6. è®°å½•
                epoch_loss += loss.item()
                epoch_mse += mse.item()
                epoch_cos += cos.item()
                
                pbar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'mse': f'{mse.item():.4f}',
                    'cos': f'{cos.item():.4f}'
                })
        
        # å¹³å‡æŸå¤±
        n_batches = len(self.train_loader)
        metrics = {
            'train_loss': epoch_loss / n_batches,
            'train_mse': epoch_mse / n_batches,
            'train_cos': epoch_cos / n_batches
        }
        
        return metrics
    
    def validate(self) -> Dict[str, float]:
        """éªŒè¯"""
        if self.val_loader is None:
            return {}
        
        self.model.alignment_layer.eval()
        
        val_loss = 0.0
        val_mse = 0.0
        val_cos = 0.0
        
        with torch.no_grad():
            for zh_texts, en_texts in tqdm(self.val_loader, desc="Validation"):
                # ç¼–ç ä¸­æ–‡
                zh_embeds = []
                for zh_text in zh_texts:
                    embed = self.model.encode_text(zh_text, language='zh', return_numpy=False)
                    zh_embeds.append(embed)
                zh_embeds = torch.stack(zh_embeds, dim=0)
                
                # ç¼–ç è‹±æ–‡
                en_embeds = []
                for en_text in en_texts:
                    embed = self.model.encode_text(en_text, language='en', return_numpy=False)
                    en_embeds.append(embed)
                en_embeds = torch.stack(en_embeds, dim=0)
                
                # æŸå¤±
                mse = self.mse_loss(zh_embeds, en_embeds)
                cos = 1 - self.cos_sim(zh_embeds, en_embeds).mean()
                loss = mse + 0.1 * cos
                
                val_loss += loss.item()
                val_mse += mse.item()
                val_cos += cos.item()
        
        n_batches = len(self.val_loader)
        metrics = {
            'val_loss': val_loss / n_batches,
            'val_mse': val_mse / n_batches,
            'val_cos': val_cos / n_batches
        }
        
        return metrics
    
    def train(
        self,
        epochs: int,
        save_dir: str = "data/weights/alignment",
        save_every: int = 10
    ):
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            save_dir: æƒé‡ä¿å­˜ç›®å½•
            save_every: æ¯Nä¸ªepochä¿å­˜ä¸€æ¬¡
        """
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"å¼€å§‹è®­ç»ƒå¯¹é½å±‚ï¼Œå…±{epochs}è½®")
        logger.info(f"è®­ç»ƒæ•°æ®: {len(self.train_dataset)} å¯¹")
        if self.val_loader:
            logger.info(f"éªŒè¯æ•°æ®: {len(self.val_dataset)} å¯¹")
        
        for epoch in range(epochs):
            self.current_epoch = epoch + 1
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch()
            self.train_losses.append(train_metrics['train_loss'])
            
            # éªŒè¯
            val_metrics = self.validate()
            if val_metrics:
                self.val_losses.append(val_metrics['val_loss'])
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # æ—¥å¿—
            logger.info(
                f"Epoch {self.current_epoch}/{epochs} - "
                f"train_loss: {train_metrics['train_loss']:.4f}, "
                f"train_mse: {train_metrics['train_mse']:.4f}, "
                f"train_cos: {train_metrics['train_cos']:.4f}"
            )
            
            if val_metrics:
                logger.info(
                    f"  val_loss: {val_metrics['val_loss']:.4f}, "
                    f"val_mse: {val_metrics['val_mse']:.4f}, "
                    f"val_cos: {val_metrics['val_cos']:.4f}"
                )
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_metrics['val_loss'] < self.best_val_loss:
                    self.best_val_loss = val_metrics['val_loss']
                    best_path = save_dir / "alignment_best.pth"
                    torch.save(
                        self.model.alignment_layer.state_dict(),
                        best_path
                    )
                    logger.info(f"  ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
            
            # å®šæœŸä¿å­˜
            if (epoch + 1) % save_every == 0:
                checkpoint_path = save_dir / f"alignment_epoch_{epoch+1}.pth"
                torch.save(
                    self.model.alignment_layer.state_dict(),
                    checkpoint_path
                )
                logger.info(f"  ä¿å­˜checkpoint: {checkpoint_path}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = save_dir / "alignment_final.pth"
        torch.save(
            self.model.alignment_layer.state_dict(),
            final_path
        )
        logger.info(f"è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹: {final_path}")
        
        # ä¿å­˜è®­ç»ƒæ›²çº¿
        self._save_training_curves(save_dir)
    
    def _save_training_curves(self, save_dir: Path):
        """ä¿å­˜è®­ç»ƒæ›²çº¿"""
        import matplotlib.pyplot as plt
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(self.train_losses, label='Train Loss')
        if self.val_losses:
            ax.plot(self.val_losses, label='Val Loss')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.set_title('Alignment Layer Training Curves')
        ax.legend()
        ax.grid(True)
        
        curve_path = save_dir / "training_curves.png"
        plt.savefig(curve_path)
        plt.close()
        
        logger.info(f"ä¿å­˜è®­ç»ƒæ›²çº¿: {curve_path}")
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„ä¸ä»£ç é€‚é…

### 3.1 æ–°å¢æ–‡ä»¶

```
src/
â”œâ”€â”€ models/                          # æ–°å¢ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ multilingual_mineclip.py     # æ ¸å¿ƒ: MultilingualMineCLIP
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ alignment_trainer.py         # æ–°å¢: å¯¹é½å±‚è®­ç»ƒå™¨
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train_alignment.py           # æ–°å¢: è®­ç»ƒè„šæœ¬
    â””â”€â”€ evaluate_alignment.py        # æ–°å¢: è¯„ä¼°è„šæœ¬

data/
â”œâ”€â”€ alignment_pairs/                 # æ–°å¢ç›®å½•
â”‚   â”œâ”€â”€ train.json                   # è®­ç»ƒæ•°æ®ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
â”‚   â”œâ”€â”€ val.json                     # éªŒè¯æ•°æ®
â”‚   â””â”€â”€ README.md                    # æ•°æ®æ ¼å¼è¯´æ˜
â”‚
â””â”€â”€ weights/
    â””â”€â”€ alignment/                   # æ–°å¢ç›®å½•
        â”œâ”€â”€ alignment_best.pth       # æœ€ä½³æƒé‡
        â”œâ”€â”€ alignment_final.pth      # æœ€ç»ˆæƒé‡
        â””â”€â”€ training_curves.png      # è®­ç»ƒæ›²çº¿
```

### 3.2 éœ€è¦ä¿®æ”¹çš„ç°æœ‰æ–‡ä»¶

#### 3.2.1 `src/evaluation/steve1_evaluator.py`

**ä¿®æ”¹ç‚¹**: æ”¯æŒä½¿ç”¨MultilingualMineCLIPæ›¿ä»£ç¿»è¯‘

```python
# åŸæœ‰ä»£ç 
from ..translation.translator import ChineseTranslator

# æ–°å¢å¯¼å…¥
from ..models.multilingual_mineclip import MultilingualMineCLIP

class STEVE1Evaluator:
    def __init__(
        self,
        # ... å…¶ä»–å‚æ•°
        use_multilingual: bool = False,  # æ–°å¢å‚æ•°
        alignment_path: Optional[str] = None  # æ–°å¢å‚æ•°
    ):
        # ... åŸæœ‰ä»£ç 
        
        # ä¿®æ”¹: æ ¹æ®é…ç½®é€‰æ‹©ç¿»è¯‘å™¨æˆ–å¤šè¯­è¨€æ¨¡å‹
        if use_multilingual:
            logger.info("ä½¿ç”¨å¤šè¯­è¨€MineCLIPï¼ˆå¯¹é½å±‚æ–¹æ¡ˆï¼‰")
            # æ³¨æ„: MineCLIPå·²åœ¨_lazy_load_modelsä¸­åŠ è½½
            # åˆ›å»ºå¤šè¯­è¨€é€‚é…å™¨æ—¶å¤ç”¨å·²åŠ è½½çš„MineCLIP
            self._multilingual_mineclip = None  # å»¶è¿ŸåŠ è½½
            self.alignment_path = alignment_path
            self.translator = None  # ä¸ä½¿ç”¨ç¿»è¯‘å™¨
        else:
            logger.info("ä½¿ç”¨ç¿»è¯‘æ¡¥æ¥æ–¹æ¡ˆ")
            self.translator = ChineseTranslator(
                term_dict_path="data/chinese_terms.json",
                method="term_dict"
            )
            self._multilingual_mineclip = None
    
    def _lazy_load_models(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        if self._agent is None or self._mineclip is None:
            logger.info("å»¶è¿ŸåŠ è½½ STEVE-1 Agent å’Œ MineCLIP...")
            self._agent, self._mineclip, _ = load_mineclip_agent_env(
                # ... å‚æ•°
            )
        
        # å¦‚æœä½¿ç”¨å¤šè¯­è¨€æ¨¡å¼ï¼ŒåŠ è½½MultilingualMineCLIP
        if self._multilingual_mineclip is None and self.translator is None:
            logger.info("åŠ è½½ MultilingualMineCLIP...")
            from ..models.multilingual_mineclip import MultilingualMineCLIP
            self._multilingual_mineclip = MultilingualMineCLIP(
                mineclip_model=self._mineclip,  # å¤ç”¨å·²åŠ è½½çš„MineCLIP
                alignment_path=self.alignment_path
            )
    
    def _run_single_trial(
        self,
        task_id: str,
        instruction: str,
        max_steps: int,
        trial_idx: int,
        n_trials: int
    ) -> TrialResult:
        """è¿è¡Œå•æ¬¡è¯•éªŒ"""
        # ... å‰é¢ä»£ç ä¸å˜
        
        # ä¿®æ”¹: æ ¹æ®æ¨¡å¼é€‰æ‹©ç¼–ç æ–¹å¼
        if self._multilingual_mineclip:
            # æ–¹æ¡ˆB: å¤šè¯­è¨€MineCLIPï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
            logger.debug(f"  ä½¿ç”¨å¤šè¯­è¨€MineCLIPç¼–ç : '{instruction}'")
            with th.no_grad():
                prompt_embed = self._multilingual_mineclip.encode_text(
                    instruction,
                    language='auto',
                    return_numpy=False  # è¿”å›Tensor
                )
                # ä½¿ç”¨Prior
                prompt_embed = get_prior_embed(
                    instruction,
                    self._multilingual_mineclip,  # ä¼ å…¥å¤šè¯­è¨€æ¨¡å‹
                    self._prior,
                    DEVICE
                )
                prompt_embed_np = prompt_embed.cpu().numpy()
        else:
            # æ–¹æ¡ˆA: ç¿»è¯‘æ¡¥æ¥
            if self._is_chinese(instruction):
                translated_instruction = self.translator.translate(instruction)
                logger.debug(f"  ç¿»è¯‘: {instruction} â†’ {translated_instruction}")
                instruction_to_encode = translated_instruction
            else:
                instruction_to_encode = instruction
            
            logger.debug(f"  ä½¿ç”¨ MineCLIP ç¼–ç : '{instruction_to_encode}'")
            with th.no_grad():
                prompt_embed = get_prior_embed(
                    instruction_to_encode,
                    self._mineclip,
                    self._prior,
                    DEVICE
                )
                prompt_embed_np = prompt_embed.cpu().numpy()
        
        # ... åç»­ä»£ç ä¸å˜
```

#### 3.2.2 `src/evaluation/eval_framework.py`

**ä¿®æ”¹ç‚¹**: æ·»åŠ é…ç½®å‚æ•°ä¼ é€’

```python
@dataclass
class EvaluationConfig:
    # ... åŸæœ‰å‚æ•°
    
    # æ–°å¢: å¤šè¯­è¨€æ”¯æŒé…ç½®
    use_multilingual: bool = False
    alignment_path: Optional[str] = None

class EvaluationFramework:
    def __init__(self, config: Optional[EvaluationConfig] = None, ...):
        # ...
        
        if evaluator is None:
            self.evaluator = STEVE1Evaluator(
                # ... åŸæœ‰å‚æ•°
                use_multilingual=self.config.use_multilingual,  # æ–°å¢
                alignment_path=self.config.alignment_path  # æ–°å¢
            )
```

#### 3.2.3 `src/utils/steve1_mineclip_agent_env_utils.py`

**ä¿®æ”¹ç‚¹**: å¯é€‰æ”¯æŒMultilingualMineCLIPï¼ˆå¦‚æœéœ€è¦åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰

```python
def load_multilingual_mineclip(
    mineclip_config,
    alignment_path: Optional[str] = None,
    device=DEVICE
):
    """
    åŠ è½½å¤šè¯­è¨€MineCLIP
    
    Args:
        mineclip_config: MineCLIPé…ç½®è·¯å¾„
        alignment_path: å¯¹é½å±‚æƒé‡è·¯å¾„
        device: è®¾å¤‡
    
    Returns:
        MultilingualMineCLIPå®ä¾‹
    """
    from ..models.multilingual_mineclip import MultilingualMineCLIP
    
    return MultilingualMineCLIP(
        mineclip_config=mineclip_config,
        alignment_path=alignment_path,
        device=device
    )
```

---

## ğŸ¯ æ•°æ®å‡†å¤‡æ–¹æ¡ˆ

### 4.1 æ•°æ®æ¥æº

```python
# 1. ä»ç°æœ‰æœ¯è¯­è¯å…¸æ‰©å±•
from data/chinese_terms.json â†’ data/alignment_pairs/

ç­–ç•¥:
  - å±•å¼€åµŒå¥—ç»“æ„: {"åŸºç¡€åŠ¨ä½œ": {"ç æ ‘": "chop tree"}} â†’ {"zh": "ç æ ‘", "en": "chop tree"}
  - æ·»åŠ åŒä¹‰è¯å˜ä½“: "ä¼æœ¨" â†’ "chop tree", "è·å–æœ¨å¤´" â†’ "chop tree"
  - å½“å‰å¯ç”Ÿæˆ: ~200å¯¹

# 2. MineDojoä»»åŠ¡é›†
from config/eval_tasks.yaml â†’ æå–ä¸­è‹±æ–‡æŒ‡ä»¤å¯¹

ç­–ç•¥:
  - æ¯ä¸ªä»»åŠ¡çš„ zh å’Œ en æŒ‡ä»¤é…å¯¹
  - ä¸åŒä»»åŠ¡å˜ä½“
  - å¯ç”Ÿæˆ: ~50-100å¯¹

# 3. ç»„åˆæŒ‡ä»¤ç”Ÿæˆ
æ¨¡æ¿æ–¹æ³•:
  - "ç  + æ ‘" â†’ "chop tree"
  - "åˆ¶ä½œ + æœ¨é•" â†’ "craft wooden pickaxe"
  - "æ‰¾åˆ° + æ´ç©´" â†’ "find cave"
  - å¯ç”Ÿæˆ: ~500-1000å¯¹

# 4. äººå·¥æ‰©å……ï¼ˆå¯é€‰ï¼‰
  - Minecraftè®ºå›/ç¤¾åŒºå¸¸ç”¨è¡¨è¿°
  - Bç«™/æŠ–éŸ³è§†é¢‘æ ‡é¢˜/è¯„è®º
  - ç›®æ ‡: 1000-2000å¯¹

æ€»è®¡: 2000-3000å¯¹ï¼ˆè¶³å¤Ÿè®­ç»ƒï¼‰
è®­ç»ƒé›†:éªŒè¯é›† = 8:2
```

### 4.2 æ•°æ®æ ¼å¼

```json
// data/alignment_pairs/train.json
[
  {
    "zh": "ç æ ‘",
    "en": "chop tree",
    "category": "basic_action",
    "source": "term_dict"
  },
  {
    "zh": "ä¼æœ¨",
    "en": "chop tree",
    "category": "basic_action",
    "source": "synonym"
  },
  {
    "zh": "åˆ¶ä½œæœ¨é•",
    "en": "craft wooden pickaxe",
    "category": "composite_task",
    "source": "generated"
  },
  {
    "zh": "æ‰¾åˆ°æ´ç©´å¹¶è¿›å…¥",
    "en": "find cave and enter",
    "category": "complex_task",
    "source": "eval_tasks"
  }
]
```

### 4.3 æ•°æ®ç”Ÿæˆè„šæœ¬

**æ–‡ä»¶**: `scripts/generate_alignment_data.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
ç”Ÿæˆå¯¹é½å±‚è®­ç»ƒæ•°æ®
ä»ç°æœ‰èµ„æºç”Ÿæˆä¸­è‹±æ–‡å¯¹ç…§æ•°æ®é›†
"""

import json
from pathlib import Path
from typing import List, Dict
import yaml
import random


def load_term_dict(path: str = "data/chinese_terms.json") -> List[Dict]:
    """ä»æœ¯è¯­è¯å…¸ç”Ÿæˆpairs"""
    with open(path, 'r', encoding='utf-8') as f:
        terms = json.load(f)
    
    pairs = []
    for category, items in terms.items():
        if isinstance(items, dict):
            for zh, en in items.items():
                pairs.append({
                    "zh": zh,
                    "en": en,
                    "category": category,
                    "source": "term_dict"
                })
    
    return pairs


def load_eval_tasks(path: str = "config/eval_tasks.yaml") -> List[Dict]:
    """ä»è¯„ä¼°ä»»åŠ¡ç”Ÿæˆpairs"""
    with open(path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    pairs = []
    for task in config.get('tasks', []):
        en = task.get('instructions', {}).get('en')
        zh_list = task.get('instructions', {}).get('zh', [])
        
        if en and zh_list:
            for zh in zh_list:
                pairs.append({
                    "zh": zh,
                    "en": en,
                    "category": task.get('category', 'task'),
                    "source": "eval_tasks",
                    "task_id": task.get('task_id')
                })
    
    return pairs


def generate_composite_pairs() -> List[Dict]:
    """ç”Ÿæˆç»„åˆæŒ‡ä»¤pairs"""
    actions = [
        ("ç ", "chop"),
        ("æŒ–", "mine"),
        ("åˆ¶ä½œ", "craft"),
        ("å»ºé€ ", "build"),
        ("æ‰¾åˆ°", "find"),
        ("æ”»å‡»", "attack")
    ]
    
    objects = [
        ("æ ‘", "tree"),
        ("æœ¨å¤´", "wood"),
        ("çŸ³å¤´", "stone"),
        ("çŸ¿çŸ³", "ore"),
        ("æˆ¿å­", "house"),
        ("å·¥ä½œå°", "crafting table")
    ]
    
    pairs = []
    for zh_action, en_action in actions:
        for zh_obj, en_obj in objects:
            pairs.append({
                "zh": f"{zh_action}{zh_obj}",
                "en": f"{en_action} {en_obj}",
                "category": "composite",
                "source": "generated"
            })
    
    return pairs


def main():
    """ç”Ÿæˆå¹¶ä¿å­˜æ•°æ®é›†"""
    # æ”¶é›†æ‰€æœ‰pairs
    all_pairs = []
    
    print("åŠ è½½æœ¯è¯­è¯å…¸...")
    all_pairs.extend(load_term_dict())
    
    print("åŠ è½½è¯„ä¼°ä»»åŠ¡...")
    all_pairs.extend(load_eval_tasks())
    
    print("ç”Ÿæˆç»„åˆæŒ‡ä»¤...")
    all_pairs.extend(generate_composite_pairs())
    
    print(f"æ€»è®¡: {len(all_pairs)} å¯¹")
    
    # å»é‡ï¼ˆåŸºäºzh-enå¯¹ï¼‰
    unique_pairs = []
    seen = set()
    for pair in all_pairs:
        key = (pair['zh'], pair['en'])
        if key not in seen:
            seen.add(key)
            unique_pairs.append(pair)
    
    print(f"å»é‡å: {len(unique_pairs)} å¯¹")
    
    # æ‰“ä¹±é¡ºåº
    random.shuffle(unique_pairs)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›† (8:2)
    split_idx = int(len(unique_pairs) * 0.8)
    train_pairs = unique_pairs[:split_idx]
    val_pairs = unique_pairs[split_idx:]
    
    # ä¿å­˜
    output_dir = Path("data/alignment_pairs")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    with open(output_dir / "train.json", 'w', encoding='utf-8') as f:
        json.dump(train_pairs, f, ensure_ascii=False, indent=2)
    
    with open(output_dir / "val.json", 'w', encoding='utf-8') as f:
        json.dump(val_pairs, f, ensure_ascii=False, indent=2)
    
    print(f"è®­ç»ƒé›†: {len(train_pairs)} å¯¹ â†’ {output_dir / 'train.json'}")
    print(f"éªŒè¯é›†: {len(val_pairs)} å¯¹ â†’ {output_dir / 'val.json'}")


if __name__ == "__main__":
    main()
```

---

## ğŸš€ è®­ç»ƒæµç¨‹

### 5.1 è®­ç»ƒè„šæœ¬

**æ–‡ä»¶**: `scripts/train_alignment.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
è®­ç»ƒå¯¹é½å±‚
Train Alignment Layer for Multilingual MineCLIP
"""

import argparse
import logging
from pathlib import Path

import torch

from src.models.multilingual_mineclip import MultilingualMineCLIP
from src.training.alignment_trainer import AlignmentTrainer
from steve1.config import MINECLIP_CONFIG

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒå¯¹é½å±‚")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--train_data", type=str, 
                        default="data/alignment_pairs/train.json",
                        help="è®­ç»ƒæ•°æ®è·¯å¾„")
    parser.add_argument("--val_data", type=str,
                        default="data/alignment_pairs/val.json",
                        help="éªŒè¯æ•°æ®è·¯å¾„")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=100,
                        help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32,
                        help="æ‰¹å¤§å°")
    parser.add_argument("--lr", type=float, default=1e-4,
                        help="å­¦ä¹ ç‡")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--chinese_clip_model", type=str,
                        default="OFA-Sys/chinese-clip-vit-base-patch16",
                        help="Chinese-CLIPæ¨¡å‹")
    
    # ä¿å­˜å‚æ•°
    parser.add_argument("--save_dir", type=str,
                        default="data/weights/alignment",
                        help="æƒé‡ä¿å­˜ç›®å½•")
    parser.add_argument("--save_every", type=int, default=10,
                        help="æ¯Nä¸ªepochä¿å­˜ä¸€æ¬¡")
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument("--device", type=str,
                        default="cuda" if torch.cuda.is_available() else "cpu",
                        help="è®­ç»ƒè®¾å¤‡")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not Path(args.train_data).exists():
        logger.error(f"è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {args.train_data}")
        logger.info("è¯·å…ˆè¿è¡Œ: python scripts/generate_alignment_data.py")
        return
    
    # åˆ›å»ºå¤šè¯­è¨€MineCLIP
    logger.info("åˆå§‹åŒ–MultilingualMineCLIP...")
    model = MultilingualMineCLIP(
        mineclip_config=MINECLIP_CONFIG,
        chinese_clip_model=args.chinese_clip_model,
        alignment_path=None,  # ä»å¤´è®­ç»ƒ
        device=args.device
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    logger.info("åˆ›å»ºè®­ç»ƒå™¨...")
    trainer = AlignmentTrainer(
        model=model,
        train_data_path=args.train_data,
        val_data_path=args.val_data if Path(args.val_data).exists() else None,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        device=args.device
    )
    
    # å¼€å§‹è®­ç»ƒ
    logger.info("å¼€å§‹è®­ç»ƒ...")
    trainer.train(
        epochs=args.epochs,
        save_dir=args.save_dir,
        save_every=args.save_every
    )
    
    logger.info("è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
```

### 5.2 ä½¿ç”¨æ–¹æ³•

```bash
# 1. ç”Ÿæˆè®­ç»ƒæ•°æ®
python scripts/generate_alignment_data.py

# 2. è®­ç»ƒå¯¹é½å±‚
python scripts/train_alignment.py \
    --train_data data/alignment_pairs/train.json \
    --val_data data/alignment_pairs/val.json \
    --epochs 100 \
    --batch_size 32 \
    --lr 1e-4 \
    --save_dir data/weights/alignment

# 3. ç›‘æ§è®­ç»ƒï¼ˆå¯é€‰ï¼‰
# æŸ¥çœ‹è®­ç»ƒæ›²çº¿
ls data/weights/alignment/training_curves.png
```

---

## ğŸ“Š è¯„ä¼°å¯¹æ¯”æ–¹æ¡ˆ

### 6.1 å¯¹æ¯”è¯„ä¼°è„šæœ¬

**æ–‡ä»¶**: `scripts/evaluate_alignment.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
è¯„ä¼°å¯¹é½å±‚æ€§èƒ½
Compare Alignment Layer vs Translation Bridge
"""

import argparse
import logging
from pathlib import Path

from src.evaluation.eval_framework import EvaluationFramework, EvaluationConfig

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description="å¯¹æ¯”è¯„ä¼°ï¼šå¯¹é½å±‚ vs ç¿»è¯‘æ¡¥æ¥")
    
    parser.add_argument("--alignment_path", type=str,
                        default="data/weights/alignment/alignment_best.pth",
                        help="å¯¹é½å±‚æƒé‡è·¯å¾„")
    parser.add_argument("--task_config", type=str,
                        default="config/eval_tasks.yaml",
                        help="ä»»åŠ¡é…ç½®æ–‡ä»¶")
    parser.add_argument("--n_trials", type=int, default=10,
                        help="æ¯ä¸ªä»»åŠ¡çš„è¯•éªŒæ¬¡æ•°")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    if not Path(args.alignment_path).exists():
        logger.error(f"å¯¹é½å±‚æƒé‡ä¸å­˜åœ¨: {args.alignment_path}")
        logger.info("è¯·å…ˆè¿è¡Œè®­ç»ƒ: python scripts/train_alignment.py")
        return
    
    # ===== æ–¹æ¡ˆA: ç¿»è¯‘æ¡¥æ¥ =====
    logger.info("="*80)
    logger.info("è¯„ä¼°æ–¹æ¡ˆA: ç¿»è¯‘æ¡¥æ¥")
    logger.info("="*80)
    
    config_translation = EvaluationConfig(
        task_config_path=args.task_config,
        n_trials=args.n_trials,
        use_multilingual=False,  # ä½¿ç”¨ç¿»è¯‘
        results_dir="results/evaluation/translation"
    )
    
    framework_translation = EvaluationFramework(config=config_translation)
    results_translation = framework_translation.evaluate_all_tasks()
    
    # ===== æ–¹æ¡ˆB: å¯¹é½å±‚ =====
    logger.info("="*80)
    logger.info("è¯„ä¼°æ–¹æ¡ˆB: å¯¹é½å±‚")
    logger.info("="*80)
    
    config_alignment = EvaluationConfig(
        task_config_path=args.task_config,
        n_trials=args.n_trials,
        use_multilingual=True,  # ä½¿ç”¨å¯¹é½å±‚
        alignment_path=args.alignment_path,
        results_dir="results/evaluation/alignment"
    )
    
    framework_alignment = EvaluationFramework(config=config_alignment)
    results_alignment = framework_alignment.evaluate_all_tasks()
    
    # ===== å¯¹æ¯”åˆ†æ =====
    logger.info("="*80)
    logger.info("å¯¹æ¯”ç»“æœ")
    logger.info("="*80)
    
    # è®¡ç®—å¹³å‡æˆåŠŸç‡
    def calc_avg_success(results):
        en_rates = [r.success_rate for r in results if r.language == 'en']
        zh_rates = [r.success_rate for r in results if r.language == 'zh']
        return {
            'en_avg': sum(en_rates) / len(en_rates) if en_rates else 0,
            'zh_avg': sum(zh_rates) / len(zh_rates) if zh_rates else 0
        }
    
    stats_translation = calc_avg_success(results_translation)
    stats_alignment = calc_avg_success(results_alignment)
    
    logger.info(f"ç¿»è¯‘æ¡¥æ¥: EN={stats_translation['en_avg']:.1%}, ZH={stats_translation['zh_avg']:.1%}, Gap={(stats_translation['en_avg']-stats_translation['zh_avg']):.1%}")
    logger.info(f"å¯¹é½å±‚:   EN={stats_alignment['en_avg']:.1%}, ZH={stats_alignment['zh_avg']:.1%}, Gap={(stats_alignment['en_avg']-stats_alignment['zh_avg']):.1%}")
    
    # æ”¹è¿›åˆ†æ
    zh_improvement = stats_alignment['zh_avg'] - stats_translation['zh_avg']
    gap_improvement = (stats_translation['en_avg'] - stats_translation['zh_avg']) - (stats_alignment['en_avg'] - stats_alignment['zh_avg'])
    
    logger.info(f"ä¸­æ–‡æˆåŠŸç‡æå‡: {zh_improvement:+.1%}")
    logger.info(f"ä¸­è‹±æ–‡Gapç¼©å°: {gap_improvement:+.1%}")
    
    if zh_improvement > 0:
        logger.info("âœ… å¯¹é½å±‚æ–¹æ¡ˆä¼˜äºç¿»è¯‘æ¡¥æ¥")
    else:
        logger.info("âš ï¸  å¯¹é½å±‚æ–¹æ¡ˆæœªè¾¾é¢„æœŸï¼Œå»ºè®®æ£€æŸ¥è®­ç»ƒ")


if __name__ == "__main__":
    main()
```

---

## ğŸ“… å®æ–½æ—¶é—´è¡¨

### ç¬¬1å‘¨ï¼šç¯å¢ƒå‡†å¤‡å’Œæ•°æ®ç”Ÿæˆ

```
Day 1-2: ä»£ç æ¡†æ¶æ­å»º
  âœ“ åˆ›å»º src/models/ ç›®å½•
  âœ“ å®ç° MultilingualMineCLIP ç±»
  âœ“ å®ç° AlignmentLayer ç±»
  âœ“ æµ‹è¯•Chinese-CLIPåŠ è½½

Day 3-4: è®­ç»ƒå™¨å®ç°
  âœ“ å®ç° AlignmentTrainer ç±»
  âœ“ å®ç°æ•°æ®åŠ è½½
  âœ“ æµ‹è¯•è®­ç»ƒå¾ªç¯

Day 5-7: æ•°æ®å‡†å¤‡
  âœ“ å®ç°æ•°æ®ç”Ÿæˆè„šæœ¬
  âœ“ ä»æœ¯è¯­è¯å…¸æå–pairs
  âœ“ ä»è¯„ä¼°ä»»åŠ¡æå–pairs
  âœ“ ç”Ÿæˆç»„åˆæŒ‡ä»¤
  âœ“ æ•°æ®éªŒè¯å’Œæ¸…æ´—
```

### ç¬¬2å‘¨ï¼šè®­ç»ƒå’Œè°ƒä¼˜

```
Day 8-10: æ¨¡å‹è®­ç»ƒ
  âœ“ è¿è¡Œå®Œæ•´è®­ç»ƒï¼ˆ100 epochsï¼‰
  âœ“ ç›‘æ§è®­ç»ƒæ›²çº¿
  âœ“ è°ƒæ•´è¶…å‚æ•°

Day 11-12: è¯„ä¼°éªŒè¯
  âœ“ å®ç°å¯¹æ¯”è¯„ä¼°è„šæœ¬
  âœ“ è¿è¡Œæ–¹æ¡ˆA vs æ–¹æ¡ˆBå¯¹æ¯”
  âœ“ åˆ†ææ€§èƒ½å·®å¼‚

Day 13-14: ä¼˜åŒ–è¿­ä»£
  âœ“ æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´
  âœ“ è¡¥å……æ•°æ®ï¼ˆå¦‚æœ‰å¿…è¦ï¼‰
  âœ“ é‡æ–°è®­ç»ƒ
```

### ç¬¬3-4å‘¨ï¼šé›†æˆå’Œéƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

```
Day 15-18: ç³»ç»Ÿé›†æˆ
  âœ“ ä¿®æ”¹è¯„ä¼°æ¡†æ¶
  âœ“ æ›´æ–°é…ç½®ç®¡ç†
  âœ“ å®Œæ•´æµ‹è¯•

Day 19-21: æ–‡æ¡£å’Œæ€»ç»“
  âœ“ ç¼–å†™ä½¿ç”¨æ–‡æ¡£
  âœ“ æ›´æ–°é¡¹ç›®README
  âœ“ æ€§èƒ½æŠ¥å‘Š

Day 22-28: æŒç»­ä¼˜åŒ–
  âœ“ æ”¶é›†å¤±è´¥case
  âœ“ è¡¥å……è®­ç»ƒæ•°æ®
  âœ“ å¾®è°ƒæ¨¡å‹
```

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### è®­ç»ƒé˜¶æ®µç›®æ ‡

```
å¿…è¾¾æŒ‡æ ‡:
  âœ… è®­ç»ƒæŸå¤±æ”¶æ•›ï¼ˆ<0.05ï¼‰
  âœ… éªŒè¯æŸå¤±ç¨³å®š
  âœ… ä½™å¼¦ç›¸ä¼¼åº¦ > 0.90

æœŸæœ›æŒ‡æ ‡:
  â­ è®­ç»ƒæŸå¤± < 0.01
  â­ ä½™å¼¦ç›¸ä¼¼åº¦ > 0.95
  â­ ä¸­è‹±æ–‡åµŒå…¥L2è·ç¦» < 0.1
```

### è¯„ä¼°é˜¶æ®µç›®æ ‡

```
å¿…è¾¾æŒ‡æ ‡ï¼ˆvs ç¿»è¯‘æ–¹æ¡ˆï¼‰:
  âœ… ä¸­æ–‡æˆåŠŸç‡æå‡ > 0%
  âœ… ä¸­è‹±æ–‡gapç¼©å° > 0%
  âœ… æ¨ç†é€Ÿåº¦æå‡ > 20%ï¼ˆæ¶ˆé™¤ç¿»è¯‘å»¶è¿Ÿï¼‰

æœŸæœ›æŒ‡æ ‡:
  â­ ä¸­æ–‡æˆåŠŸç‡æå‡ > 5%
  â­ ä¸­è‹±æ–‡gap < 5%ï¼ˆvs ç¿»è¯‘æ–¹æ¡ˆ 10-15%ï¼‰
  â­ åŸºç¡€ä»»åŠ¡ä¸­æ–‡æˆåŠŸç‡ > 85%
```

### ç”Ÿäº§éƒ¨ç½²æ ‡å‡†

```
å¿…è¾¾æŒ‡æ ‡:
  âœ… æ¨¡å‹ç¨³å®šï¼ˆæ— å´©æºƒï¼‰
  âœ… æ¨ç†é€Ÿåº¦å¯æ¥å—ï¼ˆ<50msï¼‰
  âœ… å†…å­˜å ç”¨åˆç†ï¼ˆ<4GBï¼‰

æœŸæœ›æŒ‡æ ‡:
  â­ æ”¯æŒå®æ—¶æ¨ç†ï¼ˆ<20msï¼‰
  â­ æ‰¹å¤„ç†ä¼˜åŒ–
  â­ å¯é…ç½®fallbackï¼ˆå¯¹é½å±‚å¤±è´¥æ—¶ç”¨ç¿»è¯‘ï¼‰
```

---

## ğŸ”„ æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

| ç»´åº¦ | æ–¹æ¡ˆA: ç¿»è¯‘æ¡¥æ¥ | æ–¹æ¡ˆB: å¯¹é½å±‚ | æ”¹è¿› |
|-----|---------------|-------------|-----|
| **å®ç°éš¾åº¦** | â­ ç®€å• | â­â­â­ ä¸­ç­‰ | éœ€è¦è®­ç»ƒ |
| **å¼€å‘æ—¶é—´** | 1-2å¤© | 1-2å‘¨ | +10å€ |
| **è®­ç»ƒéœ€æ±‚** | æ—  | éœ€è¦ï¼ˆ1-3å¤©GPUï¼‰ | æœ‰æˆæœ¬ |
| **æ•°æ®éœ€æ±‚** | 100æœ¯è¯­ | 2000-3000å¯¹ | +20å€ |
| **ä¸­æ–‡ç†è§£** | ä¾èµ–ç¿»è¯‘è´¨é‡ | ç›´æ¥è¯­ä¹‰ç†è§£ | âœ… æ›´å‡†ç¡® |
| **æ¨ç†é€Ÿåº¦** | ~150ms | ~30ms | âœ… å¿«5å€ |
| **æˆåŠŸç‡gap** | 10-15% | ç›®æ ‡<5% | âœ… ç¼©å°gap |
| **ç»´æŠ¤æˆæœ¬** | éœ€ç»´æŠ¤è¯å…¸ | æ¨¡å‹å›ºå®š | âœ… æ›´ä½ |
| **æ‰©å±•æ€§** | éš¾æ‰©å±• | æ˜“æ‰©å±•ï¼ˆå¢åŠ æ•°æ®é‡è®­ï¼‰ | âœ… æ›´å¥½ |

---

## ğŸ’¡ å…³é”®æŠ€æœ¯è¦ç‚¹

### 1. ä¸ºä»€ä¹ˆåªè®­ç»ƒå¯¹é½å±‚ï¼Ÿ

```
å›ºå®šéƒ¨åˆ†ï¼ˆä¸è®­ç»ƒï¼‰:
  âœ… MineCLIPè§†è§‰ç¼–ç å™¨ - å·²åœ¨å¤§è§„æ¨¡Minecraftæ•°æ®ä¸Šè®­ç»ƒ
  âœ… MineCLIPæ–‡æœ¬ç¼–ç å™¨ - è‹±æ–‡ç†è§£èƒ½åŠ›å¼º
  âœ… Chinese-CLIP - ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º

è®­ç»ƒéƒ¨åˆ†:
  ğŸ¯ å¯¹é½å±‚ - å­¦ä¹ ä¸­æ–‡â†’MineCLIPç©ºé—´çš„æ˜ å°„

ä¼˜åŠ¿:
  âš¡ è®­ç»ƒæ•°æ®éœ€æ±‚å°ï¼ˆ2000å¯¹ vs 10ä¸‡+è§†é¢‘ï¼‰
  âš¡ è®­ç»ƒæ—¶é—´çŸ­ï¼ˆ1-3å¤© vs æ•°å‘¨ï¼‰
  âš¡ ä¿æŒåŸæ¨¡å‹æ€§èƒ½ï¼ˆä¸ç ´åMineCLIPå’ŒChinese-CLIPï¼‰
```

### 2. æŸå¤±å‡½æ•°è®¾è®¡

```python
# ç»„åˆæŸå¤±
loss = MSE(aligned, target) + 0.1 * (1 - CosineSim(aligned, target))

åŸå› :
  1. MSE - ä¿è¯åµŒå…¥æ•°å€¼æ¥è¿‘
  2. CosineSim - ä¿è¯è¯­ä¹‰æ–¹å‘ä¸€è‡´
  3. 0.1æƒé‡ - MSEä¸»å¯¼ï¼Œä½™å¼¦è¾…åŠ©
```

### 3. æ•°æ®å¢å¼ºç­–ç•¥

```python
# 1. åŒä¹‰è¯å¢å¼º
("ç æ ‘", "chop tree")
("ä¼æœ¨", "chop tree")  # åŒä¸€ç›®æ ‡
("è·å–æœ¨å¤´", "chop tree")

# 2. çŸ­è¯­å˜ä½“
("æ‰¾åˆ°æ´ç©´", "find cave")
("å¯»æ‰¾æ´ç©´", "find cave")
("è¿›å…¥æ´ç©´", "find cave")

# 3. ä¸Šä¸‹æ–‡å¢å¼º
("ç æ ‘", "chop tree")
("ç ä¸€æ£µæ ‘", "chop a tree")  # æ›´è‡ªç„¶çš„è¡¨è¿°

æ•ˆæœ: æå‡æ¨¡å‹é²æ£’æ€§
```

---

## ğŸš¨ æ½œåœ¨é£é™©ä¸åº”å¯¹

### é£é™©1: Chinese-CLIPåµŒå…¥ç»´åº¦ä¸åŒ¹é…

```
é—®é¢˜: Chinese-CLIPè¾“å‡ºå¯èƒ½ä¸æ˜¯512ç»´
åº”å¯¹:
  âœ“ æ£€æŸ¥æ¨¡å‹é…ç½®
  âœ“ å¦‚æœä¸æ˜¯512ç»´ï¼Œä¿®æ”¹å¯¹é½å±‚è¾“å…¥ç»´åº¦
  âœ“ æˆ–ä½¿ç”¨æŠ•å½±å±‚: Linear(chinese_dim, 512)
```

### é£é™©2: è®­ç»ƒæ•°æ®ä¸è¶³

```
é—®é¢˜: 2000å¯¹å¯èƒ½ä¸å¤Ÿ
åº”å¯¹:
  âœ“ ä¼˜å…ˆä½¿ç”¨ç°æœ‰æ•°æ®è®­ç»ƒbaseline
  âœ“ æ ¹æ®è¯„ä¼°ç»“æœå†³å®šæ˜¯å¦éœ€è¦æ›´å¤šæ•°æ®
  âœ“ å¯ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆå›è¯‘ã€åŒä¹‰è¯æ›¿æ¢ï¼‰
```

### é£é™©3: å¯¹é½å±‚è¿‡æ‹Ÿåˆ

```
é—®é¢˜: éªŒè¯é›†lossä¸ä¸‹é™
åº”å¯¹:
  âœ“ å¢åŠ Dropout
  âœ“ ä½¿ç”¨æ›´ç®€å•çš„ç½‘ç»œï¼ˆå•å±‚Linearï¼‰
  âœ“ Early stopping
  âœ“ æ•°æ®å¢å¼º
```

### é£é™©4: æ€§èƒ½æœªè¾¾é¢„æœŸ

```
é—®é¢˜: å¯¹é½å±‚æ–¹æ¡ˆä¸å¦‚ç¿»è¯‘
åº”å¯¹:
  âœ“ åˆ†æå¤±è´¥case
  âœ“ æ£€æŸ¥è®­ç»ƒæ›²çº¿
  âœ“ å°è¯•ä¸åŒçš„ç½‘ç»œç»“æ„
  âœ“ Fallbackåˆ°ç¿»è¯‘æ–¹æ¡ˆ
```

---

## âœ… æ£€æŸ¥æ¸…å•

### å¼€å§‹å‰æ£€æŸ¥

- [ ] æ–¹æ¡ˆAï¼ˆç¿»è¯‘æ¡¥æ¥ï¼‰å·²å®Œæˆå¹¶éªŒè¯
- [ ] è¯„ä¼°æ¡†æ¶å¯æ­£å¸¸è¿è¡Œ
- [ ] GPUå¯ç”¨ï¼ˆå»ºè®®ï¼ŒCPUä¹Ÿå¯ä»¥ä½†è¾ƒæ…¢ï¼‰
- [ ] Chinese-CLIPæ¨¡å‹å¯æ­£å¸¸ä¸‹è½½

### å®æ–½ä¸­æ£€æŸ¥

- [ ] MultilingualMineCLIPç±»å®ç°æ­£ç¡®
- [ ] AlignmentTrainerç±»å®ç°æ­£ç¡®
- [ ] è®­ç»ƒæ•°æ®ç”ŸæˆæˆåŠŸï¼ˆ>2000å¯¹ï¼‰
- [ ] è®­ç»ƒæŸå¤±æ­£å¸¸æ”¶æ•›
- [ ] éªŒè¯é›†æ€§èƒ½åˆç†

### å®Œæˆåæ£€æŸ¥

- [ ] å¯¹æ¯”è¯„ä¼°å®Œæˆ
- [ ] æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
- [ ] ä»£ç æ–‡æ¡£å®Œæ•´
- [ ] æƒé‡æ–‡ä»¶å·²ä¿å­˜
- [ ] ä½¿ç”¨æŒ‡å—å·²æ›´æ–°

---

## ğŸ“š å‚è€ƒèµ„æº

**å·²æœ‰ä»£ç **:
- `src/evaluation/steve1_evaluator.py` - è¯„ä¼°å™¨ï¼ˆéœ€ä¿®æ”¹ï¼‰
- `src/translation/translator.py` - ç¿»è¯‘å™¨ï¼ˆå‚è€ƒè¯­è¨€æ£€æµ‹ï¼‰
- `src/utils/steve1_mineclip_agent_env_utils.py` - MineCLIPåŠ è½½

**å¤–éƒ¨èµ„æº**:
- Chinese-CLIP: https://github.com/OFA-Sys/Chinese-CLIP
- MineCLIPè®ºæ–‡: https://arxiv.org/abs/2206.08853
- STEVE-1è®ºæ–‡: https://arxiv.org/abs/2306.00937

**é¡¹ç›®æ–‡æ¡£**:
- `docs/design/CHINESE_AIMC_AGENT_TECHNICAL_PLAN.md` - æ•´ä½“æ–¹æ¡ˆ
- `docs/guides/STEVE1_EVALUATION_GUIDE.md` - è¯„ä¼°æ–¹æ³•
- `docs/design/UNIVERSAL_MINECLIP_STRATEGY.md` - MineCLIPé€šç”¨ç­–ç•¥

---

**æ–¹æ¡ˆç‰ˆæœ¬**: v1.0  
**è®¾è®¡æ—¥æœŸ**: 2025-11-10  
**çŠ¶æ€**: å¾…å®æ–½  
**é¢„è®¡å®Œæˆ**: 2å‘¨

**ä¸‹ä¸€æ­¥**: 
1. å®¡é˜…æœ¬è®¾è®¡æ–‡æ¡£
2. ç¡®è®¤å®æ–½è®¡åˆ’
3. å¼€å§‹ä»£ç å®ç°

