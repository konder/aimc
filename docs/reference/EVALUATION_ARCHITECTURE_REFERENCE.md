# è¯„ä¼°æ¶æ„å¿«é€Ÿå‚è€ƒ

## ğŸ—ï¸ æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EvaluationFramework (Manager)              â”‚
â”‚  èŒè´£ï¼šä»»åŠ¡ç®¡ç†ã€æ‰¹é‡è°ƒåº¦ã€æŠ¥å‘Šç”Ÿæˆ                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ TaskLoader (åŠ è½½ YAML é…ç½®)                        â”‚
â”‚  â€¢ ReportGenerator (ç”Ÿæˆ JSON + TXT)                 â”‚
â”‚  â€¢ evaluate_single_task()                           â”‚
â”‚  â€¢ evaluate_task_list()                             â”‚
â”‚  â€¢ evaluate_test_set()                              â”‚
â”‚  â€¢ generate_report()                                â”‚
â”‚  â€¢ print_summary()                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ ç®¡ç†å’Œè°ƒåº¦
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           STEVE1Evaluator (Worker)                   â”‚
â”‚  èŒè´£ï¼šä»»åŠ¡æ‰§è¡Œã€æ¨¡å‹åŠ è½½ã€è‡ªåŠ¨ç¿»è¯‘                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ ChineseTranslator (ä¸­æ–‡â†’è‹±æ–‡)                     â”‚
â”‚  â€¢ evaluate_task() [å”¯ä¸€çš„å…¬å¼€è¯„ä¼°æ–¹æ³•]              â”‚
â”‚  â€¢ close()                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ æ‰§è¡Œç¯å¢ƒ
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Environment + Agent + MineCLIP              â”‚
â”‚  MineRL ç¯å¢ƒ / è‡ªå®šä¹‰ç¯å¢ƒ                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ API é€ŸæŸ¥è¡¨

### STEVE1Evaluatorï¼ˆæ‰§è¡Œå™¨ï¼‰

#### åˆå§‹åŒ–
```python
evaluator = STEVE1Evaluator(
    model_path="data/weights/vpt/2x.model",
    weights_path="data/weights/steve1/steve1.weights",
    prior_weights="data/weights/steve1/steve1_prior.pt",
    text_cond_scale=6.0,
    visual_cond_scale=7.0,
    seed=42,
    enable_render=False,
    env_name='MineRLHarvestEnv-v0'
)
```

#### å…¬å¼€æ–¹æ³•ï¼ˆä»…2ä¸ªï¼‰

| æ–¹æ³• | å‚æ•° | è¿”å› | è¯´æ˜ |
|------|------|------|------|
| `evaluate_task()` | `task_id`, `language`, `instruction`, `n_trials`, `max_steps` | `TaskResult` | **æ‰§è¡Œå•ä¸ªä»»åŠ¡** |
| `close()` | æ—  | æ—  | æ¸…ç†èµ„æº |

#### ç¤ºä¾‹
```python
result = evaluator.evaluate_task(
    task_id="harvest_wood",
    language="zh",              # è‡ªåŠ¨ç¿»è¯‘ä¸­æ–‡
    instruction="ç æ ‘",
    n_trials=3,
    max_steps=2000
)
print(f"æˆåŠŸç‡: {result.success_rate * 100:.1f}%")
evaluator.close()
```

---

### EvaluationFrameworkï¼ˆç®¡ç†å™¨ï¼‰

#### åˆå§‹åŒ–
```python
from src.evaluation.eval_framework import EvaluationFramework, EvaluationConfig

config = EvaluationConfig(
    model_path="...",
    weights_path="...",
    n_trials=3,
    max_steps=2000,
    enable_render=False,
    task_config_path="config/eval_tasks.yaml",
    results_dir="results/evaluation"
)

framework = EvaluationFramework(config=config)
# æˆ–ä½¿ç”¨é»˜è®¤é…ç½®
framework = EvaluationFramework()
```

#### å…¬å¼€æ–¹æ³•

| æ–¹æ³• | å‚æ•° | è¿”å› | è¯´æ˜ |
|------|------|------|------|
| `evaluate_single_task()` | `task_id`, `n_trials`, `max_steps` | `TaskResult` | è¯„ä¼°å•ä¸ªä»»åŠ¡ï¼ˆä» YAMLï¼‰ |
| `evaluate_task_list()` | `task_ids`, `n_trials`, `max_steps` | `List[TaskResult]` | **æ‰¹é‡è¯„ä¼°ä»»åŠ¡** |
| `evaluate_test_set()` | `test_set_name`, `n_trials`, `max_steps` | `List[TaskResult]` | è¯„ä¼°æµ‹è¯•é›† |
| `generate_report()` | `results`, `report_name` | `(json_path, txt_path)` | **ç”ŸæˆæŠ¥å‘Š** |
| `print_summary()` | `results` | æ—  | æ‰“å°ç»Ÿè®¡æ‘˜è¦ |
| `close()` | æ—  | æ—  | æ¸…ç†èµ„æº |

#### ç¤ºä¾‹
```python
# å•ä¸ªä»»åŠ¡
result = framework.evaluate_single_task('harvest_wood_zh')

# æ‰¹é‡ä»»åŠ¡
results = framework.evaluate_task_list([
    'harvest_wood_en',
    'harvest_wood_zh'
])

# æµ‹è¯•é›†
results = framework.evaluate_test_set('quick_test')

# æ‰“å°æ‘˜è¦
framework.print_summary(results)

# ç”ŸæˆæŠ¥å‘Š
framework.generate_report(results, "my_evaluation")

# æ¸…ç†
framework.close()
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯é€‰æ‹©

| åœºæ™¯ | æ¨èæ–¹å¼ | ç†ç”± |
|------|---------|------|
| è°ƒè¯•å•ä¸ªä»»åŠ¡ | `STEVE1Evaluator` | ç›´æ¥æ§åˆ¶ï¼Œçµæ´» |
| æ‰¹é‡è¯„ä¼°ä»»åŠ¡ | `EvaluationFramework` | è‡ªåŠ¨è°ƒåº¦ï¼Œç”ŸæˆæŠ¥å‘Š |
| æ­£å¼è¯„ä¼° | `EvaluationFramework` | å®Œæ•´çš„é…ç½®ç®¡ç†å’ŒæŠ¥å‘Š |
| è‡ªå®šä¹‰è¯„ä¼°æµç¨‹ | `STEVE1Evaluator` | è‡ªç”±ç»„åˆ |
| ä¸­æ–‡æŒ‡ä»¤è¯„ä¼° | ä»»æ„ï¼ˆè‡ªåŠ¨ç¿»è¯‘ï¼‰ | ä¸¤è€…éƒ½æ”¯æŒ |

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
src/evaluation/
â”œâ”€â”€ steve1_evaluator.py      # âš¡ æ‰§è¡Œå™¨ï¼šä»»åŠ¡æ‰§è¡Œ
â”œâ”€â”€ eval_framework.py        # ğŸ›ï¸  ç®¡ç†å™¨ï¼šä»»åŠ¡ç®¡ç†
â”œâ”€â”€ task_loader.py           # ğŸ“‚ ä»»åŠ¡é…ç½®åŠ è½½
â”œâ”€â”€ metrics.py               # ğŸ“Š ç»“æœæ•°æ®ç»“æ„
â””â”€â”€ report_generator.py      # ğŸ“„ æŠ¥å‘Šç”Ÿæˆå·¥å…·

src/translation/
â””â”€â”€ translator.py            # ğŸŒ ä¸­æ–‡ç¿»è¯‘

config/
â””â”€â”€ eval_tasks.yaml          # âš™ï¸  ä»»åŠ¡é…ç½®æ–‡ä»¶

scripts/
â”œâ”€â”€ evaluate_harvest.py      # ğŸ”§ å•ä»»åŠ¡ç¤ºä¾‹
â””â”€â”€ evaluate_with_framework.py # ğŸ¯ æ‰¹é‡è¯„ä¼°ç¤ºä¾‹
```

---

## âš™ï¸ é…ç½®æ–‡ä»¶æ ¼å¼

### config/eval_tasks.yaml

```yaml
basic_tasks:
  - task_id: "harvest_wood_en"
    category: "harvest"
    difficulty: "easy"
    description: "ä½¿ç”¨è‹±æ–‡æŒ‡ä»¤ç æ ‘"
    env_name: "MineRLHarvestEnv-v0"
    en_instruction: "chop tree"
    n_trials: 3
    max_steps: 2000

  - task_id: "harvest_wood_zh"
    category: "harvest"
    difficulty: "easy"
    description: "ä½¿ç”¨ä¸­æ–‡æŒ‡ä»¤ç æ ‘"
    env_name: "MineRLHarvestEnv-v0"
    zh_instruction: "ç æ ‘"  # è‡ªåŠ¨ç¿»è¯‘æˆ "chop tree"
    n_trials: 3
    max_steps: 2000

# æµ‹è¯•é›†å®šä¹‰
quick_test:
  - "harvest_wood_en"
  - "harvest_wood_zh"
```

---

## ğŸš€ å‘½ä»¤è¡Œæ¥å£

### ç›´æ¥è¿è¡Œ Framework

```bash
# å•ä¸ªä»»åŠ¡
python src/evaluation/eval_framework.py \
    --task harvest_wood_zh \
    --n-trials 3 \
    --max-steps 2000

# æ‰¹é‡ä»»åŠ¡
python src/evaluation/eval_framework.py \
    --task-list harvest_wood_en harvest_wood_zh \
    --n-trials 3

# æµ‹è¯•é›†
python src/evaluation/eval_framework.py \
    --test-set quick_test \
    --n-trials 5

# å¯ç”¨æ¸²æŸ“
python src/evaluation/eval_framework.py \
    --task harvest_wood_zh \
    --render
```

### ä½¿ç”¨ç¤ºä¾‹è„šæœ¬

```bash
# ä¸­æ–‡ vs è‹±æ–‡å¯¹æ¯”
python scripts/evaluate_with_framework.py

# å•ä»»åŠ¡è¯„ä¼°ï¼ˆå¸¦æ¸²æŸ“ï¼‰
python scripts/evaluate_harvest.py
```

---

## ğŸ“Š è¾“å‡ºæ ¼å¼

### æ§åˆ¶å°è¾“å‡º
```
================================================================================
è¯„ä¼°ç»“æœæ±‡æ€»
================================================================================

ä»»åŠ¡ID                       æŒ‡ä»¤        æˆåŠŸç‡      å¹³å‡æ­¥æ•°      å¹³å‡æ—¶é—´
--------------------------------------------------------------------------------
harvest_wood_en             chop tree    100.0%      839.3        56.9s
harvest_wood_zh             ç æ ‘         100.0%      852.1        58.3s

--------------------------------------------------------------------------------
æ€»ä½“ç»Ÿè®¡                     N/A          100.0%      845.7        57.6s

æ€»ä»»åŠ¡æ•°: 2
æ€»è¯•éªŒæ•°: 6
================================================================================
```

### JSON æŠ¥å‘Š
```json
{
  "metadata": {
    "timestamp": "2025-11-08T17:12:34",
    "total_tasks": 2,
    "evaluator": "STEVE-1",
    "framework": "EvaluationFramework"
  },
  "tasks": [
    {
      "task_id": "harvest_wood_zh",
      "instruction": "ç æ ‘",
      "language": "zh",
      "success_rate": 100.0,
      "avg_steps": 852.1,
      "trials": [...]
    }
  ],
  "summary": {
    "overall_success_rate": 100.0,
    "total_trials": 6
  }
}
```

---

## ğŸ”‘ å…³é”®ç‰¹æ€§

### 1. è‡ªåŠ¨ä¸­æ–‡ç¿»è¯‘
```python
# ä¸­æ–‡æŒ‡ä»¤è‡ªåŠ¨ç¿»è¯‘
result = evaluator.evaluate_task(
    instruction="ç æ ‘",  # è‡ªåŠ¨ â†’ "chop tree"
    language="zh"
)
```

### 2. å‚æ•°ä¼˜å…ˆçº§
```
å‡½æ•°å‚æ•° > ä»»åŠ¡é…ç½® > å…¨å±€é…ç½®
```

### 3. è‡ªå®šä¹‰ç¯å¢ƒæ”¯æŒ
```python
# åœ¨ YAML ä¸­æŒ‡å®š
env_name: "MineRLHarvestEnv-v0"

# æˆ–åœ¨ä»£ç ä¸­
evaluator = STEVE1Evaluator(env_name='CustomEnv-v0')
```

### 4. å»¶è¿ŸåŠ è½½
```python
# æ¨¡å‹å’Œç¯å¢ƒåªåœ¨é¦–æ¬¡ evaluate_task æ—¶åŠ è½½
evaluator = STEVE1Evaluator()  # å¿«é€Ÿ
result = evaluator.evaluate_task(...)  # æ­¤æ—¶æ‰åŠ è½½
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **ä½¿ç”¨æŒ‡å—**: `docs/guides/EVALUATION_FRAMEWORK_GUIDE.md`
- **é‡æ„æ€»ç»“**: `docs/summaries/EVALUATION_FRAMEWORK_REFACTORING.md`
- **æ¸…ç†æ€»ç»“**: `docs/summaries/STEVE1_EVALUATOR_CLEANUP.md`
- **ä»»åŠ¡é…ç½®**: `config/eval_tasks.yaml`

---

**æ›´æ–°æ—¥æœŸ**: 2025-11-08  
**ç‰ˆæœ¬**: 2.0 (é‡æ„å)

