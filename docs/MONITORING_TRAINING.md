# è®­ç»ƒç›‘æ§æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ç›‘æ§å’ŒæŸ¥çœ‹ MineDojo è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æ•°æ®ã€‚

---

## ç›®å½•

1. [æŸ¥çœ‹ Loss å’Œè®­ç»ƒæŒ‡æ ‡](#1-æŸ¥çœ‹-loss-å’Œè®­ç»ƒæŒ‡æ ‡)
2. [TensorBoard å¯è§†åŒ–](#2-tensorboard-å¯è§†åŒ–)
3. [æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶](#3-æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶)
4. [å…³é”®æŒ‡æ ‡è§£è¯»](#4-å…³é”®æŒ‡æ ‡è§£è¯»)
5. [MPS è®¾å¤‡æ”¯æŒ](#5-mps-è®¾å¤‡æ”¯æŒ)

---

## 1. æŸ¥çœ‹ Loss å’Œè®­ç»ƒæŒ‡æ ‡

### æ–¹æ³•1: TensorBoardï¼ˆæ¨èï¼‰

TensorBoard æä¾›æœ€ç›´è§‚çš„å¯è§†åŒ–ç•Œé¢ï¼š

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir logs/tensorboard

# åœ¨æµè§ˆå™¨æ‰“å¼€
http://localhost:6006
```

**å¯ä»¥çœ‹åˆ°çš„æŒ‡æ ‡**ï¼š

| æ ‡ç­¾é¡µ | æŒ‡æ ‡ | è¯´æ˜ |
|--------|------|------|
| **SCALARS** | `train/policy_loss` | ç­–ç•¥æŸå¤±ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| | `train/value_loss` | ä»·å€¼å‡½æ•°æŸå¤± |
| | `train/entropy_loss` | ç†µæŸå¤±ï¼ˆæ¢ç´¢ç¨‹åº¦ï¼‰ |
| | `train/approx_kl` | KLæ•£åº¦ï¼ˆç­–ç•¥å˜åŒ–ï¼‰ |
| | `train/clip_fraction` | è£å‰ªæ¯”ä¾‹ |
| | `train/learning_rate` | å½“å‰å­¦ä¹ ç‡ |
| | `rollout/ep_rew_mean` | å¹³å‡episodeå¥–åŠ± |
| | `rollout/ep_len_mean` | å¹³å‡episodeé•¿åº¦ |
| | `eval/mean_reward` | è¯„ä¼°å¹³å‡å¥–åŠ± |
| **DISTRIBUTIONS** | å‚æ•°åˆ†å¸ƒ | ç½‘ç»œæƒé‡åˆ†å¸ƒ |
| **GRAPHS** | è®¡ç®—å›¾ | æ¨¡å‹ç»“æ„å¯è§†åŒ– |

### æ–¹æ³•2: æ§åˆ¶å°å®æ—¶è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå®æ—¶æ‰“å°ï¼š

```
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    fps             | 42       |
|    iterations      | 10       |
|    time_elapsed    | 485      |
|    total_timesteps | 20480    |
| train/             |          |
|    approx_kl       | 0.012    |
|    clip_fraction   | 0.089    |
|    clip_range      | 0.2      |
|    entropy_loss    | -2.45    |
|    learning_rate   | 0.0003   |
|    loss            | 1.23     |
|    policy_gradient_loss | -0.01 |
|    value_loss      | 0.45     |
---------------------------------
```

### æ–¹æ³•3: æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ `logs/training/` ç›®å½•ï¼š

```bash
# å®æ—¶æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f logs/training/training_*.log

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
cat logs/training/training_*.log

# æœç´¢ç‰¹å®šæŒ‡æ ‡
grep "ep_rew_mean" logs/training/training_*.log
```

---

## 2. TensorBoard å¯è§†åŒ–

### 2.1 å¯åŠ¨ TensorBoard

```bash
# åŸºæœ¬ç”¨æ³•
tensorboard --logdir logs/tensorboard

# æŒ‡å®šç«¯å£
tensorboard --logdir logs/tensorboard --port 6007

# ç»‘å®šåˆ°æ‰€æœ‰ç½‘ç»œæ¥å£ï¼ˆè¿œç¨‹è®¿é—®ï¼‰
tensorboard --logdir logs/tensorboard --bind_all
```

### 2.2 TensorBoard ç•Œé¢ä½¿ç”¨

#### ğŸ“Š Scalarsï¼ˆæ ‡é‡ï¼‰

æŸ¥çœ‹ loss å’Œå„ç§æŒ‡æ ‡çš„æ—¶é—´åºåˆ—æ›²çº¿ã€‚

**å¸¸ç”¨æ“ä½œ**ï¼š
- **ç¼©æ”¾**ï¼šé¼ æ ‡æ»šè½®æˆ–æ‹–æ‹½
- **å¹³æ»‘**ï¼šå·¦ä¾§ "Smoothing" æ»‘å—è°ƒæ•´æ›²çº¿å¹³æ»‘åº¦
- **å¯¹æ¯”**ï¼šåŒæ—¶æŸ¥çœ‹å¤šä¸ªè®­ç»ƒè¿è¡Œ
- **ä¸‹è½½**ï¼šç‚¹å‡»æ›²çº¿å³ä¸Šè§’ä¸‹è½½æ•°æ®

**å…³é”®æ›²çº¿**ï¼š

1. **è®­ç»ƒæŸå¤±æ›²çº¿**
   ```
   train/policy_loss    # ç­–ç•¥æŸå¤±
   train/value_loss     # ä»·å€¼æŸå¤±  
   train/entropy_loss   # ç†µæŸå¤±
   ```

2. **æ€§èƒ½æ›²çº¿**
   ```
   rollout/ep_rew_mean  # å¹³å‡å¥–åŠ±ï¼ˆæœ€é‡è¦ï¼‰
   eval/mean_reward     # è¯„ä¼°å¥–åŠ±
   ```

3. **è®­ç»ƒæŒ‡æ ‡**
   ```
   train/approx_kl      # KLæ•£åº¦
   train/clip_fraction  # è£å‰ªæ¯”ä¾‹
   train/explained_variance  # è§£é‡Šæ–¹å·®
   ```

#### ğŸ“ˆ å…¸å‹çš„å¥åº·è®­ç»ƒæ›²çº¿

**Policy Loss**:
```
é«˜ |     ___________
   |    /           \____
   |   /                 \____
ä½ |__/________________________â†’ æ—¶é—´
   å¼€å§‹  æ¢ç´¢æœŸ   å­¦ä¹ æœŸ   æ”¶æ•›æœŸ
```

**Episode Reward**:
```
é«˜ |                   ________
   |                __/
   |          _____/
ä½ |_________/___________________â†’ æ—¶é—´
   å¼€å§‹  æ¢ç´¢æœŸ   æå‡æœŸ   ç¨³å®šæœŸ
```

#### ğŸ–¼ï¸ Imagesï¼ˆå›¾åƒï¼‰

å¦‚æœè®°å½•äº†è§‚å¯Ÿå›¾åƒï¼Œå¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹æ™ºèƒ½ä½“çœ‹åˆ°çš„ç”»é¢ã€‚

#### ğŸ“Š Distributionsï¼ˆåˆ†å¸ƒï¼‰

æŸ¥çœ‹ç½‘ç»œæƒé‡å’Œæ¿€æ´»å€¼çš„åˆ†å¸ƒï¼Œç”¨äºè¯Šæ–­æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ã€‚

#### ğŸ” Graphsï¼ˆè®¡ç®—å›¾ï¼‰

å¯è§†åŒ–ç¥ç»ç½‘ç»œç»“æ„ã€‚

---

## 3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶

### 3.1 è®­ç»ƒæ—¥å¿—

ä¸»è®­ç»ƒæ—¥å¿—åŒ…å«è®­ç»ƒå¼€å§‹ã€è¿›åº¦ã€æ£€æŸ¥ç‚¹ä¿å­˜ç­‰ä¿¡æ¯ï¼š

```bash
# å®æ—¶æŸ¥çœ‹
tail -f logs/training/training_20241019_143022.log

# æŸ¥çœ‹å®Œæ•´æ—¥å¿—
cat logs/training/training_*.log

# åªçœ‹é”™è¯¯
grep "ERROR\|âœ—" logs/training/training_*.log
```

**æ—¥å¿—å†…å®¹ç¤ºä¾‹**ï¼š
```
[2024-10-19 14:30:22] ======================================================================
[2024-10-19 14:30:22] MineDojo harvest_1_paper è®­ç»ƒå¼€å§‹
[2024-10-19 14:30:22] ======================================================================
[2024-10-19 14:30:22] è®­ç»ƒé…ç½®:
[2024-10-19 14:30:22]   ä»»åŠ¡: harvest_milk
[2024-10-19 14:30:22]   æ€»æ­¥æ•°: 500,000
[2024-10-19 14:30:22]   è®¾å¤‡: mps
[2024-10-19 14:30:25] [1/5] åˆ›å»ºè®­ç»ƒç¯å¢ƒ...
[2024-10-19 14:30:28]   âœ“ è®­ç»ƒç¯å¢ƒåˆ›å»ºæˆåŠŸ
```

### 3.2 TensorBoard äº‹ä»¶æ–‡ä»¶

TensorBoard è¯»å– `logs/tensorboard/` ä¸­çš„äº‹ä»¶æ–‡ä»¶ï¼š

```bash
# æŸ¥çœ‹äº‹ä»¶æ–‡ä»¶
ls -lh logs/tensorboard/ppo_harvest_paper_*/

# è¾“å‡ºç¤ºä¾‹
-rw-r--r--  events.out.tfevents.1234567890.hostname
```

### 3.3 å¯¼å‡º TensorBoard æ•°æ®

```python
# ä½¿ç”¨ TensorBoard æ•°æ®å¯¼å‡ºå·¥å…·
from tensorboard.backend.event_processing import event_accumulator

ea = event_accumulator.EventAccumulator('logs/tensorboard/ppo_harvest_paper_1/')
ea.Reload()

# è·å–æ‰€æœ‰æ ‡é‡
print(ea.Tags()['scalars'])

# è¯»å–ç‰¹å®šæŒ‡æ ‡
policy_loss = ea.Scalars('train/policy_loss')
for item in policy_loss:
    print(f"Step: {item.step}, Value: {item.value}")
```

---

## 4. å…³é”®æŒ‡æ ‡è§£è¯»

### 4.1 Loss æŒ‡æ ‡

#### Policy Lossï¼ˆç­–ç•¥æŸå¤±ï¼‰
- **å«ä¹‰**: ç­–ç•¥ç½‘ç»œçš„æŸå¤±ï¼Œè¡¡é‡ç­–ç•¥æ›´æ–°çš„å¹…åº¦
- **æ­£å¸¸èŒƒå›´**: 0.001 - 0.1
- **æœŸæœ›è¶‹åŠ¿**: 
  - åˆæœŸï¼šè¾ƒé«˜ä¸”æ³¢åŠ¨ï¼ˆ0.05-0.2ï¼‰
  - ä¸­æœŸï¼šé€æ¸ä¸‹é™å¹¶ç¨³å®š
  - åæœŸï¼šå°å¹…æ³¢åŠ¨ï¼Œç»´æŒä½å€¼
- **å¼‚å¸¸æƒ…å†µ**:
  - æŒç»­ä¸Šå‡ â†’ å­¦ä¹ ç‡è¿‡é«˜æˆ–æ¢ç´¢ä¸è¶³
  - æŒç»­ä¸º0 â†’ æ¨¡å‹å´©æºƒ
  - å‰§çƒˆæ³¢åŠ¨ â†’ å­¦ä¹ ç‡è¿‡é«˜æˆ–æ‰¹æ¬¡å¤ªå°

#### Value Lossï¼ˆä»·å€¼æŸå¤±ï¼‰
- **å«ä¹‰**: ä»·å€¼å‡½æ•°çš„é¢„æµ‹è¯¯å·®
- **æ­£å¸¸èŒƒå›´**: 0.1 - 10
- **æœŸæœ›è¶‹åŠ¿**: é€æ¸ä¸‹é™å¹¶ç¨³å®š
- **å¼‚å¸¸æƒ…å†µ**:
  - æŒç»­ä¸Šå‡ â†’ ä»·å€¼å‡½æ•°è¿‡æ‹Ÿåˆ
  - æå¤§å€¼ â†’ å¥–åŠ±ç¼©æ”¾é—®é¢˜

#### Entropy Lossï¼ˆç†µæŸå¤±ï¼‰
- **å«ä¹‰**: ç­–ç•¥çš„éšæœºæ€§ï¼Œè´Ÿå€¼
- **æ­£å¸¸èŒƒå›´**: -2.0 åˆ° -4.0
- **æœŸæœ›è¶‹åŠ¿**: 
  - åˆæœŸï¼šé«˜ç†µï¼ˆæ¥è¿‘-2ï¼‰ï¼Œæ¢ç´¢æ€§å¼º
  - åæœŸï¼šä½ç†µï¼ˆæ¥è¿‘-4ï¼‰ï¼Œæ›´ç¡®å®šæ€§
- **å¼‚å¸¸æƒ…å†µ**:
  - å¿«é€Ÿé™è‡³-6ä»¥ä¸‹ â†’ è¿‡æ—©æ”¶æ•›ï¼Œæ¢ç´¢ä¸è¶³
  - ç»´æŒåœ¨-1é™„è¿‘ â†’ ç­–ç•¥è¿‡äºéšæœº

### 4.2 æ€§èƒ½æŒ‡æ ‡

#### Episode Reward Meanï¼ˆå¹³å‡å¥–åŠ±ï¼‰
- **å«ä¹‰**: æœ€è¿‘ episodes çš„å¹³å‡ç´¯è®¡å¥–åŠ±
- **æœŸæœ›è¶‹åŠ¿**: **é€æ¸ä¸Šå‡**ï¼ˆæœ€é‡è¦çš„æŒ‡æ ‡ï¼ï¼‰
- **harvest_milk å‚è€ƒå€¼**:
  - åˆæœŸ (0-50Kæ­¥): 0.0 - 0.1
  - ä¸­æœŸ (50-200Kæ­¥): 0.1 - 0.5
  - åæœŸ (200K+æ­¥): 0.5 - 1.0
- **å¼‚å¸¸æƒ…å†µ**:
  - é•¿æ—¶é—´ä¸º0 â†’ ä»»åŠ¡å¤ªéš¾æˆ–å¥–åŠ±ç¨€ç–
  - å‰§çƒˆæ³¢åŠ¨ â†’ ç¯å¢ƒéšæœºæ€§å¤§æˆ–ç­–ç•¥ä¸ç¨³å®š

#### Episode Length Meanï¼ˆå¹³å‡æ­¥æ•°ï¼‰
- **å«ä¹‰**: å¹³å‡ episode æŒç»­æ—¶é—´
- **æœŸæœ›è¶‹åŠ¿**: 
  - ç®€å•ä»»åŠ¡ï¼šé€æ¸ç¼©çŸ­ï¼ˆæ›´å¿«å®Œæˆï¼‰
  - å¤æ‚ä»»åŠ¡ï¼šå¯èƒ½ä¿æŒç¨³å®š
- **harvest_milk**: é€šå¸¸ 200-800 æ­¥

### 4.3 è®­ç»ƒå¥åº·åº¦æŒ‡æ ‡

#### Approx KLï¼ˆè¿‘ä¼¼KLæ•£åº¦ï¼‰
- **å«ä¹‰**: æ–°æ—§ç­–ç•¥çš„å·®å¼‚
- **æ­£å¸¸èŒƒå›´**: 0.01 - 0.03
- **æœŸæœ›**: ä¿æŒç¨³å®š
- **å¼‚å¸¸**: > 0.05 è¡¨ç¤ºç­–ç•¥å˜åŒ–è¿‡å¤§

#### Clip Fractionï¼ˆè£å‰ªæ¯”ä¾‹ï¼‰
- **å«ä¹‰**: è¢« PPO è£å‰ªçš„æ ·æœ¬æ¯”ä¾‹
- **æ­£å¸¸èŒƒå›´**: 0.05 - 0.15
- **æœŸæœ›**: é€‚ä¸­ï¼Œè¯´æ˜ PPO èµ·ä½œç”¨ä½†ä¸è¿‡åº¦
- **å¼‚å¸¸**: 
  - æ¥è¿‘0 â†’ å­¦ä¹ ç‡å¯èƒ½è¿‡ä½
  - æ¥è¿‘1 â†’ å­¦ä¹ ç‡è¿‡é«˜

#### Explained Varianceï¼ˆè§£é‡Šæ–¹å·®ï¼‰
- **å«ä¹‰**: ä»·å€¼å‡½æ•°é¢„æµ‹çš„å‡†ç¡®åº¦
- **æ­£å¸¸èŒƒå›´**: 0.5 - 1.0
- **æœŸæœ›**: é€æ¸å¢åŠ è‡³ > 0.7
- **å¼‚å¸¸**: < 0 è¡¨ç¤ºä»·å€¼å‡½æ•°å®Œå…¨é”™è¯¯

---

## 5. MPS è®¾å¤‡æ”¯æŒ

### 5.1 ä»€ä¹ˆæ˜¯ MPSï¼Ÿ

**MPS (Metal Performance Shaders)** æ˜¯ Apple ä¸º Apple Siliconï¼ˆM1/M2/M3 èŠ¯ç‰‡ï¼‰æä¾›çš„ GPU åŠ é€Ÿæ¡†æ¶ã€‚

**ä¼˜åŠ¿**ï¼š
- ğŸš€ æ¯” CPU å¿« 2-5 å€
- ğŸ”‹ èƒ½æ•ˆæ›´é«˜
- ğŸ’» é€‚åˆ MacBook è®­ç»ƒ

### 5.2 æ£€æŸ¥ MPS æ”¯æŒ

```python
import torch

# æ£€æŸ¥ MPS æ˜¯å¦å¯ç”¨
print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"MPS å¯ç”¨: {torch.backends.mps.is_available()}")
print(f"MPS å·²æ„å»º: {torch.backends.mps.is_built()}")

# å¦‚æœå¯ç”¨ï¼Œæµ‹è¯•åˆ›å»ºå¼ é‡
if torch.backends.mps.is_available():
    x = torch.randn(3, 3).to('mps')
    print(f"MPS æµ‹è¯•æˆåŠŸ: {x.device}")
```

### 5.3 ä½¿ç”¨ MPS è®­ç»ƒ

#### æ–¹æ³•1: è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰

```bash
# è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ MPS
./scripts/train_harvest.sh
```

#### æ–¹æ³•2: æ˜¾å¼æŒ‡å®š

```bash
# æ˜¾å¼ä½¿ç”¨ MPS
python src/training/train_harvest_paper.py --device mps

# æˆ–ä½¿ç”¨è®­ç»ƒè„šæœ¬
./scripts/train_harvest.sh
```

è®­ç»ƒå¼€å§‹æ—¶ä¼šæ˜¾ç¤ºï¼š
```
ğŸ æ£€æµ‹åˆ° Apple Siliconï¼Œä½¿ç”¨ MPS åŠ é€Ÿ
```

#### æ–¹æ³•3: å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆå¯¹æ¯”æ€§èƒ½ï¼‰

```bash
python src/training/train_harvest_paper.py --device cpu
```

### 5.4 MPS æ€§èƒ½å¯¹æ¯”

åœ¨ M1 MacBook Pro ä¸Šçš„å…¸å‹é€Ÿåº¦ï¼ˆharvest_milkï¼Œå•ç¯å¢ƒï¼‰ï¼š

| è®¾å¤‡ | FPS | 10Kæ­¥è€—æ—¶ | ç›¸å¯¹é€Ÿåº¦ |
|------|-----|-----------|----------|
| CPU | 15-25 | 8-10 min | 1x |
| MPS | 40-60 | 3-5 min | 2.5x |
| CUDA (å‚è€ƒ) | 80-120 | 2-3 min | 4-5x |

### 5.5 MPS æ•…éšœæ’é™¤

#### é—®é¢˜1: MPS ä¸å¯ç”¨

```bash
# æ£€æŸ¥ PyTorch ç‰ˆæœ¬ï¼ˆéœ€è¦ >= 1.12ï¼‰
python -c "import torch; print(torch.__version__)"

# å‡çº§ PyTorch
pip install --upgrade torch torchvision
```

#### é—®é¢˜2: MPS è®­ç»ƒå‡ºé”™

å¦‚æœé‡åˆ° MPS ç›¸å…³é”™è¯¯ï¼Œå›é€€åˆ° CPUï¼š

```bash
python src/training/train_harvest_paper.py --device cpu
```

å¸¸è§é”™è¯¯ï¼š
- `NotImplementedError: The operator ... is not currently implemented for the MPS device`
  â†’ æŸäº›æ“ä½œ MPS ä¸æ”¯æŒï¼Œä½¿ç”¨ CPU

#### é—®é¢˜3: å†…å­˜ä¸è¶³

```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
python src/training/train_harvest_paper.py \
    --device mps \
    --batch-size 32

# å‡å°‘å›¾åƒå°ºå¯¸
python src/training/train_harvest_paper.py \
    --device mps \
    --image-size 120 160
```

---

## 6. å®æ—¶ç›‘æ§è„šæœ¬

åˆ›å»ºä¸€ä¸ªä¾¿æ·çš„ç›‘æ§è„šæœ¬ï¼š

```bash
#!/bin/bash
# scripts/monitor_training.sh

# åœ¨ä¸€ä¸ªç»ˆç«¯æ˜¾ç¤ºæ—¥å¿—
echo "è®­ç»ƒæ—¥å¿—:"
tail -f logs/training/training_*.log &
PID1=$!

# æç¤ºæ‰“å¼€ TensorBoard
echo ""
echo "========================================"
echo "åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ:"
echo "  tensorboard --logdir logs/tensorboard"
echo "ç„¶åæ‰“å¼€: http://localhost:6006"
echo "========================================"
echo ""

# ç­‰å¾…ç”¨æˆ·ä¸­æ–­
trap "kill $PID1; exit" INT
wait
```

---

## 7. è®­ç»ƒæ•°æ®åˆ†æç¤ºä¾‹

### 7.1 ä½¿ç”¨ Python åˆ†æ

```python
import pandas as pd
from tensorboard.backend.event_processing import event_accumulator

# åŠ è½½ TensorBoard æ•°æ®
ea = event_accumulator.EventAccumulator(
    'logs/tensorboard/ppo_harvest_paper_1/'
)
ea.Reload()

# æå–å…³é”®æŒ‡æ ‡
def extract_scalar(tag):
    events = ea.Scalars(tag)
    return pd.DataFrame([
        {'step': e.step, 'value': e.value} 
        for e in events
    ])

# è·å–æ•°æ®
reward_df = extract_scalar('rollout/ep_rew_mean')
policy_loss_df = extract_scalar('train/policy_loss')
value_loss_df = extract_scalar('train/value_loss')

# ç»˜å›¾
import matplotlib.pyplot as plt

fig, axes = plt.subplots(3, 1, figsize=(10, 8))

axes[0].plot(reward_df['step'], reward_df['value'])
axes[0].set_title('Episode Reward')
axes[0].set_ylabel('Reward')

axes[1].plot(policy_loss_df['step'], policy_loss_df['value'])
axes[1].set_title('Policy Loss')
axes[1].set_ylabel('Loss')

axes[2].plot(value_loss_df['step'], value_loss_df['value'])
axes[2].set_title('Value Loss')
axes[2].set_ylabel('Loss')

plt.tight_layout()
plt.savefig('training_curves.png')
print("å·²ä¿å­˜è®­ç»ƒæ›²çº¿åˆ° training_curves.png")
```

### 7.2 ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š

```python
# ç®€å•çš„è®­ç»ƒæ€»ç»“
print("=" * 50)
print("è®­ç»ƒæ€»ç»“")
print("=" * 50)
print(f"æ€»æ­¥æ•°: {reward_df['step'].max():,}")
print(f"æœ€ç»ˆå¹³å‡å¥–åŠ±: {reward_df['value'].iloc[-10:].mean():.3f}")
print(f"æœ€ä½³å¥–åŠ±: {reward_df['value'].max():.3f}")
print(f"æœ€ç»ˆç­–ç•¥æŸå¤±: {policy_loss_df['value'].iloc[-10:].mean():.4f}")
print(f"æœ€ç»ˆä»·å€¼æŸå¤±: {value_loss_df['value'].iloc[-10:].mean():.4f}")
print("=" * 50)
```

---

## 8. å¿«é€Ÿå‚è€ƒ

### å¯åŠ¨ç›‘æ§
```bash
# TensorBoard
tensorboard --logdir logs/tensorboard

# æ—¥å¿—
tail -f logs/training/training_*.log
```

### å…³é”®æŒ‡æ ‡ä½ç½®
- **TensorBoard**: `http://localhost:6006` â†’ SCALARS æ ‡ç­¾é¡µ
- **æ§åˆ¶å°**: è®­ç»ƒè¿‡ç¨‹å®æ—¶æ‰“å°
- **æ—¥å¿—æ–‡ä»¶**: `logs/training/training_*.log`

### æœ€é‡è¦çš„æŒ‡æ ‡
1. ğŸ“ˆ `rollout/ep_rew_mean` - **å¿…çœ‹ï¼**å¥–åŠ±å¢é•¿æƒ…å†µ
2. ğŸ“‰ `train/policy_loss` - ç­–ç•¥æ˜¯å¦æ­£å¸¸å­¦ä¹ 
3. ğŸ“‰ `train/value_loss` - ä»·å€¼å‡½æ•°è´¨é‡

### è®¾å¤‡é€‰æ‹©
```bash
--device auto   # è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
--device mps    # Apple Silicon GPU
--device cuda   # NVIDIA GPU
--device cpu    # CPU
```

---

## æ€»ç»“

âœ… **æŸ¥çœ‹ Loss**: TensorBoard çš„ SCALARS æ ‡ç­¾é¡µ  
âœ… **å®æ—¶ç›‘æ§**: `tail -f logs/training/training_*.log`  
âœ… **å¯è§†åŒ–**: `tensorboard --logdir logs/tensorboard`  
âœ… **MPS åŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹ Apple Siliconï¼Œé€Ÿåº¦æå‡ 2-3 å€  
âœ… **å…³é”®æŒ‡æ ‡**: `ep_rew_mean` æ˜¯æœ€é‡è¦çš„æ€§èƒ½æŒ‡æ ‡  

**å¼€å§‹ç›‘æ§ä½ çš„è®­ç»ƒå§ï¼** ğŸ“ŠğŸš€

