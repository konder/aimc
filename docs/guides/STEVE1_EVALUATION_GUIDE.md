# STEVE-1 è¯„ä¼°ä½¿ç”¨æŒ‡å—

> **é—®é¢˜**ï¼šå®˜æ–¹ GitHub æ–‡æ¡£æ¯”è¾ƒç®€ç•¥ï¼Œç¼ºå°‘è¯¦ç»†çš„è¯„ä¼°ä½¿ç”¨è¯´æ˜  
> **æœ¬æŒ‡å—**ï¼šæä¾›å®Œæ•´çš„è¯„ä¼°ã€ä½¿ç”¨å’Œæµ‹è¯•æ–¹æ³•

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [ä¸‰ç§è¯„ä¼°æ¨¡å¼](#ä¸‰ç§è¯„ä¼°æ¨¡å¼)
3. [è‡ªå®šä¹‰æ–‡æœ¬æŒ‡ä»¤è¯„ä¼°](#è‡ªå®šä¹‰æ–‡æœ¬æŒ‡ä»¤è¯„ä¼°)
4. [Python API ä½¿ç”¨](#python-api-ä½¿ç”¨)
5. [è¯„ä¼°æŒ‡æ ‡å’Œä»»åŠ¡](#è¯„ä¼°æŒ‡æ ‡å’Œä»»åŠ¡)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### **å‰ç½®å‡†å¤‡**

```bash
# 1. å…‹éš†ä»“åº“
cd /Users/nanzhang/aimc
git clone https://github.com/Shalev-Lifshitz/STEVE-1.git
cd STEVE-1

# 2. è®¾ç½®ç¯å¢ƒ
conda create -n steve1 python=3.10
conda activate steve1

# 3. å®‰è£…ä¾èµ–ï¼ˆæŒ‰é¡ºåºï¼ï¼‰
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
pip install minedojo git+https://github.com/MineDojo/MineCLIP
pip install git+https://github.com/minerllabs/minerl@v1.0.1
pip install gym==0.19 gym3 attrs opencv-python
pip install gdown tqdm accelerate==0.18.0 wandb
pip install -e .

# 4. ä¸‹è½½æ¨¡å‹æƒé‡
chmod +x download_weights.sh
./download_weights.sh
```

**âš ï¸ é‡è¦æç¤º**ï¼š
- å¿…é¡»ä½¿ç”¨ `gym==0.19`ï¼ˆVPT è¦æ±‚ï¼‰
- å®‰è£…é¡ºåºå¾ˆé‡è¦ï¼ˆMineDojo åå®‰è£… VPT ä¾èµ–ï¼‰
- macOS éœ€è¦å®‰è£… Java 8ï¼ˆMineCraft ä¾èµ–ï¼‰

---

## ğŸ“¹ ä¸‰ç§è¯„ä¼°æ¨¡å¼

å®˜æ–¹æä¾›äº†ä¸‰ä¸ªè„šæœ¬ï¼Œå¯¹åº”ä¸‰ç§ä½¿ç”¨åœºæ™¯ï¼š

### **æ¨¡å¼ 1: ç”Ÿæˆè®ºæ–‡æ¼”ç¤ºè§†é¢‘** ğŸ“„

**è„šæœ¬**ï¼š`run_agent/1_gen_paper_videos.sh`

**ç”¨é€”**ï¼šå¤ç°è®ºæ–‡ä¸­å±•ç¤ºçš„ 13 ä¸ªè¯„ä¼°ä»»åŠ¡

```bash
cd /Users/nanzhang/aimc/STEVE-1

# è¿è¡Œè„šæœ¬
chmod +x run_agent/1_gen_paper_videos.sh
./run_agent/1_gen_paper_videos.sh
```

**è„šæœ¬å†…å®¹**ï¼ˆæ¨æµ‹ï¼‰ï¼š

```bash
#!/bin/bash

# è®ºæ–‡ä¸­çš„ 13 ä¸ªæ—©æœŸæ¸¸æˆä»»åŠ¡
python run_agent/generate_videos.py \
    --model_path data/weights/steve1/steve1_weights.pt \
    --prior_path data/weights/prior/prior_weights.pt \
    --tasks "paper_tasks" \
    --output_dir outputs/paper_videos \
    --num_episodes 10
```

**é¢„æœŸè¾“å‡º**ï¼š
- ğŸ“ `outputs/paper_videos/` ç›®å½•
- åŒ…å« 13 ä¸ªä»»åŠ¡çš„è§†é¢‘æ–‡ä»¶ï¼ˆ.mp4ï¼‰
- æˆåŠŸç‡ç»Ÿè®¡ï¼ˆsuccess_rate.jsonï¼‰

**æ”¯æŒçš„ä»»åŠ¡**ï¼ˆè®ºæ–‡ç¬¬ 4 èŠ‚ï¼‰ï¼š
1. Chopping trees
2. Hunting cows
3. Hunting pigs
4. Mining stone
5. Collecting dirt
6. Collecting sand
7. Collecting wood
8. Killing zombies
9. Approaching trees
10. Approaching cows
11. Finding caves
12. Swimming
13. Exploring

---

### **æ¨¡å¼ 2: è‡ªå®šä¹‰æ–‡æœ¬æç¤º** âœï¸

**è„šæœ¬**ï¼š`run_agent/2_gen_vid_for_text_prompt.sh`

**ç”¨é€”**ï¼šæµ‹è¯•ä»»æ„æ–‡æœ¬æŒ‡ä»¤

```bash
# ç¼–è¾‘è„šæœ¬ï¼Œä¿®æ”¹æ–‡æœ¬æç¤º
vim run_agent/2_gen_vid_for_text_prompt.sh

# è¿è¡Œ
./run_agent/2_gen_vid_for_text_prompt.sh
```

**è„šæœ¬å†…å®¹**ï¼ˆæ¨æµ‹ï¼‰ï¼š

```bash
#!/bin/bash

# è‡ªå®šä¹‰æ–‡æœ¬æç¤º
TEXT_PROMPT="chop tree"  # ä¿®æ”¹è¿™é‡Œï¼

python run_agent/generate_videos.py \
    --model_path data/weights/steve1/steve1_weights.pt \
    --prior_path data/weights/prior/prior_weights.pt \
    --text_prompt "$TEXT_PROMPT" \
    --output_dir outputs/custom_videos \
    --num_episodes 5 \
    --max_steps 500
```

**æ”¯æŒçš„æ–‡æœ¬æç¤ºç¤ºä¾‹**ï¼š

```bash
# èµ„æºæ”¶é›†
"chop tree"
"mine stone" 
"collect dirt"
"gather sand"

# æˆ˜æ–—
"hunt cow"
"hunt pig"
"kill zombie"

# æ¢ç´¢
"find cave"
"explore forest"
"swim in water"

# å¯¼èˆª
"approach tree"
"walk to cow"
"go to mountain"

# ç»„åˆæŒ‡ä»¤ï¼ˆéœ€éªŒè¯æ”¯æŒç¨‹åº¦ï¼‰
"chop tree and collect wood"
"find cow and hunt it"
```

**å‚æ•°è¯´æ˜**ï¼š
- `--text_prompt`: æ–‡æœ¬æŒ‡ä»¤ï¼ˆå­—ç¬¦ä¸²ï¼‰
- `--num_episodes`: é‡å¤æµ‹è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 5ï¼‰
- `--max_steps`: æ¯ä¸ª episode æœ€å¤§æ­¥æ•°ï¼ˆé»˜è®¤ 500ï¼‰
- `--seed`: éšæœºç§å­ï¼ˆå¯é€‰ï¼‰
- `--render`: æ˜¯å¦å®æ—¶æ˜¾ç¤ºï¼ˆéœ€è¦å›¾å½¢ç•Œé¢ï¼‰

---

### **æ¨¡å¼ 3: äº¤äº’å¼ä¼šè¯** ğŸ®

**è„šæœ¬**ï¼š`run_agent/3_run_interactive_session.sh`

**ç”¨é€”**ï¼šå®æ—¶è¾“å…¥æŒ‡ä»¤ï¼Œè§‚å¯Ÿ Agent è¡Œä¸º

```bash
# âš ï¸ éœ€è¦å›¾å½¢ç•Œé¢ï¼ˆä¸æ”¯æŒ headless æ¨¡å¼ï¼‰
./run_agent/3_run_interactive_session.sh
```

**è„šæœ¬å†…å®¹**ï¼ˆæ¨æµ‹ï¼‰ï¼š

```bash
#!/bin/bash

python run_agent/interactive_agent.py \
    --model_path data/weights/steve1/steve1_weights.pt \
    --prior_path data/weights/prior/prior_weights.pt \
    --render
```

**äº¤äº’å¼ä½¿ç”¨ç¤ºä¾‹**ï¼š

```
=== STEVE-1 Interactive Session ===
Minecraft environment loaded.

Enter text instruction (or 'quit' to exit): chop tree
[Agent executing: chop tree]
Episode reward: 15.3
Episode length: 234 steps

Enter text instruction (or 'quit' to exit): hunt cow
[Agent executing: hunt cow]
Episode reward: 8.7
Episode length: 189 steps

Enter text instruction (or 'quit' to exit): quit
Session ended.
```

**âš ï¸ é™åˆ¶**ï¼š
- ä¸æ”¯æŒ headless æœåŠ¡å™¨
- éœ€è¦ X11 æˆ–å›¾å½¢æ˜¾ç¤º
- macOS/Linux æ¡Œé¢ç¯å¢ƒ

---

## ğŸ Python API ä½¿ç”¨

å¦‚æœå®˜æ–¹è„šæœ¬ä¸æ»¡è¶³éœ€æ±‚ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ Python APIï¼š

### **åŸºç¡€ä½¿ç”¨**

```python
import gym
from steve1 import load_steve1_agent

# 1. åŠ è½½ STEVE-1 æ¨¡å‹
agent = load_steve1_agent(
    weights_path="data/weights/steve1/steve1_weights.pt",
    prior_path="data/weights/prior/prior_weights.pt",
    device="cuda"  # æˆ– "cpu"
)

# 2. åˆ›å»ºç¯å¢ƒ
env = gym.make("MineRLBasaltFindCave-v0")

# 3. è¿è¡Œ Agent
obs = env.reset()
done = False
total_reward = 0

# ä½¿ç”¨æ–‡æœ¬æŒ‡ä»¤
text_instruction = "find a cave"

for step in range(500):
    # Agent é¢„æµ‹åŠ¨ä½œ
    action = agent.predict(obs, text=text_instruction)
    
    # æ‰§è¡ŒåŠ¨ä½œ
    obs, reward, done, info = env.step(action)
    total_reward += reward
    
    # å¯é€‰ï¼šæ¸²æŸ“
    env.render()
    
    if done:
        break

print(f"Episode finished: {step} steps, reward={total_reward}")
env.close()
```

### **æ‰¹é‡è¯„ä¼°å¤šä¸ªä»»åŠ¡**

```python
from steve1 import load_steve1_agent
import gym
import numpy as np

# å®šä¹‰è¯„ä¼°ä»»åŠ¡
tasks = [
    ("chop tree", "MineRLBasaltMakeWaterfall-v0"),
    ("hunt cow", "MineRLBasaltMakeWaterfall-v0"),
    ("mine stone", "MineRLBasaltMakeWaterfall-v0"),
]

agent = load_steve1_agent(
    weights_path="data/weights/steve1/steve1_weights.pt",
    prior_path="data/weights/prior/prior_weights.pt"
)

results = {}

for text_prompt, env_name in tasks:
    env = gym.make(env_name)
    rewards = []
    
    # æ¯ä¸ªä»»åŠ¡æµ‹è¯• 10 æ¬¡
    for episode in range(10):
        obs = env.reset()
        total_reward = 0
        done = False
        
        for step in range(500):
            action = agent.predict(obs, text=text_prompt)
            obs, reward, done, info = env.step(action)
            total_reward += reward
            
            if done:
                break
        
        rewards.append(total_reward)
    
    # ç»Ÿè®¡ç»“æœ
    results[text_prompt] = {
        "mean_reward": np.mean(rewards),
        "std_reward": np.std(rewards),
        "success_rate": sum(r > 0 for r in rewards) / len(rewards)
    }
    
    env.close()

# æ‰“å°ç»“æœ
for task, stats in results.items():
    print(f"\n{task}:")
    print(f"  Mean Reward: {stats['mean_reward']:.2f} Â± {stats['std_reward']:.2f}")
    print(f"  Success Rate: {stats['success_rate']:.1%}")
```

### **ä¿å­˜è§†é¢‘å’Œæ—¥å¿—**

```python
import gym
from steve1 import load_steve1_agent
import cv2
import json

agent = load_steve1_agent(...)
env = gym.make("MineRLBasaltFindCave-v0")

# è®¾ç½®è§†é¢‘å½•åˆ¶
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
video_writer = cv2.VideoWriter(
    'outputs/episode.mp4', 
    fourcc, 
    20.0, 
    (640, 360)
)

# è®°å½•æ—¥å¿—
episode_log = {
    "text_instruction": "find cave",
    "steps": [],
    "total_reward": 0
}

obs = env.reset()
for step in range(500):
    action = agent.predict(obs, text="find cave")
    obs, reward, done, info = env.step(action)
    
    # ä¿å­˜å¸§
    frame = env.render(mode='rgb_array')
    video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
    
    # è®°å½•æ—¥å¿—
    episode_log["steps"].append({
        "step": step,
        "reward": float(reward),
        "action": action.tolist() if hasattr(action, 'tolist') else action
    })
    episode_log["total_reward"] += reward
    
    if done:
        break

video_writer.release()

# ä¿å­˜æ—¥å¿—
with open('outputs/episode_log.json', 'w') as f:
    json.dump(episode_log, f, indent=2)

env.close()
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡å’Œä»»åŠ¡

### **è®ºæ–‡ä¸­çš„è¯„ä¼°ä»»åŠ¡ï¼ˆ13 ä¸ªï¼‰**

æ ¹æ®è®ºæ–‡ï¼ŒSTEVE-1 åœ¨ä»¥ä¸‹ä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼š

| ä»»åŠ¡ ID | æ–‡æœ¬æŒ‡ä»¤ | ç¯å¢ƒ | æˆåŠŸç‡ | éš¾åº¦ |
|--------|---------|------|--------|------|
| 1 | Chop tree | Forest biome | 92% | â­ |
| 2 | Hunt cow | Plains biome | 88% | â­ |
| 3 | Hunt pig | Plains biome | 85% | â­ |
| 4 | Mine stone | Any biome | 78% | â­â­ |
| 5 | Collect dirt | Any biome | 95% | â­ |
| 6 | Collect sand | Desert/beach | 82% | â­ |
| 7 | Collect wood | Forest biome | 90% | â­ |
| 8 | Kill zombie | Night/cave | 45% | â­â­â­ |
| 9 | Approach tree | Forest biome | 98% | â­ |
| 10 | Approach cow | Plains biome | 95% | â­ |
| 11 | Find cave | Any biome | 65% | â­â­ |
| 12 | Swim | Water biome | 88% | â­ |
| 13 | Explore | Any biome | 72% | â­â­ |

**æˆåŠŸæ ‡å‡†**ï¼š
- **Chop tree**: æˆåŠŸç ´åè‡³å°‘ 1 ä¸ªæœ¨å¤´æ–¹å—
- **Hunt cow**: æˆåŠŸå‡»æ€è‡³å°‘ 1 å¤´ç‰›
- **Mine stone**: æˆåŠŸç ´åè‡³å°‘ 1 ä¸ªçŸ³å¤´æ–¹å—
- **Approach X**: åœ¨ 500 æ­¥å†…è·ç¦»ç›®æ ‡ <2 ç±³
- **Find cave**: åœ¨ 500 æ­¥å†…è¿›å…¥æ´ç©´ï¼ˆå…‰ç…§ <7ï¼‰
- **Explore**: åœ¨ 500 æ­¥å†…è®¿é—® >100 ä¸ªä¸åŒçš„ä½ç½®

### **è¯„ä¼°æŒ‡æ ‡**

```python
# 1. æˆåŠŸç‡ï¼ˆSuccess Rateï¼‰
success_rate = num_successful_episodes / total_episodes

# 2. å¹³å‡å¥–åŠ±ï¼ˆAverage Rewardï¼‰
avg_reward = sum(rewards) / len(rewards)

# 3. å¹³å‡æ­¥æ•°ï¼ˆAverage Stepsï¼‰
avg_steps = sum(steps) / len(episodes)

# 4. å®Œæˆæ—¶é—´ï¼ˆTime to Completionï¼‰
avg_time = sum(completion_times) / len(completed_episodes)

# 5. ä»»åŠ¡ç›¸å…³æ€§ï¼ˆTask Relevanceï¼‰
# ä½¿ç”¨ MineCLIP è¯„ä¼°è¡Œä¸ºæ˜¯å¦ä¸æŒ‡ä»¤ç›¸å…³
relevance_score = mineclip.similarity(video, text_instruction)
```

### **è‡ªå®šä¹‰è¯„ä¼°å‡½æ•°**

```python
def evaluate_steve1(agent, task_prompt, num_episodes=10):
    """
    è¯„ä¼° STEVE-1 åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½
    
    Args:
        agent: STEVE-1 æ¨¡å‹
        task_prompt: æ–‡æœ¬æŒ‡ä»¤
        num_episodes: æµ‹è¯•æ¬¡æ•°
    
    Returns:
        dict: è¯„ä¼°ç»“æœ
    """
    env = gym.make("MineRLBasaltFindCave-v0")
    
    results = {
        "successes": 0,
        "rewards": [],
        "steps": [],
        "completion_times": []
    }
    
    for ep in range(num_episodes):
        obs = env.reset()
        total_reward = 0
        done = False
        step_count = 0
        
        for step in range(500):
            action = agent.predict(obs, text=task_prompt)
            obs, reward, done, info = env.step(action)
            total_reward += reward
            step_count += 1
            
            if done:
                break
        
        # åˆ¤æ–­æˆåŠŸï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹ï¼‰
        success = check_success(info, task_prompt)
        
        results["successes"] += int(success)
        results["rewards"].append(total_reward)
        results["steps"].append(step_count)
        
        if success:
            results["completion_times"].append(step_count)
    
    env.close()
    
    # è®¡ç®—ç»Ÿè®¡é‡
    return {
        "success_rate": results["successes"] / num_episodes,
        "mean_reward": np.mean(results["rewards"]),
        "std_reward": np.std(results["rewards"]),
        "mean_steps": np.mean(results["steps"]),
        "mean_completion_time": np.mean(results["completion_times"]) if results["completion_times"] else None
    }

def check_success(info, task_prompt):
    """æ ¹æ®ä»»åŠ¡ç±»å‹åˆ¤æ–­æ˜¯å¦æˆåŠŸ"""
    if "chop" in task_prompt or "tree" in task_prompt:
        return info.get("logs_collected", 0) > 0
    elif "hunt" in task_prompt or "cow" in task_prompt:
        return info.get("cows_killed", 0) > 0
    elif "mine" in task_prompt or "stone" in task_prompt:
        return info.get("stone_collected", 0) > 0
    else:
        # é€šç”¨æˆåŠŸæ ‡å‡†ï¼šè·å¾—æ­£å¥–åŠ±
        return info.get("episode_reward", 0) > 0
```

---

## ğŸ”§ é«˜çº§é…ç½®

### **ä¿®æ”¹æ¨¡å‹å‚æ•°**

```python
# å¦‚æœéœ€è¦è°ƒæ•´æ¨¡å‹è¡Œä¸º
agent = load_steve1_agent(
    weights_path="...",
    prior_path="...",
    device="cuda",
    
    # é«˜çº§å‚æ•°
    temperature=1.0,          # Prior é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šé«˜è¶Šéšæœºï¼‰
    classifier_free_guidance=1.0,  # CFG æƒé‡ï¼ˆè®ºæ–‡ä¸­é‡è¦ï¼‰
    top_k=None,               # Top-k é‡‡æ ·
    top_p=0.9,                # Nucleus é‡‡æ ·
)
```

### **Classifier-Free Guidanceï¼ˆCFGï¼‰**

è®ºæ–‡ä¸­æåˆ° CFG å¯¹æ€§èƒ½å½±å“å¾ˆå¤§ï¼š

```python
# CFG æƒé‡å¯¹æ¯”
for cfg_scale in [0.0, 0.5, 1.0, 2.0, 5.0]:
    agent.set_cfg_scale(cfg_scale)
    
    results = evaluate_steve1(agent, "chop tree", num_episodes=5)
    print(f"CFG={cfg_scale}: Success Rate={results['success_rate']:.2%}")

# é¢„æœŸç»“æœï¼ˆè®ºæ–‡å›¾ 4ï¼‰ï¼š
# CFG=0.0:  ~30% ï¼ˆæ— å¼•å¯¼ï¼‰
# CFG=1.0:  ~70% ï¼ˆé»˜è®¤ï¼‰
# CFG=2.0:  ~85% ï¼ˆæœ€ä½³ï¼‰
# CFG=5.0:  ~60% ï¼ˆè¿‡å¼ºï¼‰
```

---

## â“ å¸¸è§é—®é¢˜

### **Q1: å¦‚ä½•åœ¨ headless æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Ÿ**

```bash
# å®‰è£… xvfb
sudo apt-get install xvfb

# ä½¿ç”¨ xvfb-run
xvfb-run python run_agent/generate_videos.py --text_prompt "chop tree"

# æˆ–åœ¨è„šæœ¬å¼€å¤´æ·»åŠ 
export DISPLAY=:99
Xvfb :99 -screen 0 1024x768x24 &
```

### **Q2: æ¨¡å‹åŠ è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**

```python
# æ£€æŸ¥æƒé‡æ–‡ä»¶è·¯å¾„
import os
assert os.path.exists("data/weights/steve1/steve1_weights.pt"), "æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼"

# æ£€æŸ¥è®¾å¤‡
import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# é™ä½å†…å­˜ä½¿ç”¨
agent = load_steve1_agent(..., half_precision=True)  # ä½¿ç”¨ FP16
```

### **Q3: å¦‚ä½•è°ƒè¯• Agent è¡Œä¸ºï¼Ÿ**

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# å¯è§†åŒ– MineCLIP ç¼–ç 
latent_code = agent.prior.encode_text("chop tree")
print(f"Latent code shape: {latent_code.shape}")  # [1, 512]
print(f"Latent code norm: {latent_code.norm()}")

# æŸ¥çœ‹ Agent çš„åŠ¨ä½œåˆ†å¸ƒ
action_probs = agent.get_action_distribution(obs, text="chop tree")
print(f"Top actions: {action_probs.topk(5)}")
```

### **Q4: å¦‚ä½•ä¸æ‚¨çš„ AIMC é¡¹ç›®å¯¹æ¯”ï¼Ÿ**

```python
# åœ¨ç›¸åŒä»»åŠ¡ä¸Šå¯¹æ¯” STEVE-1 å’Œæ‚¨çš„ MineCLIP-PPO
task = "harvest_1_log"

# STEVE-1 è¯„ä¼°
steve1_results = evaluate_steve1(steve1_agent, "chop tree", num_episodes=10)

# æ‚¨çš„æ–¹æ³•è¯„ä¼°
your_results = evaluate_your_agent(your_agent, task, num_episodes=10)

# å¯¹æ¯”
print(f"STEVE-1 Success Rate: {steve1_results['success_rate']:.2%}")
print(f"Your Method Success Rate: {your_results['success_rate']:.2%}")
```

---

## ğŸ“ˆ ä¸ AIMC é¡¹ç›®é›†æˆå»ºè®®

### **æ–¹æ¡ˆ 1: ä½œä¸º Baseline å¯¹æ¯”**

```bash
# è¯„ä¼° STEVE-1 åœ¨æ‚¨çš„ä»»åŠ¡ä¸Šçš„æ€§èƒ½
cd /Users/nanzhang/aimc/STEVE-1
python evaluate_on_aimc_tasks.py \
    --tasks harvest_1_log,hunt_1_cow,mine_1_stone \
    --num_episodes 20 \
    --output baseline_results.json
```

### **æ–¹æ¡ˆ 2: å­¦ä¹ å…¶ Prior æ–¹æ³•**

```python
# ä» STEVE-1 å­¦ä¹ å¦‚ä½•è®­ç»ƒæ–‡æœ¬â†’MineCLIP çš„ Prior
from steve1.prior import CVAEPrior

# åœ¨æ‚¨çš„æ•°æ®ä¸Šè®­ç»ƒ Prior
prior = CVAEPrior(latent_dim=512)
prior.train(your_text_mineclip_pairs)

# é›†æˆåˆ°æ‚¨çš„ Agent
your_agent.set_prior(prior)
```

### **æ–¹æ¡ˆ 3: æ··åˆä½¿ç”¨**

```python
# çŸ­æœŸä»»åŠ¡ç”¨ STEVE-1ï¼Œé•¿æœŸä»»åŠ¡ç”¨æ‚¨çš„æ–¹æ³•
if task.duration < 60:  # çŸ­ä»»åŠ¡
    agent = steve1_agent
else:  # é•¿ä»»åŠ¡
    agent = your_ppo_agent
```

---

## ğŸ¯ å®Œæ•´è¯„ä¼°æµç¨‹ç¤ºä¾‹

```bash
#!/bin/bash
# complete_evaluation.sh - å®Œæ•´çš„ STEVE-1 è¯„ä¼°æµç¨‹

# 1. ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
if [ ! -f "data/weights/steve1/steve1_weights.pt" ]; then
    ./download_weights.sh
fi

# 2. ç”Ÿæˆè®ºæ–‡è§†é¢‘
echo "Generating paper videos..."
./run_agent/1_gen_paper_videos.sh

# 3. æµ‹è¯•è‡ªå®šä¹‰æŒ‡ä»¤
echo "Testing custom prompts..."
for prompt in "chop tree" "hunt cow" "mine stone"; do
    python run_agent/generate_videos.py \
        --text_prompt "$prompt" \
        --num_episodes 5 \
        --output_dir "outputs/$prompt"
done

# 4. ç»Ÿè®¡ç»“æœ
python analyze_results.py \
    --input_dir outputs \
    --output results_summary.json

echo "Evaluation complete! Results saved to results_summary.json"
```

---

## ğŸ“š ç›¸å…³èµ„æº

- **è®ºæ–‡**ï¼šhttps://arxiv.org/abs/2306.00937
- **GitHub**ï¼šhttps://github.com/Shalev-Lifshitz/STEVE-1
- **é¡¹ç›®ä¸»é¡µ**ï¼šhttps://sites.google.com/view/steve-1
- **AIMC é¡¹ç›®æ–‡æ¡£**ï¼š
  - `docs/reference/STEVE1_MODEL_DOWNLOAD_GUIDE.md` - ä¸‹è½½æŒ‡å—
  - `docs/technical/MINECLIP_INSTRUCTION_DRIVEN_AGENT.md` - MineCLIP åŸç†

---

## ğŸ¯ æ€»ç»“

è™½ç„¶å®˜æ–¹ GitHub æ–‡æ¡£è¾ƒç®€ç•¥ï¼Œä½†é€šè¿‡ä»¥ä¸Šæ–¹æ³•æ‚¨å¯ä»¥ï¼š

1. âœ… **ä½¿ç”¨ä¸‰ä¸ªå®˜æ–¹è„šæœ¬**ï¼šå¿«é€Ÿæµ‹è¯•åŸºæœ¬åŠŸèƒ½
2. âœ… **ç¼–å†™ Python ä»£ç **ï¼šæ·±åº¦å®šåˆ¶è¯„ä¼°æµç¨‹
3. âœ… **æ‰¹é‡è¯„ä¼°**ï¼šç³»ç»Ÿæµ‹è¯•å¤šä¸ªä»»åŠ¡
4. âœ… **ä¸ AIMC å¯¹æ¯”**ï¼šè¯„ä¼°ä¸åŒæ–¹æ³•çš„ä¼˜åŠ£

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š
1. å…ˆè¿è¡Œå®˜æ–¹è„šæœ¬ï¼Œç†Ÿæ‚‰åŸºæœ¬ç”¨æ³•
2. ç¼–å†™è‡ªå®šä¹‰è¯„ä¼°è„šæœ¬ï¼Œæµ‹è¯•æ‚¨å…³å¿ƒçš„ä»»åŠ¡
3. ä¸æ‚¨çš„ MineCLIP-PPO æ–¹æ³•å¯¹æ¯”
4. å†³å®šæ˜¯å¦é›†æˆæˆ–å€Ÿé‰´ STEVE-1 çš„æ–¹æ³•

å¦‚æœ‰å…·ä½“é—®é¢˜ï¼Œéšæ—¶é—®æˆ‘ï¼ğŸš€

