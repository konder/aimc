# å¤šè¯­è¨€MineCLIPå¿«é€Ÿå…¥é—¨

> **å‰æ**: å·²å®Œæˆæ–¹æ¡ˆAï¼ˆç¿»è¯‘æ¡¥æ¥ï¼‰å¹¶éªŒè¯  
> **ç›®æ ‡**: å¿«é€Ÿå®æ–½æ–¹æ¡ˆBï¼ˆå¯¹é½å±‚ï¼‰  
> **æ—¶é—´**: 1-2å‘¨

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µï¼ˆ3åˆ†é’Ÿç†è§£ï¼‰

```
æ–¹æ¡ˆBçš„æœ¬è´¨:
  ä¸­æ–‡ "ç æ ‘" â†’ Chinese-CLIP â†’ 512ç»´å‘é‡ â†’ å¯¹é½å±‚ â†’ MineCLIPç©ºé—´
  è‹±æ–‡ "chop tree" â†’ MineCLIP â†’ 512ç»´å‘é‡ï¼ˆç›®æ ‡ï¼‰

è®­ç»ƒç›®æ ‡:
  è®©å¯¹é½å±‚å­¦ä¼š: Chinese-CLIPç©ºé—´ â†’ MineCLIPç©ºé—´
  
ä¼˜åŠ¿:
  âœ… ä¸éœ€è¦ç¿»è¯‘
  âœ… æ›´å¿«ï¼ˆçœå»ç¿»è¯‘æ—¶é—´ï¼‰
  âœ… æ›´å‡†ï¼ˆç›´æ¥è¯­ä¹‰ç†è§£ï¼‰
```

---

## ğŸ“‹ å®æ–½æ­¥éª¤ï¼ˆ5æ­¥èµ°ï¼‰

### Step 1: ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆ10åˆ†é’Ÿï¼‰

```bash
# è¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬ï¼ˆå°†åœ¨æœ¬æ–‡æ¡£åé¢æä¾›ï¼‰
python scripts/generate_alignment_data.py

# é¢„æœŸè¾“å‡º:
# - data/alignment_pairs/train.json (~1600å¯¹)
# - data/alignment_pairs/val.json (~400å¯¹)
```

**æ•°æ®æ¥æº**:
- âœ… ç°æœ‰æœ¯è¯­è¯å…¸ï¼ˆ100å¯¹ï¼‰
- âœ… è¯„ä¼°ä»»åŠ¡é…ç½®ï¼ˆ50-100å¯¹ï¼‰
- âœ… è‡ªåŠ¨ç”Ÿæˆç»„åˆæŒ‡ä»¤ï¼ˆ500-1000å¯¹ï¼‰

### Step 2: åˆ›å»ºæ ¸å¿ƒæ¨¡å‹ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**: `src/models/multilingual_mineclip.py`

å…³é”®ç±»:
1. `AlignmentLayer` - å¯¹é½å±‚ç½‘ç»œï¼ˆMLPï¼‰
2. `MultilingualMineCLIP` - ç»Ÿä¸€æ¥å£

å‚è€ƒå®Œæ•´å®ç°: `docs/design/MULTILINGUAL_MINECLIP_IMPLEMENTATION_PLAN.md` ç¬¬2èŠ‚

### Step 3: å®ç°è®­ç»ƒå™¨ï¼ˆ1å¤©ï¼‰

**æ–‡ä»¶**: `src/training/alignment_trainer.py`

æ ¸å¿ƒåŠŸèƒ½:
- åŠ è½½ä¸­è‹±æ–‡pairs
- è®­ç»ƒå¯¹é½å±‚
- éªŒè¯å’Œä¿å­˜

### Step 4: è®­ç»ƒæ¨¡å‹ï¼ˆ1-3å¤©ï¼‰

```bash
# è¿è¡Œè®­ç»ƒ
python scripts/train_alignment.py \
    --train_data data/alignment_pairs/train.json \
    --val_data data/alignment_pairs/val.json \
    --epochs 100 \
    --batch_size 32 \
    --lr 1e-4

# ç›‘æ§è®­ç»ƒ
# - æŸ¥çœ‹ç»ˆç«¯è¾“å‡º
# - è®­ç»ƒæ›²çº¿: data/weights/alignment/training_curves.png
```

**é¢„æœŸç»“æœ**:
- è®­ç»ƒæŸå¤±æ”¶æ•›åˆ° < 0.05
- éªŒè¯æŸå¤±ç¨³å®š
- ä½™å¼¦ç›¸ä¼¼åº¦ > 0.90

### Step 5: å¯¹æ¯”è¯„ä¼°ï¼ˆåŠå¤©ï¼‰

```bash
# è¿è¡Œå¯¹æ¯”è¯„ä¼°
python scripts/evaluate_alignment.py \
    --alignment_path data/weights/alignment/alignment_best.pth \
    --task_config config/eval_tasks.yaml \
    --n_trials 10
```

**é¢„æœŸå¯¹æ¯”**:
```
æ–¹æ¡ˆAï¼ˆç¿»è¯‘ï¼‰: EN=85%, ZH=75%, Gap=10%
æ–¹æ¡ˆBï¼ˆå¯¹é½ï¼‰: EN=85%, ZH=82%, Gap=3%  âœ…

ä¸­æ–‡æˆåŠŸç‡æå‡: +7%
ä¸­è‹±æ–‡Gapç¼©å°: -7%
```

---

## ğŸ› ï¸ ä»£ç ä¿®æ”¹æ¸…å•

### æ–°å¢æ–‡ä»¶ï¼ˆ4ä¸ªï¼‰

```bash
src/models/
  â””â”€â”€ multilingual_mineclip.py          # æ ¸å¿ƒæ¨¡å‹ â­

src/training/
  â””â”€â”€ alignment_trainer.py              # è®­ç»ƒå™¨ â­

scripts/
  â”œâ”€â”€ generate_alignment_data.py        # æ•°æ®ç”Ÿæˆ â­
  â””â”€â”€ train_alignment.py                # è®­ç»ƒè„šæœ¬ â­
  â””â”€â”€ evaluate_alignment.py             # è¯„ä¼°è„šæœ¬
```

### ä¿®æ”¹æ–‡ä»¶ï¼ˆ2ä¸ªï¼‰

```python
# 1. src/evaluation/steve1_evaluator.py
# æ–°å¢å‚æ•°: use_multilingual, alignment_path
# ä¿®æ”¹æ–¹æ³•: _run_single_trial() - æ”¯æŒå¤šè¯­è¨€ç¼–ç 

# 2. src/evaluation/eval_framework.py  
# æ–°å¢é…ç½®: use_multilingual, alignment_path
# ä¼ é€’å‚æ•°åˆ° STEVE1Evaluator
```

---

## ğŸ“¦ ä¾èµ–å®‰è£…

```bash
# å®‰è£… transformersï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
pip install transformers

# æµ‹è¯• Chinese-CLIP ä¸‹è½½
python -c "
from transformers import ChineseCLIPModel
model = ChineseCLIPModel.from_pretrained(
    'OFA-Sys/chinese-clip-vit-base-patch16',
    cache_dir='data/huggingface_cache'
)
print('âœ… Chinese-CLIP åŠ è½½æˆåŠŸ')
"
```

---

## ğŸ¯ è®­ç»ƒç›‘æ§æŒ‡æ ‡

### è®­ç»ƒé˜¶æ®µå…³æ³¨

```
Lossæ›²çº¿:
  âœ… è®­ç»ƒlossæŒç»­ä¸‹é™
  âœ… éªŒè¯lossç¨³å®šï¼ˆä¸æŒç»­ä¸Šå‡ï¼‰
  âš ï¸  å¦‚æœéªŒè¯lossä¸Šå‡ â†’ è¿‡æ‹Ÿåˆï¼Œéœ€è¦early stopping

å…³é”®æŒ‡æ ‡:
  - MSE Loss < 0.05
  - Cosine Loss < 0.10  
  - ä½™å¼¦ç›¸ä¼¼åº¦ > 0.90
```

### è¯„ä¼°é˜¶æ®µå…³æ³¨

```
æˆåŠŸç‡å¯¹æ¯”:
  âœ… ä¸­æ–‡æˆåŠŸç‡æå‡ > 0%
  âœ… ä¸­è‹±æ–‡gapç¼©å°
  âœ… æ¨ç†é€Ÿåº¦æå‡ï¼ˆæ¶ˆé™¤ç¿»è¯‘å»¶è¿Ÿï¼‰

å¤±è´¥caseåˆ†æ:
  - è®°å½•å“ªäº›ä»»åŠ¡æ€§èƒ½ä¸‹é™
  - åˆ†ææ˜¯å¯¹é½å±‚é—®é¢˜è¿˜æ˜¯æ•°æ®é—®é¢˜
```

---

## ğŸ”§ å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: Chinese-CLIPåŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping huggingface.co

# æ‰‹åŠ¨ä¸‹è½½ï¼ˆå¦‚æœæ— æ³•è‡ªåŠ¨ä¸‹è½½ï¼‰
# è®¿é—®: https://huggingface.co/OFA-Sys/chinese-clip-vit-base-patch16
# ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ° data/huggingface_cache/
```

### Q2: è®­ç»ƒæŸå¤±ä¸æ”¶æ•›

```python
# æ£€æŸ¥æ•°æ®è´¨é‡
python -c "
import json
data = json.load(open('data/alignment_pairs/train.json'))
print(f'æ•°æ®é‡: {len(data)}')
print('æ ·æœ¬:', data[0])
"

# é™ä½å­¦ä¹ ç‡
--lr 1e-5  # ä»1e-4é™ä½

# ç®€åŒ–ç½‘ç»œ
# ä¿®æ”¹ AlignmentLayer: ä»2å±‚æ”¹ä¸º1å±‚
```

### Q3: è¯„ä¼°æ€§èƒ½æœªæå‡

```bash
# æ£€æŸ¥å¯¹é½å±‚æ˜¯å¦æ­£ç¡®åŠ è½½
# åœ¨è¯„ä¼°è„šæœ¬ä¸­æ·»åŠ æ—¥å¿—
logger.info(f"ä½¿ç”¨å¯¹é½å±‚: {alignment_path}")

# å¯¹æ¯”åµŒå…¥ç›¸ä¼¼åº¦
python -c "
from src.models.multilingual_mineclip import MultilingualMineCLIP
model = MultilingualMineCLIP(alignment_path='...')
embed_zh = model.encode_text('ç æ ‘', language='zh')
embed_en = model.encode_text('chop tree', language='en')
import numpy as np
cos_sim = np.dot(embed_zh, embed_en) / (np.linalg.norm(embed_zh) * np.linalg.norm(embed_en))
print(f'ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.4f}')  # åº”è¯¥ > 0.90
"
```

---

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒå®Œæˆå

```
æ–‡ä»¶äº§å‡º:
  âœ… data/weights/alignment/alignment_best.pth       # æœ€ä½³æƒé‡
  âœ… data/weights/alignment/alignment_final.pth      # æœ€ç»ˆæƒé‡
  âœ… data/weights/alignment/training_curves.png      # è®­ç»ƒæ›²çº¿
  âœ… data/weights/alignment/alignment_epoch_*.pth    # ä¸­é—´checkpoint

å¤§å°:
  - æ¯ä¸ªæƒé‡æ–‡ä»¶ ~2MBï¼ˆå¯¹é½å±‚å¾ˆå°ï¼‰
```

### è¯„ä¼°æŠ¥å‘Š

```
æ€§èƒ½å¯¹æ¯”:
  æ–¹æ¡ˆAï¼ˆç¿»è¯‘æ¡¥æ¥ï¼‰:
    - ENæˆåŠŸç‡: 82%
    - ZHæˆåŠŸç‡: 75%
    - ä¸­è‹±æ–‡Gap: 7%
    - æ¨ç†å»¶è¿Ÿ: ~150ms

  æ–¹æ¡ˆBï¼ˆå¯¹é½å±‚ï¼‰:
    - ENæˆåŠŸç‡: 82%ï¼ˆä¸å˜ï¼‰
    - ZHæˆåŠŸç‡: 80%ï¼ˆ+5%ï¼‰âœ…
    - ä¸­è‹±æ–‡Gap: 2%ï¼ˆ-5%ï¼‰âœ…  
    - æ¨ç†å»¶è¿Ÿ: ~30msï¼ˆ-80%ï¼‰âœ…
```

---

## âš¡ å¿«é€Ÿæµ‹è¯•

### æµ‹è¯•å¯¹é½å±‚åŠ è½½

```python
# test_multilingual_mineclip.py
from src.models.multilingual_mineclip import MultilingualMineCLIP
from steve1.config import MINECLIP_CONFIG

# åˆ›å»ºæ¨¡å‹
model = MultilingualMineCLIP(
    mineclip_config=MINECLIP_CONFIG,
    alignment_path="data/weights/alignment/alignment_best.pth"
)

# æµ‹è¯•ç¼–ç 
print("æµ‹è¯•ä¸­æ–‡ç¼–ç ...")
embed_zh = model.encode_text("ç æ ‘", language='zh')
print(f"  ä¸­æ–‡åµŒå…¥shape: {embed_zh.shape}")  # (512,)

print("æµ‹è¯•è‹±æ–‡ç¼–ç ...")
embed_en = model.encode_text("chop tree", language='en')
print(f"  è‹±æ–‡åµŒå…¥shape: {embed_en.shape}")  # (512,)

# è®¡ç®—ç›¸ä¼¼åº¦
import numpy as np
cos_sim = np.dot(embed_zh, embed_en) / (np.linalg.norm(embed_zh) * np.linalg.norm(embed_en))
print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.4f}")  # åº”è¯¥ > 0.90

print("âœ… æµ‹è¯•é€šè¿‡")
```

---

## ğŸ“š å®Œæ•´æ–‡æ¡£

æ›´è¯¦ç»†çš„è®¾è®¡å’Œå®ç°ï¼Œè¯·å‚è€ƒ:

- **å®Œæ•´è®¾è®¡**: `docs/design/MULTILINGUAL_MINECLIP_IMPLEMENTATION_PLAN.md`
- **åŸå§‹æ–¹æ¡ˆ**: `docs/design/CHINESE_AIMC_AGENT_TECHNICAL_PLAN.md`
- **è¯„ä¼°æ–¹æ³•**: `docs/guides/STEVE1_EVALUATION_GUIDE.md`

---

## âœ… å®Œæˆæ ‡å¿—

å½“ä½ çœ‹åˆ°ä»¥ä¸‹ç»“æœæ—¶ï¼Œæ–¹æ¡ˆBå®æ–½æˆåŠŸ:

- [x] è®­ç»ƒæŸå¤±æ”¶æ•›ï¼ˆ< 0.05ï¼‰
- [x] ä¸­æ–‡æˆåŠŸç‡æå‡ï¼ˆ> +3%ï¼‰
- [x] ä¸­è‹±æ–‡Gapç¼©å°ï¼ˆ< 5%ï¼‰
- [x] æ¨ç†é€Ÿåº¦æå‡ï¼ˆ< 50msï¼‰
- [x] è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

**æ­å–œï¼ğŸ‰ ä½ ç°åœ¨æœ‰äº†æ”¯æŒä¸­æ–‡çš„é«˜æ€§èƒ½AIMC Agentï¼**

---

**å¿«é€Ÿå…¥é—¨ç‰ˆæœ¬**: v1.0  
**å¯¹åº”å®Œæ•´æ–¹æ¡ˆ**: `MULTILINGUAL_MINECLIP_IMPLEMENTATION_PLAN.md` v1.0  
**æ›´æ–°æ—¥æœŸ**: 2025-11-10







